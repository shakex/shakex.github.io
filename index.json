[{"categories":null,"content":"Image ","date":"2021-01-25","objectID":"/test-page.html/:0:1","tags":["blogging"],"title":"ğŸ”åŠŸèƒ½æµ‹è¯•é¡µé¢","uri":"/test-page.html/"},{"categories":null,"content":"Font Awesome ","date":"2021-01-25","objectID":"/test-page.html/:0:2","tags":["blogging"],"title":"ğŸ”åŠŸèƒ½æµ‹è¯•é¡µé¢","uri":"/test-page.html/"},{"categories":null,"content":"Music ","date":"2021-01-25","objectID":"/test-page.html/:0:3","tags":["blogging"],"title":"ğŸ”åŠŸèƒ½æµ‹è¯•é¡µé¢","uri":"/test-page.html/"},{"categories":null,"content":"bilibili ","date":"2021-01-25","objectID":"/test-page.html/:0:4","tags":["blogging"],"title":"ğŸ”åŠŸèƒ½æµ‹è¯•é¡µé¢","uri":"/test-page.html/"},{"categories":null,"content":"Typeit ","date":"2021-01-25","objectID":"/test-page.html/:0:5","tags":["blogging"],"title":"ğŸ”åŠŸèƒ½æµ‹è¯•é¡µé¢","uri":"/test-page.html/"},{"categories":null,"content":"æ¸…å• åˆå§‹åŒ–ï¼Œé€‰ç”¨Hugo-CodeITä¸»é¢˜ ç½‘ç«™ä¿¡æ¯åŸºç¡€é…ç½®ï¼Œä¸ªæ€§åŒ–æ ·å¼ï¼ˆå­—å·ã€è‰²å½©é£æ ¼ç­‰ï¼‰ æ·»åŠ å‡ ç¯‡æ–‡ç«  å°ç«™è¿è¡Œå¤©æ•°foot æ·»åŠ æ–‡ç« ç½®é¡¶æ ‡è®°ğŸ” ç½‘ç«™Logo å‡ ä¸ªæ ç›®çš„Markdownæ¨¡æ¿ å…³äº/Abouté¡µé¢ 404é¡µé¢ Netlifyéƒ¨ç½² CI/CDå·¥ä½œæµ åŸŸåç”³è¯· æ–°å¢ç›¸å†Œæ ç›® ","date":"2021-01-25","objectID":"/blog-build.html/:1:0","tags":["blogging"],"title":"å°ç«™æ–½å·¥è¿›åº¦è‡ªæŸ¥","uri":"/blog-build.html/"},{"categories":null,"content":"è¿‘æœŸæ ç›® ","date":"2021-01-25","objectID":"/blog-build.html/:2:0","tags":["blogging"],"title":"å°ç«™æ–½å·¥è¿›åº¦è‡ªæŸ¥","uri":"/blog-build.html/"},{"categories":null,"content":"about ","date":"2021-01-23","objectID":"/about/:0:0","tags":null,"title":"å…³äº","uri":"/about/"},{"categories":["LMSI"],"content":"MIT-Adobe FiveK Datasetï¼šMIT-Adobeç¾å­¦å¢å¼ºæ•°æ®é›†1 https://data.csail.mit.edu/graphics/fivek/ #Classification #Multi-label #Image enhancement å‘å¸ƒè€…ï¼šMIT CSAIL \u0026 Adobe Systems Inc. å‘å¸ƒæ—¥æœŸï¼š2011 æ ·æœ¬æ•°ï¼š5000 åˆ†è¾¨ç‡ï¼šä¸å›ºå®šï¼ˆRAWï¼‰ è¯ä¹¦ï¼šLicenseAdobe, LicenseAdobeMIT fivekMIT-Adobe FiveK dataset \" MIT-Adobe FiveK dataset â€œWe collected 5,000 photographs taken with SLR cameras by a set of different photographers. They are all in RAW format; that is, all the information recorded by the camera sensor is preserved. We made sure that these photographs cover a broad range of scenes, subjects, and lighting conditions. We then hired five photography students in an art school to adjust the tone of the photos. Each of them retouched all the 5,000 photos using a software dedicated to photo adjustment (Adobe Lightroom) on which they were extensively trained. We asked the retouchers to achieve visually pleasing renditions, akin to a postcard. The retouchers were compensated for their work.â€ ","date":"2021-01-19","objectID":"/lmsi-fivek.html/:1:0","tags":["computer vision","dataset"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek.html/"},{"categories":["LMSI"],"content":"ç›®å½• ï¼ˆæ–‡ä»¶å¤ªå¤§ï¼Œæœªå…¨éƒ¨ä¸‹è½½ï¼‰ ","date":"2021-01-19","objectID":"/lmsi-fivek.html/:1:1","tags":["computer vision","dataset"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek.html/"},{"categories":["LMSI"],"content":"å¤‡æ³¨ æä¾›å…¨éƒ¨æ•°æ®ä¸‹è½½ï¼ˆï½50GBï¼‰å’Œå•å¼ å›¾ç‰‡ä¸‹è½½ï¼Œå¯å†™è„šæœ¬éƒ¨åˆ†ä¸‹è½½æŸå‡ å¼ å›¾ç‰‡æˆ–æŸä¸ªä¸“å®¶è°ƒè‰²åçš„å›¾ç‰‡ã€‚æ•°æ®é›†åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š å›¾ç‰‡æ ¼å¼ä¸ºPNGï¼ˆå¯é€šè¿‡DCRAWã€Adobe lightroomæˆ–å…¶ä»–å›¾åƒå·¥å…·è¯»å–ï¼‰ï¼Œè°ƒè‰²åçš„å›¾ç‰‡ä¿å­˜ä¸ºTIFFæ ¼å¼ æä¾›5ä½åæœŸä¸“å®¶Adobe Lightroom catalogæ–‡ä»¶ï¼Œå³åŒ…å«äº†5ä½ä¸“å®¶å¯¹æ¯å¼ å›¾ç‰‡çš„è°ƒè‰²è®°å½•å’Œå„å‚æ•°å€¼ æä¾›æ¯å¼ å›¾ç‰‡çš„è¯­ä¹‰ä¿¡æ¯æ ‡æ³¨ï¼ˆå®¤å†…/å®¤å¤–ã€æ‹æ‘„æ—¶æ®µã€å…‰çº¿ã€æ‹æ‘„ä¸»é¢˜ç­‰ï¼‰ ","date":"2021-01-19","objectID":"/lmsi-fivek.html/:1:2","tags":["computer vision","dataset"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek.html/"},{"categories":["LMSI"],"content":"å¼•ç”¨ @inproceedings{fivek, author = \"Vladimir Bychkovsky and Sylvain Paris and Eric Chan and Fr{\\'e}do Durand\", title = \"Learning Photographic Global Tonal Adjustment with a Database of Input / Output Image Pairs\", booktitle = \"The Twenty-Fourth IEEE Conference on Computer Vision and Pattern Recognition\", year = \"2011\" } ","date":"2021-01-19","objectID":"/lmsi-fivek.html/:1:3","tags":["computer vision","dataset"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek.html/"},{"categories":["LMSI"],"content":"è”ç³»æ–¹å¼ fivek-dataset@googlegroups.com æ•°æ®ä½¿ç”¨ å¦‚æœªä½œç‰¹åˆ«è¯´æ˜ï¼Œå¤§éƒ¨åˆ†å…¬å¼€æ•°æ®é›†ä»…ä½œä¸ºç ”ç©¶ç”¨é€”ã€‚ Bychkovsky, V., Sylvain Paris, E. Chan and F. Durand. Learning photographic global tonal adjustment with a database of input/output image pairs. [CVPR'11] â†©ï¸ ","date":"2021-01-19","objectID":"/lmsi-fivek.html/:1:4","tags":["computer vision","dataset"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek.html/"},{"categories":["LMSI"],"content":"Mars32kï¼šç«æ˜Ÿæ•°æ®é›†1 https://dominikschmidt.xyz/mars32k/ #Unsupervised å‘å¸ƒè€…ï¼šNASA/JPL-Caltech å‘å¸ƒæ—¥æœŸï¼š2018.11 æ ·æœ¬æ•°ï¼š32368 åˆ†è¾¨ç‡ï¼š560x500 sample data This dataset consists of about 32,000 color images collected by the Curiosity rover on Mars between August 2012 and November 2018. The images show various geographical and geological features of Mars such as mountains and valleys, craters, dunes and rocky terrain. All images have been scaled down using linear interpolation to 560x500px (some images have been cropped). The dataset is intended for unsupervised learning and the images are only labeled with the date they were taken on. This dataset only contains photos taken with Curiosityâ€™s Mastcam camera and all grayscale or other images were removed. ","date":"2021-01-17","objectID":"/lsmi-mars32k.html/:1:0","tags":["computer vision","dataset"],"title":"Mars32k dataset","uri":"/lsmi-mars32k.html/"},{"categories":["LMSI"],"content":"ç›®å½• mars32k/ â””[cr_]sol_nasa_filename.jpg # æ–‡ä»¶å‘½åè§„åˆ™ï¼š # cr_: æ ‡è®°è¯¥å›¾ç‰‡å·²ç»è¿‡è£å‰ª # solï¼šæ ‡è®°æ‹æ‘„è¿™å¼ å›¾ç‰‡çš„ç«æ˜Ÿå¤ªé˜³æ—¥ # nasa_filenameï¼šæ ‡è®°NASAå¯¹è¯¥å›¾ç‰‡çš„å‘½å # ä¾‹å¦‚å›¾ç‰‡åç§°ï¼š725_0725MR0030950120402857E01_DXXX.jpgï¼Œ # è¡¨ç¤ºè¯¥å›¾ç‰‡æœªç»è¿‡è£å‰ªï¼Œæ‹æ‘„äºç™»é™†ç«æ˜Ÿçš„ç¬¬725å¤©ï¼Œåç§°ä¸º0725MR0030950120402857E01_DXXX ","date":"2021-01-17","objectID":"/lsmi-mars32k.html/:1:1","tags":["computer vision","dataset"],"title":"Mars32k dataset","uri":"/lsmi-mars32k.html/"},{"categories":["LMSI"],"content":"å¤‡æ³¨ æ•°æ®é›†ä¸­çš„å›¾åƒå¹¶éåŸå§‹åˆ†è¾¨ç‡ï¼Œéƒ½ç»è¿‡äº†çº¿æ€§æ’å€¼ï¼Œç»Ÿä¸€è°ƒæ•´ä¸º560Ã—500pxï¼Œè¿™äº›å›¾ç‰‡æ˜¾ç¤ºäº†ç«æ˜Ÿçš„å„ç§åœ°ç†å’Œåœ°è´¨ç‰¹å¾ï¼Œå¦‚å±±è„‰å’Œå±±è°·ï¼Œé™¨çŸ³å‘ï¼Œæ²™ä¸˜å’Œå²©çŸ³åœ°å½¢ã€‚è¯¥æ•°æ®é›†å¯ç”¨äºä¸€äº›è®¡ç®—æœºå›¾åƒä»»åŠ¡ï¼Œæ¯”å¦‚äºç‰©ä½“æ£€æµ‹æ¨¡å‹çš„è®­ç»ƒã€æ¨¡æ‹Ÿä»¿çœŸ3Dç«æ˜Ÿè¡¨é¢æ¨¡å‹çš„æ­å»ºï¼Œè¿˜èƒ½ä½œä¸ºå¤©æ–‡å­¦ç§‘ç§‘æ™®æ‰€ç”¨ã€‚ ","date":"2021-01-17","objectID":"/lsmi-mars32k.html/:1:2","tags":["computer vision","dataset"],"title":"Mars32k dataset","uri":"/lsmi-mars32k.html/"},{"categories":["LMSI"],"content":"è”ç³»æ–¹å¼ schmidtdominik30@gmail.com æ•°æ®ä½¿ç”¨ å¦‚æœªä½œç‰¹åˆ«è¯´æ˜ï¼Œå¤§éƒ¨åˆ†å…¬å¼€æ•°æ®é›†ä»…ä½œä¸ºç ”ç©¶ç”¨é€”ã€‚ https://dominikschmidt.xyz/mars32k/ â†©ï¸ ","date":"2021-01-17","objectID":"/lsmi-mars32k.html/:1:3","tags":["computer vision","dataset"],"title":"Mars32k dataset","uri":"/lsmi-mars32k.html/"},{"categories":["LMSI"],"content":"1. UEC Food-100ï¼šé£Ÿç‰©è¯†åˆ«æ•°æ®é›†1 http://foodcam.mobi/dataset100.html #Classification #Recognition #Multi-label å‘å¸ƒè€…ï¼šThe University of Electro-Communications, Tokyo, Japan å‘å¸ƒæ—¥æœŸï¼š2012 æ ·æœ¬æ•°ï¼š16557 ç±»åˆ«æ•°ï¼š100 åˆ†è¾¨ç‡ï¼šä¸å›ºå®š è¯ä¹¦ï¼šResearch Only uecfood-100UEC Food 100 dataset \" UEC Food 100 dataset The dataset â€œUEC FOOD 100â€ contains 100-kind food photos. Each food photo has a bounding box indicating the location of the food item in the photo. Most of the food categories in this dataset are popular foods in Japan. Therefore, some catarogies might not be familiar with other people than Japanese. ","date":"2021-01-16","objectID":"/lmsi-uec-food.html/:1:0","tags":["computer vision","dataset"],"title":"UEC food datasets","uri":"/lmsi-uec-food.html/"},{"categories":["LMSI"],"content":"2. UEC Food-256ï¼šé£Ÿç‰©è¯†åˆ«æ•°æ®é›†2 http://foodcam.mobi/dataset256.html #Classification #Recognition å‘å¸ƒè€…ï¼šThe University of Electro-Communications, Tokyo, Japan å‘å¸ƒæ—¥æœŸï¼š2014 æ ·æœ¬æ•°ï¼š16557 ç±»åˆ«æ•°ï¼š256 åˆ†è¾¨ç‡ï¼šä¸å›ºå®š è¯ä¹¦ï¼šResearch Only uecfood-256UEC Food 256 dataset \" UEC Food 256 dataset The dataset â€œUEC FOOD 256â€ contains 256-kind food photos. Each food photo has a bounding box indicating the location of the food item in the photo. Most of the food categories in this dataset are popular foods in Japan and other countries. Therefore, some catarogies might not be familiar with other people than Japanese. ","date":"2021-01-16","objectID":"/lmsi-uec-food.html/:2:0","tags":["computer vision","dataset"],"title":"UEC food datasets","uri":"/lmsi-uec-food.html/"},{"categories":["LMSI"],"content":"3. UECFoodPix/UECFoodPixCompleteï¼šé£Ÿç‰©åˆ†å‰²æ•°æ®é›†34 http://mm.cs.uec.ac.jp/uecfoodpix/ #Classification #Segmentation å‘å¸ƒè€…ï¼šThe University of Electro-Communications, Tokyo, Japan å‘å¸ƒæ—¥æœŸï¼š2020.7(UECFoodPix), 2020.10(UECFoodPixComplete) æ ·æœ¬æ•°ï¼š9000 (train) + 1000 (test) ç±»åˆ«æ•°ï¼š103 åˆ†è¾¨ç‡ï¼šä¸å›ºå®š è¯ä¹¦ï¼šResearch Only uecfoodpixUECFoodPix/UECFoodPixComplete dataset \" UECFoodPix/UECFoodPixComplete dataset UECFoodPix and UECFoodPixComplete are food images dataset with segmentation masks including 9,000 images for training and 1,000 image for testing. The Segmentation masks are augmented by food category. In UECFoodPix, the mask images is created using a bounding box and GrabCut, and In UECFoodPixCimplete there is provided manualy.The mask images have pixel-wise food 103 class labels, and only R(red) channel have this labels. ","date":"2021-01-16","objectID":"/lmsi-uec-food.html/:3:0","tags":["computer vision","dataset"],"title":"UEC food datasets","uri":"/lmsi-uec-food.html/"},{"categories":["LMSI"],"content":"ç›®å½• # UEC Food-100 UCEFOOD100/ â””[1-100]/ # 1-100ç±»é£Ÿç‰©å›¾ç‰‡æ–‡ä»¶å¤¹ â”‚ã€€â””*.jpg # å±äºè¯¥ç±»çš„å›¾ç‰‡ â”‚ã€€â””bb_info.txt # è¯¥ç±»æ‰€æœ‰å›¾ç‰‡çš„bouding boxä¿¡æ¯ â””category_ja_{euc, sjis, utf8}.txt # ç±»åˆ«IDå’Œå¯¹åº”æ ‡ç­¾ï¼ˆæ—¥æ–‡ï¼‰ â””category.txt # ç±»åˆ«IDå’Œå¯¹åº”æ ‡ç­¾ï¼ˆè‹±æ–‡ï¼‰ â””multiple_food.txt # åŒ…å«å¤šæ ‡ç­¾çš„å›¾ç‰‡åå’Œå¯¹åº”çš„ç±»åˆ«ID â””README.txt # è¯´æ˜æ–‡æ¡£ # UEC Food-256 UCEFOOD256/ â””[1-256]/ # 1-256ç±»é£Ÿç‰©å›¾ç‰‡æ–‡ä»¶å¤¹ â”‚ã€€â””*.jpg # å±äºè¯¥ç±»çš„å›¾ç‰‡ â”‚ã€€â””bb_info.txt # è¯¥ç±»æ‰€æœ‰å›¾ç‰‡çš„bouding boxä¿¡æ¯ â””category.txt # ç±»åˆ«IDå’Œå¯¹åº”æ ‡ç­¾ï¼ˆè‹±æ–‡ï¼‰ â””README.txt # è¯´æ˜æ–‡æ¡£ # UECFoodPixComplete UECFOODPIXCOMPLTE/ â”œdata/ â””UECFoodPIXCOMPLTE/ â””train/ â”‚ã€€â””img/*.jpg # è®­ç»ƒå›¾ç‰‡ â”‚ã€€â””mask/*.png # è®­ç»ƒå›¾ç‰‡åˆ†å‰²Mask â””test/ â”‚ã€€â””img/*.jpg # æµ‹è¯•å›¾ç‰‡ â”‚ã€€â””mask/*.png # æµ‹è¯•å›¾ç‰‡åˆ†å‰²Mask â””category.txt # ç±»åˆ«IDå’Œå¯¹åº”æ ‡ç­¾ï¼ˆè‹±æ–‡ï¼‰ â””train.txt # è®­ç»ƒæ•°æ®ï¼ˆå›¾ç‰‡åï¼‰ â””test.txt # æµ‹è¯•æ•°æ®ï¼ˆå›¾ç‰‡åï¼‰ ","date":"2021-01-16","objectID":"/lmsi-uec-food.html/:3:1","tags":["computer vision","dataset"],"title":"UEC food datasets","uri":"/lmsi-uec-food.html/"},{"categories":["LMSI"],"content":"å¤‡æ³¨ UECFoodPixå’ŒUECFoodPixCompleteåŒ…å«ç›¸åŒçš„å›¾åƒï¼Œä¸åŒåœ¨äºåˆ†å‰²Maskçš„ç”Ÿæˆæ–¹å¼ä¸åŒï¼ŒUECFoodPixä¸­åˆ©ç”¨Bounding Boxå’ŒGrabCutæ–¹æ³•ç”Ÿæˆåˆ†å‰²Maskï¼Œè€Œåœ¨UECFoodPixCompleteä¸­åˆ†å‰²Maskä¸ºæ‰‹å·¥æ ‡æ³¨ã€‚ å…¶ä»–é£Ÿç‰©æ•°æ®é›†è¿˜æœ‰ï¼šUNIMIB Food, Food-475, VIREO, Food-101, and Food-50ã€‚ ","date":"2021-01-16","objectID":"/lmsi-uec-food.html/:3:2","tags":["computer vision","dataset"],"title":"UEC food datasets","uri":"/lmsi-uec-food.html/"},{"categories":["LMSI"],"content":"è”ç³»æ–¹å¼ food-group@mm.cs.uec.ac.jp (Prof. Keiji Yanai) æ•°æ®ä½¿ç”¨ å¦‚æœªä½œç‰¹åˆ«è¯´æ˜ï¼Œå¤§éƒ¨åˆ†å…¬å¼€æ•°æ®é›†ä»…ä½œä¸ºç ”ç©¶ç”¨é€”ã€‚ Matsuda, Y., H. Hoashi and K. Yanai. Recognition of Multiple-Food Images by Detecting Candidate Regions. [ICME'12] â†©ï¸ Kawano, Y. and K. Yanai. Automatic Expansion of a Food Image Dataset Leveraging Existing Categories with Domain Adaptation. [ECCV'14 Workshops] â†©ï¸ Ege, Takumi, Wataru Shimoda and K. Yanai. A New Large-scale Food Image Segmentation Dataset and Its Application to Food Calorie Estimation Based on Grains of Rice. [MADiMa'19] â†©ï¸ K. Okamoto and K. Yanai: UEC-FoodPix Complete: A Large-scale Food Image Segmentation Dataset. [MADiMa'21] â†©ï¸ ","date":"2021-01-16","objectID":"/lmsi-uec-food.html/:3:3","tags":["computer vision","dataset"],"title":"UEC food datasets","uri":"/lmsi-uec-food.html/"},{"categories":["LMSI"],"content":"Mut1nyï¼šå¤´éƒ¨/é¢éƒ¨åˆ†å‰²æ•°æ®é›†1 #Segmentation å‘å¸ƒè€…ï¼šMut1ny å‘å¸ƒæ—¥æœŸï¼š2020.8 æ ·æœ¬æ•°ï¼š16557 ç±»åˆ«æ•°ï¼š11 åˆ†è¾¨ç‡ï¼š300x280 / 304x304 / 256x256 / å…¶ä»– è¯ä¹¦ï¼šCC-BY-NC-SA lmsi-1Mut1ny face-head segmentation dataset \" Mut1ny face-head segmentation dataset This new arrangement of the dataset contains over 16.5k (16557) fully pixel-level labeled segmentation images. Facial images are included from different ethnicity, ages and genders making it a well balanced dataset. Also there is a wide variety of facial poses and different camera angles to provide a good coverage from -90 to 90 degrees facing. Some images even contain multiple head/face segmentation depending on if the second or third face takes up enough screen real estate space. ","date":"2021-01-13","objectID":"/lmsi-mut1ny.html/:1:0","tags":["computer vision","dataset"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny.html/"},{"categories":["LMSI"],"content":"ç›®å½• ","date":"2021-01-13","objectID":"/lmsi-mut1ny.html/:1:1","tags":["computer vision","dataset"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny.html/"},{"categories":["LMSI"],"content":"çœŸå€¼ï¼ˆ~/labelsï¼‰ ä¸åŒç±»åˆ«çš„rgbé¢œè‰²ç¼–ç å¦‚ä¸‹ï¼š lmsi-1-figGround truth \" Ground truth ","date":"2021-01-13","objectID":"/lmsi-mut1ny.html/:1:2","tags":["computer vision","dataset"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny.html/"},{"categories":["LMSI"],"content":"å¤‡æ³¨ 2500å¼ çœŸå®å›¾åƒ (~/real_photos)ï¼Œéƒ¨åˆ†åšæ—‹è½¬å¤„ç†ï¼Œåˆ†è¾¨ç‡å¤§éƒ¨åˆ†ä¸º304x304å’Œ256x256ï¼›å…¶ä½™14057å¼ å›¾åƒç”±23ä½å¿—æ„¿è€…ï¼ˆ13ç”·+10å¥³ï¼‰çš„é¢éƒ¨åœ¨ä¸åŒèƒŒæ™¯å’Œè§’åº¦ä¸‹åˆæˆå¾—åˆ°ï¼Œåˆ†è¾¨ç‡ä¸º300x280ã€‚ ","date":"2021-01-13","objectID":"/lmsi-mut1ny.html/:1:3","tags":["computer vision","dataset"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny.html/"},{"categories":["LMSI"],"content":"é¢å¤–çš„å•†ä¸šç‰ˆæœ¬ ç›®å‰æ ‡æ³¨å¥½äº†44000å¼ å›¾åƒï¼ˆè‡³2021.1ï¼‰ï¼Œæ–°å¢äº†3ä¸ªç±»åˆ«ã€‚å¯è”ç³»å‘å¸ƒè€…æä¾›ã€‚ ","date":"2021-01-13","objectID":"/lmsi-mut1ny.html/:1:4","tags":["computer vision","dataset"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny.html/"},{"categories":["LMSI"],"content":"è”ç³»æ–¹å¼ data@mul1ny.com æ•°æ®ä½¿ç”¨ å¦‚æœªä½œç‰¹åˆ«è¯´æ˜ï¼Œå¤§éƒ¨åˆ†å…¬å¼€æ•°æ®é›†ä»…ä½œä¸ºç ”ç©¶ç”¨é€”ã€‚ https://www.mut1ny.com â†©ï¸ ","date":"2021-01-13","objectID":"/lmsi-mut1ny.html/:1:5","tags":["computer vision","dataset"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"ç‚¼ä¸¹æŠ€å·§ ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:1:0","tags":["computer vision"],"title":"è¿‘æœŸçš„æ‘¸é±¼æ‹¾ç ","uri":"/thumbbox-sundayshare.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"All in Linuxï¼šä¸€ä¸ªç®—æ³•å·¥ç¨‹å¸ˆçš„IDEæ–­å¥¶ä¹‹è·¯ åœ¨åˆæ ¼çš„ç‚¼ä¸¹å¸ˆé¢å‰ï¼Œpythonå¯èƒ½è¢«å„ç§å«Œå¼ƒâ€¦â€¦ å¤•å°ç‘¶ï¼Œå…¬ä¼—å·ï¼šå¤•å°ç‘¶çš„å–èŒå±‹ å‰æ®µæ—¶é—´åœ¨è¿œç«¯éƒ¨ç½²OCRæ¨¡å‹çš„æ—¶å€™ï¼Œå‡ åº¦è¢«æ— æ³•ä¸å¤–ç½‘æ²Ÿé€šçš„æœåŠ¡å™¨æå¾—ååˆ†æ³„æ°”ã€‚ç›´åˆ°é¡¹ç›®é˜¶æ®µæ€§åœ°å‘Šä¸€æ®µè½åæ‰çœ‹åˆ°è¿™ç¯‡æ–‡ç« ï¼ŒçœŸæ˜¯æ·±æ„Ÿç›¸è§æ¨æ™šï¼Œæ¥ä¸‹æ¥å¯ä»¥å®è·µä¸€ä¸‹äº†ã€‚ ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:1:1","tags":["computer vision"],"title":"è¿‘æœŸçš„æ‘¸é±¼æ‹¾ç ","uri":"/thumbbox-sundayshare.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"PyTorchå¸¸ç”¨ä»£ç æ®µåˆé›† æœ¬æ–‡æ˜¯PyTorchå¸¸ç”¨ä»£ç æ®µåˆé›†ï¼Œæ¶µç›–åŸºæœ¬é…ç½®ã€å¼ é‡å¤„ç†ã€æ¨¡å‹å®šä¹‰ä¸æ“ä½œã€æ•°æ®å¤„ç†ã€æ¨¡å‹è®­ç»ƒä¸æµ‹è¯•ç­‰5ä¸ªæ–¹é¢ï¼Œè¿˜ç»™å‡ºäº†å¤šä¸ªå€¼å¾—æ³¨æ„çš„Tipsï¼Œå†…å®¹éå¸¸å…¨é¢ã€‚ å…¬ä¼—å·ï¼šå¤•å°ç‘¶çš„å–èŒå±‹ ç‚¼ä¸¹å¸¸ç”¨çš„ä»£ç æ¨¡æ¿ï¼Œå¯ä»¥åœ¨æ­¤åŸºç¡€ä¸Šå†™ä¸€å¥—é€‚ç”¨è‡ªå·±çš„æ¨¡æ¿ã€‚ ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:1:2","tags":["computer vision"],"title":"è¿‘æœŸçš„æ‘¸é±¼æ‹¾ç ","uri":"/thumbbox-sundayshare.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"ä¸€æ–‡ææ‡‚ PyTorch å†…éƒ¨æœºåˆ¶ è¿™ç¯‡åšæ–‡æ˜¯ä¸€ç¯‡éå¸¸æ–°çš„ä»‹ç»PyTorchå†…éƒ¨æœºåˆ¶çš„æ–‡ç« ï¼Œä½œè€…Edward Z Yangæ¥è‡ªäºStanfordå¤§å­¦ï¼Œæ˜¯PyTorchçš„æ ¸å¿ƒå¼€å‘è€…ä¹‹ä¸€ã€‚æ–‡ç« ä¸­ä»‹ç»äº†å¦‚ä½•é˜…è¯»PyTorchæºç å’Œæ‰©å±•PyTorchçš„æŠ€å·§ã€‚ ArchWalkerï¼Œå…¬ä¼—å·ï¼šå¤•å°ç‘¶çš„å–èŒå±‹ è¿™æ˜¯ä¸€ç¯‡å¥½çœ‹çš„ç¿»è¯‘æ–‡ç« ï¼Œå¯¹äºäº†è§£PyTorchåº•å±‚çš„ä¸€äº›åŸç†å¾ˆæœ‰å¸®åŠ©1ã€‚ ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:1:3","tags":["computer vision"],"title":"è¿‘æœŸçš„æ‘¸é±¼æ‹¾ç ","uri":"/thumbbox-sundayshare.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"AIè¯†åˆ«å½»åº•æ‡µé€¼ï¼Œè¿™åˆ°åº•æ˜¯ã€Œç‰›ã€è¿˜æ˜¯ã€Œé²¨ã€ï¼Ÿ æˆ‘å’Œç¼–è¾‘éƒ¨çš„åŒäº‹å› ä¸ºä¸Šå›¾åˆ°åº•æ˜¯ç‰›è¿˜æ˜¯é²¨åµäº†èµ·æ¥å›¾ç‰‡ï¼Œæˆ‘è¯´è¿™å¼ å›¾æ›´åƒå›¾ç‰‡ï¼ŒåŒäº‹è¯´æ›´åƒå›¾ç‰‡ï¼Œæˆ‘ä»¬å·®ç‚¹å„¿å°±GANäº†ä¸€æ¶ï¼ è€³æ´æ‰“ä¸‰é‡‘ï¼Œå…¬ä¼—å·ï¼šAIç§‘æŠ€è¯„è®º å…³äºæ˜¯ç‰›è¿˜æ˜¯é²¨çš„GANæ¶æ–‡ç« ï¼Œæ•…äº‹å‘Šè¯‰äº†æˆ‘ä»¬äººçš„è§†è§‰å’Œæœºå™¨è¯†åˆ«æ¨¡å‹å­˜åœ¨çš„ä¸€äº›è®¤çŸ¥å·®å¼‚ã€‚ ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:1:4","tags":["computer vision"],"title":"è¿‘æœŸçš„æ‘¸é±¼æ‹¾ç ","uri":"/thumbbox-sundayshare.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"å°ç¨‹åº ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:2:0","tags":["computer vision"],"title":"è¿‘æœŸçš„æ‘¸é±¼æ‹¾ç ","uri":"/thumbbox-sundayshare.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"GeoPattern ç”¨ä¸€ä¸ªå­—ç¬¦ä¸²ç”ŸæˆSVGæ ¼å¼çš„å›¾æ¡ˆï¼Œæä¾›äº†å¤šç§è¯­è¨€çš„å®ç°æ–¹å¼ã€‚ç”¨åˆ°äº†SHAç®—æ³•ï¼Œå…·ä½“å®ç°è¿˜éœ€è¦å†è¯»ä¸€è¯»æºç ã€‚å“¦ï¼æƒ³èµ·æ¥æœ¬å‘¨OpenAIæå…¶å¯çˆ±çš„Dall-Eé¡¹ç›®â€”â€”ç”¨ä¸€ä¸²æ–‡æœ¬ç”Ÿæˆç¬¦åˆæè¿°çš„å›¾ç‰‡ï¼Œå¤§ä½¬ä»¬ç”¨PyTorchçš„å¤ç°ä¹Ÿæ­£åœ¨è·¯ä¸Šï¼Œæœ‰ç©ºå¯ä»¥ç©ä¸€ç©ã€‚ ä¸¾å‡ ä¸ªGeoPatternçš„æ —å­ï¼š GeoPattern examples\" GeoPattern examples å†ä¸¾ä¸€ä¸ªDall-Eçš„æ —å­ï¼š Dall-E examples \" Dall-E examples ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:2:1","tags":["computer vision"],"title":"è¿‘æœŸçš„æ‘¸é±¼æ‹¾ç ","uri":"/thumbbox-sundayshare.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"EDA (Easy Data Augmentation) æœ€è¿‘åœ¨è®­ç»ƒæ–‡æœ¬è¯†åˆ«æ¨¡å‹çš„æ—¶å€™ï¼Œé‡åˆ°äº†ä¸­æ–‡è¯­æ–™ä¸è¶³çš„é—®é¢˜ï¼Œæƒ³åˆ°å¯ä»¥å¯¹ç°æœ‰çš„è¯­æ–™åº“åšæ•°æ®å¢å¼ºï¼Œäºæ˜¯å‘ç°äº†è¿™ç¯‡åº”ç”¨äºæ–‡æœ¬åˆ†ç±»çš„æ•°æ®å¢å¼ºè®ºæ–‡â€”â€”EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasksã€‚å…¶ä¸­çš„ç®—æ³•æ€æƒ³å¾ˆæœ´ç´ ï¼Œä½œè€…æå‡ºäº†å››ç§åœ¨åŸå¥å­åŸºç¡€ä¸Šè¿›è¡Œè°ƒæ•´çš„æ“ä½œï¼šéšæœºæ’å…¥ã€éšæœºåˆ é™¤ã€éšæœºäº¤æ¢å’ŒåŒä¹‰è¯æ›¿æ¢ï¼Œåˆ©ç”¨è¿™ç§æ•°æ®å¢å¼ºçš„æ–¹æ³•å¯ä»¥åœ¨åŸæ¨¡å‹åŸºç¡€ä¸Šæé«˜æ–‡æœ¬åˆ†ç±»çš„å‡†ç¡®ç‡ã€‚ ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:2:2","tags":["computer vision"],"title":"è¿‘æœŸçš„æ‘¸é±¼æ‹¾ç ","uri":"/thumbbox-sundayshare.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"ä¹¦ç± ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:3:0","tags":["computer vision"],"title":"è¿‘æœŸçš„æ‘¸é±¼æ‹¾ç ","uri":"/thumbbox-sundayshare.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Kubernetes in Action ä¸­æ–‡ç‰ˆ ç”±ä¸ƒç‰›å®¹å™¨äº‘å›¢é˜Ÿç¿»è¯‘ã€‚æœ€è¿‘åœ¨è¯»ï¼Œä½œä¸ºK8sçš„å…¥é—¨è®²å¾—é’ˆä¸æˆ³ã€‚ ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:3:1","tags":["computer vision"],"title":"è¿‘æœŸçš„æ‘¸é±¼æ‹¾ç ","uri":"/thumbbox-sundayshare.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Google Python Style Guide è‹±æ–‡ ä¸­æ–‡ ç‹—å®¶ä¹Ÿæä¾›å…¶ä»–è¯­è¨€çš„styleguideå¯ä»¥å‚è€ƒã€‚åœ¨å›¢é˜Ÿåä½œçš„å·¥ç¨‹é¡¹ç›®ä¸­æŠŠä»£ç å†™è§„èŒƒè¿˜æ˜¯å¾ˆé‡è¦çš„ï¼Œå¸Œæœ›äººäººéƒ½å¯ä»¥çŒ®å‡ºä¸€ä»½çˆ±ï¼Œä¸–ç•Œå°†å……æ»¡æ›´å¤šæ¯›ç»’ç»’çš„å¤´å‘ã€‚ åŸæ–‡é“¾æ¥ï¼šhttp://blog.ezyang.com/2019/05/pytorch-internals/ â†©ï¸ ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:3:2","tags":["computer vision"],"title":"è¿‘æœŸçš„æ‘¸é±¼æ‹¾ç ","uri":"/thumbbox-sundayshare.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Introduction ","date":"2020-11-10","objectID":"/thumbbox2.html/:1:0","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Basic pipeline Detection+Recognition End-to-end image-20201107140006891fig1 \" fig1 ","date":"2020-11-10","objectID":"/thumbbox2.html/:1:1","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Challenges for general text detection and recognition Diversity and variability different languages/color/fonts/size/orientations/shapes Complexity and interference of background similar patterns/occlusions Imperfect image conditions Low resolution/shot angle/blurred(unfocused)/noise/light ","date":"2020-11-10","objectID":"/thumbbox2.html/:1:2","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Methods before DL ","date":"2020-11-10","objectID":"/thumbbox2.html/:2:0","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Text detection CCA (Connected Components Analysis)ï¼šè¿é€šåŸŸåˆ†ææ³• æå–å‡ºåŒ…å«æ–‡æœ¬çš„å€™é€‰åŒºåŸŸï¼ˆcolor clustering/extreme region extrationï¼‰ ä»å€™é€‰åŒºåŸŸä¸­è¿‡æ»¤èƒŒæ™¯ï¼Œå³åˆ†å‰²å‡ºæ–‡æœ¬ç±»ï¼ˆç‰¹å¾æå–ï¼Œåˆ†ç±»/åˆ†å‰²ï¼‰ ç‰¹å¾ï¼šMSRE/SWT/SIFT/SURF/LBP/ç°åº¦å…±ç”ŸçŸ©é˜µç­‰ åˆ†ç±»å™¨ï¼šKmeans/KNN/SVM/NN/DecisionTreeç­‰ Huang et al., 2013; Neumann and Matas, 2010; Epshtein et al., 2010; Tu et al., 2012; Yin et al., 2014; Yi and Tian, 2011; Jain and Yu, 1998 SW (Siliding window)ï¼šæ»‘åŠ¨çª—å£æ³• åˆ©ç”¨ä¸åŒå¤§å°çš„æ»‘åŠ¨çª—å£å¯¹çª—å£åŒºåŸŸè¿›è¡ŒäºŒåˆ†ç±»ï¼ˆåŒ…å«/ä¸åŒ…å«æ–‡æœ¬ï¼‰ é€šè¿‡å½¢æ€å­¦æ“ä½œ/CRF/Graph-based-methodç­‰å¯¹çª—å£è¿›è¡Œåˆå¹¶ Lee et al., 2011; Wang et al., 2011; Coates et al., 2011; Wang et al., 2012 ","date":"2020-11-10","objectID":"/thumbbox2.html/:2:1","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Text recognition åŸºäºç‰¹å¾çš„æ–¹æ³• åˆ’åˆ†å­é—®é¢˜ äºŒå€¼åŒ–(text binarization)-\u003eæ–‡æœ¬è¡Œåˆ‡åˆ†(text line segmentation)-\u003eå­—ç¬¦åˆ’åˆ†(character segmentation)-\u003eå•å­—ç¬¦è¯†åˆ«(single character recognition)-\u003eå•è¯æ ¡æ­£(word correction) feature-based: Shi et al., 2013; Yao et al., 2014; Rodriguez-Serrano et al., 2013, 2015; Gordo, 2015; Almazan et al., 2014 text binarization: Zhiwei et al., 2010; Mishra et al., 2011; Wakahara and Kita, 2011; Lee and Kim, 2013 text line segmentation: Ye et al., 2003 character segmentation: Nomura et al., 2005; Shivakumara et al., 2011; Roy et al., 2009 single character recognition: Chen et al., 2004; Sheshadri and Divvala, 2012 word correction: Zhang and Chang, 2003; Wachenfeld et al., 2006; Mishra et al., 2012; Karatzas and Antonacopoulos, 2004; Weinman et al., 2007 ","date":"2020-11-10","objectID":"/thumbbox2.html/:2:2","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"End-to-end (detection+recognition) Wang et al., 2011ï¼šnearest-neighbor classifier+HoG Neumann and Matas, 2013ï¼šdecision delay ap- proach+dynamic programming algorithm Wang et al., 2011; Neumann and Matas, 2013 ","date":"2020-11-10","objectID":"/thumbbox2.html/:2:3","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Methods based on DL ","date":"2020-11-10","objectID":"/thumbbox2.html/:3:0","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Text detection æ—©æœŸå°è¯• åŸºäºç›®æ ‡æ£€æµ‹çš„æ–¹æ³• Anchor-based TextBoxes (Liao et al., 2017)ï¼šanchor-based, SSD [code] EAST (Zhou et al., 2017)ï¼šanchor-based, u-net, simple pipeline and real-time speed [code] Region proposal Ma et al., 2017: solve text of arbitrary orientations [code] FEN (Zhang et al., 2018) Specific task/case (w/o sub-text) ITN (Wang et al., 2018): multi-orientated text [code] Zhang et al., 2019: irregular text Wang et al., 2019b: irregular text Sub-text components: better flexibility over shapes and aspect ratios of text Use NN to predict local attributes or segments Post-processing to re-construct text instance Pixel level PixelLink (Deng et al., 2018) [code] Border learning method (Wu and Natarajan, 2017) Component-level CTPN (Tian et al., 2016) [code] SegLink (Shi et al., 2017a) [code] Corner Localization (Lyu et al., 2018b) TextSnake (Long et., 2018) Character-level Braek et al., 2019b ","date":"2020-11-10","objectID":"/thumbbox2.html/:3:1","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Text recognition image-20201107191619556fig2 \" fig2 CTC-based (Connectionist Temporal Classificationï¼Œä¸€ç§æ—¶åºåˆ†ç±»ç®—æ³•) (CNN+RNN+CTC) CNN layerï¼šCNN Encoderæå–æ–‡æœ¬å›¾åƒç‰¹å¾ï¼Œå½¢æˆè‹¥å¹²ç‰¹å¾åºåˆ— RNN layerï¼šRNNè¿›ä¸€æ­¥æå–æ–‡æœ¬åºåˆ—ç‰¹å¾ Transcription layer (CTC loss)ï¼šCTCè§£å†³å­—ç¬¦å¯¹é½é—®é¢˜ CRNN (Shi et al., 2017b) [code] DTRN (He et al., 2016) Gao et al., 2017 Yin er al., 2017 Encoder-Decoder (CNN+Seq2Seq+Attention) CNN layerï¼šCNN Encoderæå–æ–‡æœ¬å›¾åƒç‰¹å¾ï¼Œå½¢æˆè‹¥å¹²ç‰¹å¾åºåˆ— Seq2Seq+Attentionï¼šå¥½å¤„æ˜¯è¾“å‡ºå‘é‡é•¿åº¦å¯ä»¥ä¸è¾“å…¥ä¸åŒ Transcription layer (Classification loss) Lee and Osindero, 2016 Cheng et al., 2018 Bai et al., 2018 Liu et al., 2018d Irregular text Case ","date":"2020-11-10","objectID":"/thumbbox2.html/:3:2","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"End-to-end (Detection+Recognition/Text Spotting) Two-stage pipeline: feature map instead of images are cropped and fed to recognition module SEE (Bartz et al., 2017) [code] Busta et al., 2017 [code] Li et al., 2017a He et al., 2018 Liu et al., 2018c One-stage pipeline: predict character and text bounding boxes as well as character type segmentation maps in parallel Xing et al., 2019 ","date":"2020-11-10","objectID":"/thumbbox2.html/:3:3","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Auxiliary techniques that support detection and recognition Synthetic Data Weakly and Semi-Supervision More paper reference https://github.com/Jyouhou/SceneTextPapers ","date":"2020-11-10","objectID":"/thumbbox2.html/:3:4","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Datasets image-20201107191949977 \" image-20201107191949977 Dataset (Year) Image Num (train/test) Text Num (train/test) Orientation Language Characteristics Detec/Recog Task End2End ==== ==== ==== ==== ==== ==== ICDAR03 (2003) 509 (258/251) 2276 (1110/1156) Horizontal EN - âœ“/âœ“ ICDAR13 Scene Text(2013) 462 (229/233) - (848/1095) Horizontal EN - âœ“/âœ“ ICDAR15 Incidental Text(2015) 1500 (1000/500) - (-/-) Multi-Oriented EN Blur, Small, Defocused âœ“/âœ“ ICDAR17 / RCTW (2017) 12263 (8034/4229) - (-/-) Multi-Oriented CN - âœ“/âœ“ Total-Text (2017) 1555 (1255/300) - (-/-) Multi-Oriented, Curved EN, CN Irregular polygon label âœ“/âœ“ SVT (2010) 350 (100/250) 904 (257/647) Horizontal EN - âœ“/âœ“ KAIST (2010) 3000 (-/-) 5000 (-/-) Horizontal EN, KO Distorted âœ“/âœ“ NEOCR (2011) 659 (-/-) 5238 (-/-) Multi-oriented 8 langs - âœ“/âœ“ CUTE (2014) or here 80 (-/80) - (-/-) Curved EN - âœ“/âœ“ CTW (2017) 32K ( 25K/6K) 1M ( 812K/205K) Multi-Oriented CN Fine-grained annotation âœ“/âœ“ CASIA-10K (2018) 10K (7K/3K) - (-/-) Multi-Oriented CN âœ“/âœ“ Detection Only ==== ==== ==== ==== ==== ==== OSTD (2011) 89 (-/-) 218 (-/-) Multi-oriented EN - âœ“/- MSRA-TD500 (2012) 500 (300/200) 1719 (1068/651) Multi-Oriented EN, CN Long text âœ“/- HUST-TR400 (2014) 400 (400/-) - (-/-) Multi-Oriented EN, CN Long text âœ“/- ICDAR17 / RRC-MLT (2017) 18000 (9000/9000) - (-/-) Multi-Oriented 9 langs - âœ“/- CTW1500 (2017) 1500 (1000/500) - (-/-) Multi-Oriented, Curved EN Bounding box with_14_ vertexes âœ“/- Recognition Only ==== ==== ==== ==== ==== ==== Char74k (2009) 74107 (-/-) 74107 (-/-) Horizontal EN, Kannada Character label -/âœ“ IIIT 5K-Word (2012) 5000 (-/-) 5000 (2000/3000) Horizontal - cropped -/âœ“ SVHN (2010) - (-/-) 600000 (-/-) Horizontal - House number digits -/âœ“ SVTP (2013) 639 (-/639) - (-/-) EN Distorted -/âœ“ ","date":"2020-11-10","objectID":"/thumbbox2.html/:4:0","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Evaluation ","date":"2020-11-10","objectID":"/thumbbox2.html/:5:0","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Detection Metrics Precision ($P$): the proportion of predicted text instances that can be matched to gt labels. Recall ($R$): the porportion of gt labels that have correspondents in the predicted list. F1-Score $$ F_1 = \\frac{2PR}{P+R} $$ And others ","date":"2020-11-10","objectID":"/thumbbox2.html/:5:1","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Recognition Metrics Character-level(#characters are recognized)/word level(whether the predicted word exactly the same as gt) image-20201108160251229 \" image-20201108160251229 ","date":"2020-11-10","objectID":"/thumbbox2.html/:5:2","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Applications Automatic Data Entry Identity Authentication Augmented Computer Vision Intelligence Content Analysis ","date":"2020-11-10","objectID":"/thumbbox2.html/:6:0","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"Reference CRNN+CTCæ–‡å­—è¯†åˆ« CTPNåŸç†ä¸å®ç° å®Œå…¨è§£æRNN, Seq2Seq, Attentionæ³¨æ„åŠ›æœºåˆ¶ ","date":"2020-11-10","objectID":"/thumbbox2.html/:7:0","tags":["computer vision","ocr","paper"],"title":"æ—·è§†æ–‡æœ¬æ£€æµ‹ä¸è¯†åˆ«ç»¼è¿°ç¬”è®°","uri":"/thumbbox2.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":" æœ€è¿‘åœ¨è¯»å°¤ç“¦å°”.èµ«æ‹‰åˆ©çš„ã€Šäººç±»ç®€å²ï¼šä»åŠ¨ç‰©åˆ°ä¸Šå¸ã€‹ã€‚ä¹¦ä¸­ä½œè€…ç”¨æ¯”è¾ƒå®è§‚å’Œç‹¬åˆ°çš„è§‚ç‚¹ä»‹ç»äº†äººç±»å†å²è¿›ç¨‹ä¸­çš„ä¸‰åœºé‡è¦é©å‘½ï¼šè®¤çŸ¥é©å‘½ï¼ˆCognitive Revolutionï¼‰ã€å†œä¸šé©å‘½ï¼ˆAgricultural Revolutionï¼‰å’Œç§‘å­¦é©å‘½ï¼ˆScientific Revolutionï¼‰ã€‚ä»¥ä¸‹æ‘˜å½•å¹¶æ€»ç»“ä¸€äº›è‡ªå·±è®¤ä¸ºæœ‰è¶£çš„è§‚ç‚¹ã€‚ ","date":"2020-10-11","objectID":"/thumbbox1.html/:0:0","tags":["å†å²"],"title":"äººç±»ç®€å²ï¼Œä¸€äº›æœ‰è¶£çš„è§‚ç‚¹ï¼ˆå…¶ä¸€ï¼‰","uri":"/thumbbox1.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"å…«å¦å’Œè™šæ„æ•…äº‹ä½¿å¤§è§„æ¨¡çš„æœ‰åºåˆä½œæˆä¸ºå¯èƒ½ æ™ºäººæ˜¯ä¸€ç§ç¤¾ä¼šæ€§çš„åŠ¨ç‰©ï¼Œç¤¾ä¼šåˆä½œæ˜¯æˆ‘ä»¬å¾—ä»¥ç”Ÿå­˜å’Œç¹è¡çš„å…³é”®ã€‚ æ—©æœŸå½¢æˆçš„äº²è¿‘å°å›¢ä½“ä¸­ï¼Œæ™ºäººä¸å…¶ä»–ç”Ÿç‰©æ²¡ä»€ä¹ˆä¸åŒã€‚äººä»¬éœ€è¦ååˆ†äº†è§£å½¼æ­¤ï¼Œæ‰æœ‰å¯èƒ½è¿›è¡Œåˆ†å·¥åˆä½œã€‚ä¸€æ—¦å›¢ä½“è¿‡å¤§ï¼Œç¤¾äº¤ç§©åºå°±ä¼šå´©åï¼Œå›¢ä½“å°±ä¼šåˆ†è£‚ã€‚ç”¨å…³ç³»å›¾æ¨¡å‹æ¥åšç±»æ¯”çš„è¯ï¼Œæ¯ä¸ªä¸ªä½“èŠ‚ç‚¹éœ€è¦ä¸å…¶ä»–ä¸ªä½“èŠ‚ç‚¹éƒ½æœ‰è”ç³»ï¼Œæ‰ä¼šå½¢æˆåˆä½œã€‚ è®¤çŸ¥é©å‘½ä»¥åï¼Œæ™ºäººå‘å±•å‡ºäº†â€œå…«å¦â€è¿™ç§èƒ½åŠ›â€”â€”å³äººä»¬èƒ½å¤Ÿåœ¨å½¼æ­¤èƒŒåâ€œè¯´åè¯â€è¾¾æ•°å°æ—¶ä¹‹ä¹…ã€‚è¿™ç§èƒ½åŠ›æœ¬è´¨ä¸Šä¿ƒè¿›äº†æ›´é«˜æ•ˆä¿¡æ¯çš„äº¤æ¢å’Œä¼ æ’­ï¼Œè€Œå€Ÿç”±å…«å¦æ¥ç»´æŒçš„æœ€å¤§â€œè‡ªç„¶â€å›¢ä½“äººæ•°å¤§çº¦æ˜¯150äººã€‚åœ¨è¿™ç§å…³ç³»å›¾ä¸­ï¼Œæ¯ä¸ªä¸ªä½“èŠ‚ç‚¹åªè¦åŒå±äºä¸€ä¸ªè¿é€šåŸŸä¸­ï¼Œå°±èƒ½è¿›è¡Œä¿¡æ¯ä¼ é€’ï¼Œå½¢æˆåˆä½œã€‚ ä¹‹åï¼Œæ™ºäººåˆé€†å¤©åœ°å‘æ˜äº†â€œè™šæ‹Ÿæ•…äº‹â€ï¼Œä½¿å¾—å³ä½¿æ˜¯äº’ç›¸ä¸è®¤è¯†çš„é™Œç”Ÿäººï¼Œåªè¦ç›¸ä¿¡è¿™ä¸ªâ€œè™šæ‹Ÿæ•…äº‹â€ï¼Œå°±èƒ½å½¢æˆå…±åŒåˆä½œã€‚è¿™ç§â€œè™šæ‹Ÿæ•…äº‹â€ä½¿å¾—å›¢ä½“çš„è§„æ¨¡ç©ºå‰æ‰©å¤§ï¼Œåˆä½œè¶‹äºæœ‰åºã€ç²¾ç»†å’Œä¸“ä¸šåŒ–ã€‚ç¥ã€å›½å®¶ã€å…¬å¸ã€æ³•å¾‹ç­‰ç­‰è¿™äº›æ¦‚å¿µæ‰€å½¢æˆçš„æ•…äº‹ç½‘ç»œï¼Œç›´è‡³ä»Šæ—¥æ—©å·²æ„å»ºå‡ºäº†ä¸€ä¸ªâ€œè™šæ‹Ÿä¸–ç•Œâ€ã€‚åœ¨è¿™ç§å…³ç³»å›¾ä¸­ï¼Œâ€œæ•…äº‹â€é€šè¿‡å½“æ—¶æœ€å…ˆè¿›çš„åª’ä»‹è¿›è¡Œä¼ æ’­ï¼Œåœ¨å¯è¾¾èŒƒå›´å†…çš„æ‰€æœ‰ä¸ªä½“èŠ‚ç‚¹åªè¦ç›¸ä¿¡è¿™ä¸ªæ•…äº‹ä¸ºçœŸï¼Œå°±å¯ä»¥ä¸å…¶ä»–åŒç±»ä¸ªä½“èŠ‚ç‚¹å½¢æˆåˆä½œäº¤äº’ã€‚ ","date":"2020-10-11","objectID":"/thumbbox1.html/:1:0","tags":["å†å²"],"title":"äººç±»ç®€å²ï¼Œä¸€äº›æœ‰è¶£çš„è§‚ç‚¹ï¼ˆå…¶ä¸€ï¼‰","uri":"/thumbbox1.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"äººç±»å‘æ˜äº†å®ƒï¼Œä¹Ÿè¢«å®ƒé©¯åŒ– ","date":"2020-10-11","objectID":"/thumbbox1.html/:2:0","tags":["å†å²"],"title":"äººç±»ç®€å²ï¼Œä¸€äº›æœ‰è¶£çš„è§‚ç‚¹ï¼ˆå…¶ä¸€ï¼‰","uri":"/thumbbox1.html/"},{"categories":["æ‹‡æŒ‡ç›’"],"content":"å†œä¸šé©å‘½ï¼ˆP2C5ï¼‰ å†œä¸šé©å‘½ç¡®å®å…»æ´»äº†æ›´å¤šäººå’ŒåŠ¨æ¤ç‰©ï¼Œå®ç°äº†æ¼”åŒ–æ„ä¹‰ä¸Šçš„æˆåŠŸï¼Œä¹Ÿä¸ºå†œæ°‘å¸¦äº†ä¸€å®šçš„åˆ©ç›Šã€‚ä½†ä½œè€…åœ¨ä¹¦ä¸­æåˆ°ï¼Œå†œä¸šé©å‘½æ˜¯å²ä¸Šæœ€å¤§çš„ä¸€æ¡©éª—å±€ï¼Œå®ƒæœ¬è´¨ä¸Šè®©æ›´å¤šçš„äººä»¥æ›´ç³Ÿçš„çŠ¶å†µæ´»ä¸‹å»ã€‚ä¸»è¦å½±å“æœ‰å‡ ä¸ªï¼š äººç±»çš„èº«ä½“æ¼”åŒ–ç›®çš„å¹¶ä¸æ˜¯è®©æˆ‘ä»¬å»å¼¯è…°æ¸…çŸ³å—ã€åŠªåŠ›æŒ‘æ°´æ¡¶çš„ï¼Œé€‚åº”è¿™äº›æ´»åŠ¨è®©äººç±»ä»˜å‡ºäº†è¯¸å¦‚æ¤é—´ç›˜çªå‡ºã€å…³èŠ‚ç‚å’Œç–æ°”ç­‰ç–¾ç—…ä»£ä»·ï¼› äººç±»çš„æ´»åŠ¨èŒƒå›´æ›´åŠ èšé›†ï¼Œäººå£å¢åŠ ã€èšè½å¯†åº¦ä¹Ÿéšä¹‹å¢å¤§ï¼Œå¯¼è‡´ä¼ æŸ“ç—…æ›´å®¹æ˜“æ»‹ç”Ÿå’Œæ‰©æ•£ï¼› äººç±»çš„é¥®é£Ÿæ›´åŠ å•ä¸€åŒ–ã€‚è°·ç‰©ä½œä¸ºä¸»é£Ÿä¸ä»…çŸ¿ç‰©è´¨å’Œç»´ç”Ÿç´ å«é‡ä¸è¶³ã€éš¾ä»¥æ¶ˆåŒ–ï¼Œè¿˜å¯¹ç‰™é½¿å’Œç‰™é¾ˆå¤§å¤§æœ‰å®³ï¼› äººç±»è¶Šæ¥è¶Šä¾èµ–äºä¸€æ–¹ä¹‹åœŸã€‚åœ¨æˆ˜äº‰æš´åŠ›å’Œè‡ªç„¶ç¾å®³é¢å‰ï¼Œäººä»¬æˆ–æ­»å®ˆç”°åœ°ï¼Œæˆ–å¿é¥¥æŒ¨é¥¿ï¼Œå¯¹äºæœªæ¥çš„å¿§è™‘ä¹Ÿè¿›ä¸€æ­¥åŠ æ·±ã€‚ å†œä¸šé©å‘½è±¢å…»äº†ä¸€ç¾¤å…»å°Šå¤„ä¼˜ï¼Œå¨‡ç”Ÿæƒ¯å…»çš„ç²¾è‹±åˆ†å­ï¼› å†œä¸šé©å‘½ä½¿äººç±»å¼€å§‹è½å…¥å¥¢ä¾ˆç”Ÿæ´»çš„é™·é˜±ã€‚æƒ³è®©ç”Ÿæ´»å˜å¾—è½»æ¾çš„åŠªåŠ›ï¼Œåè€Œç»™äººå¸¦æ¥æ— ç©·çš„éº»çƒ¦ï¼ˆå¦‚åŠ³å¿ƒåŠ³åŠ›åœ°å·¥ä½œã€ç”Ÿæ´»ç„¦è™‘ç­‰ï¼‰ï¼› æ€»ä½“æ¥çœ‹ï¼Œå†œä¸šé©å‘½ä¹Ÿä½¿é‚£äº›è¢«é©¯å…»çš„åŠ¨æ¤ç‰©æˆäº†å—å®³è€…ã€‚é¸¡é¸­ç‰›ç¾Šå’Œå°éº¦ä»¬è™½ç„¶ä¾é äººç±»éå¸ƒäº†æ•´ä¸ªä¸–ç•Œï¼Œä½†æ˜¯å®ƒä»¬æˆ–è®¸ä¹Ÿä¼šæƒ³ï¼šæˆ‘å®æ„¿æˆä¸ºæ¿’å±è€Œè‡ªç”±çš„ä¸ªä½“ï¼Œä¹Ÿä¸è¦åšäº¤æ˜“ä¸ä¾›å…»çš„å¥´éš¶ã€‚ â€äººç±»ä»¥ä¸ºè‡ªå·±é©¯åŒ–äº†æ¤ç‰©ï¼Œä½†å…¶å®æ˜¯æ¤ç‰©é©¯åŒ–äº†æ™ºäººã€‚â€œ æƒ³è±¡çš„ç§©åºï¼ˆP2C6ï¼‰ â€œæƒ³è±¡æ„å»ºçš„ç§©åºå¡‘é€ äº†æˆ‘ä»¬çš„æ¬²æœ›ï¼Œè€Œä¸ªäººæ¬²æœ›æˆäº†è™šæ„ç§©åºæœ€å¼ºå¤§çš„å®ˆæŠ¤è€…ã€‚â€ â€œä¾‹å¦‚ï¼Œæµªæ¼«ä¸»ä¹‰å‘Šè¯‰æˆ‘ä»¬ï¼Œä¸ºäº†è¦å°½é‡å‘æŒ¥æ½œåŠ›ï¼Œå°±å¿…é¡»å°½é‡ç´¯ç§¯ä¸åŒçš„ç»éªŒã€‚å¿…é¡»ä½“ä¼šä¸åŒçš„æƒ…æ„Ÿï¼Œå°è¯•ä¸åŒçš„å…³ç³»ï¼Œå“å°ä¸åŒçš„ç¾é£Ÿï¼Œè¿˜å¿…é¡»å­¦ä¼šæ¬£èµä¸åŒé£æ ¼çš„éŸ³ä¹ã€‚è€Œå…¶ä¸­æœ€å¥½çš„ä¸€ç§åŠæ³•ï¼Œå°±æ˜¯æ‘†è„±æ—¥å¸¸ç”Ÿæ´»åŠå·¥ä½œï¼Œè¿œç¦»ç†Ÿæ‚‰çš„ç¯å¢ƒï¼Œå‰å¾€é¥è¿œçš„å›½åº¦ï¼Œå¥½äº²èº«â€˜ä½“éªŒâ€™ä¸åŒçš„æ–‡åŒ–ã€æ°”å‘³ã€ç¾é£Ÿå’Œè§„èŒƒï¼›æ¶ˆè´¹ä¸»ä¹‰å‘Šè¯‰æˆ‘ä»¬ï¼Œæƒ³è¦å¿«ä¹ï¼Œå°±è¯¥å»ä¹°æ›´å¤šçš„äº§å“ã€æ›´å¤šçš„æœåŠ¡ã€‚å¦‚æœè§‰å¾—å°‘äº†ä»€ä¹ˆï¼Œæˆ–è€…æœ‰ä»€ä¹ˆä¸å¤Ÿèˆ’æœçš„åœ°æ–¹ï¼Œé‚£å¾ˆå¯èƒ½æ˜¯è¯¥ä¹°äº›ä»€ä¹ˆå•†å“ï¼ˆæ–°è½¦ã€æ–°è¡£æœã€æœ‰æœºé£Ÿå“ï¼‰ï¼Œæˆ–ä¹°ç‚¹ä»€ä¹ˆæœåŠ¡ï¼ˆæ¸…æ´å·¥ã€å¿ƒç†å’¨è¯¢ã€ç‘œä¼½è¯¾ï¼‰ã€‚â€ â€œä¸€å¦‚å¤åŸƒåŠç²¾è‹±åˆ†å­ï¼Œç°åœ¨å¤§å¤šæ•°äººä¸€ç”Ÿæ±²æ±²è¥è¥ï¼Œä¹Ÿéƒ½æ˜¯æƒ³ç›–èµ·æŸç§é‡‘å­—å¡”ï¼Œåªä¸è¿‡è¿™äº›é‡‘å­—å¡”åœ¨ä¸åŒæ–‡åŒ–é‡Œä¼šæœ‰ä¸åŒçš„åå­—ã€å½¢ä½“å’Œè§„æ¨¡ç½¢äº†ã€‚â€ â€œèº«ä¸ºäººç±»ï¼Œæˆ‘ä»¬ä¸å¯èƒ½è„±ç¦»æƒ³è±¡æ‰€æ„å»ºå‡ºçš„ç§©åºã€‚æ¯ä¸€æ¬¡æˆ‘ä»¬ä»¥ä¸ºè‡ªå·±æ‰“ç ´äº†ç›‘ç‹±çš„é«˜å¢™ã€è¿ˆå‘è‡ªç”±çš„å‰æ–¹ï¼Œå…¶å®åªæ˜¯åˆ°äº†å¦ä¸€ä»¶æ›´å¤§çš„ç›‘ç‹±ï¼ŒæŠŠæ´»åŠ¨èŒƒå›´ç¨ç¨åŠ ä»¥æ‰©å¤§è€Œå·²ã€‚â€ æ–‡å­—ä¸è®¡ç®—æœºï¼ˆP2C7ï¼‰ æ–‡å­—ä¸è®¡ç®—æœºçš„å‘æ˜æ˜¯å¯¹äººè„‘å­˜å‚¨çš„å¢å¼ºï¼Œä½†å®ƒåœ¨æŸç§ç¨‹åº¦ä¸Šä¹Ÿæ”¹å˜äº†äººç±»çš„æ€ç»´å’Œçœ‹å¾…è¿™ä¸ªä¸–ç•Œçš„æ–¹å¼ã€‚è¿™ç§æ”¹å˜å¾ˆå¤§ç¨‹åº¦ä¸Šæºäºæ–‡å­—å’Œè®¡ç®—æœºç³»ç»Ÿçš„å½’æ¡£ã€ç¼–ç›®å’Œæ£€ç´¢æŠ€æœ¯ï¼Œè¿™ä¸æˆ‘ä»¬å¤§è„‘åŸæœ¬å†…å»ºæœºåˆ¶éå¸¸ä¸åŒã€‚ â€œåœ¨å¤§è„‘é‡Œï¼Œæ‰€æœ‰éƒ½è‡ªç”±åœ°äº’ç›¸è¿æ¥ã€‚æ¯”å¦‚æˆ‘åœ¨å’Œå¦ä¸€åŠä¸€èµ·å»åŠæ–°å®¶æŠµæŠ¼è´·æ¬¾çš„æ—¶å€™ï¼Œå°±æƒ³åˆ°æˆ‘ä»¬ä¸€èµ·ä½çš„ç¬¬ä¸€ä¸ªåœ°æ–¹ï¼Œè¿™åˆè®©æˆ‘æƒ³åˆ°å»æ–°å¥¥å°”è‰¯åº¦çš„èœœæœˆï¼Œå†æƒ³åˆ°é³„é±¼ï¼Œå†æƒ³åˆ°è¥¿æ–¹çš„æ¶é¾™ï¼Œå†æƒ³åˆ°æ­Œå‰§ã€Šå°¼å¸ƒé¾™æ ¹çš„æŒ‡ç¯ã€‹ï¼›ç»“æœæˆ‘ä¸çŸ¥ä¸è§‰å°±å“¼èµ·äº†æ­Œå‰§é‡Œé¢é½æ ¼é£çš„ä¸»æ—‹å¾‹ï¼ŒæŠŠé“¶è¡ŒèŒå‘˜æå¾—ä¸€å¤´é›¾æ°´ã€‚â€ å¯¹äºæ–‡å­—ç³»ç»Ÿï¼Œå¿…é¡»åˆ†é—¨åˆ«ç±»æ‰æ˜“äºæ£€ç´¢ã€‚ä¾‹å¦‚å¤ä»£çš„å®˜åƒšåˆ¶åº¦ï¼Œå„ç§æ•°æ®ç”¨ç±»ä¼¼äºä¸€ç§æŠ½å±‰ç³»ç»Ÿè¿›è¡Œå­˜å‚¨â€”â€”ä¸€ä¸ªæŠ½å±‰æ”¾ä½å®…æŠµæŠ¼è´·æ¬¾ï¼Œä¸€ä¸ªæ”¾ç»“å©šè¯ä¹¦ï¼Œç¬¬ä¸‰ä¸ªæ”¾ç¨åŠ¡ç™»è®°ææ–™ï¼Œç¬¬å››ä¸ªæ”¾è¯‰è®¼æ¡ˆä»¶å·å®—â€¦â€¦æ“ä½œè¿™ç§ç³»ç»Ÿçš„äººå¿…é¡»æ¥å—è®­ç»ƒï¼Œæ€è€ƒæ–¹å¼ä¸èƒ½åƒä¸€èˆ¬äººï¼Œè€Œå¾—æœ‰ä¸“ä¸šæ–‡ä¹¦å’Œä¼šè®¡çš„æ ·å­ã€‚ æ•°å­—ç³»ç»Ÿè¿™ç§éƒ¨åˆ†è¡¨æ„çš„æ–‡å­—ä½¿å¾—å­˜å‚¨å’Œå¤„ç†æ•°æ®çš„æ•ˆç‡è¿›ä¸€æ­¥æå‡ã€‚ä¸ä»…åœ¨åƒç‰©ç†å’Œå·¥ç¨‹æ–¹é¢å‘æŒ¥ä½œç”¨ï¼Œç”šè‡³åƒâ€œè´«ç©·â€ã€â€œå¹¸ç¦â€å’Œâ€œè¯šå®â€è¿™äº›æ¦‚å¿µä¹Ÿèƒ½ç¿»è¯‘æˆä¸€ä¸ªåˆä¸€ä¸ªçš„æ•°å­—ï¼Œæˆäº†â€œè´«ç©·çº¿â€ã€â€œä¸»è§‚å¹¸ç¦æ„Ÿç¨‹åº¦â€ã€â€œä¿¡ç”¨ç­‰çº§â€ï¼Œå‡ ä¹æ•´ä¸ªçŸ¥è¯†é¢†åŸŸéƒ½èƒ½å¿«è¦å’Œäººç±»çš„å£è¯­è¯­è¨€è„±èŠ‚ï¼Œè€Œç”±æ•°å­¦ç¬¦å·ç‹¬æŒ‘å¤§æ¢ã€‚ è®¡ç®—æœºæ‰€ä½¿ç”¨çš„äºŒè¿›åˆ¶ç¨‹åºè¯­è¨€ï¼Œä»…ä»…åªç”±0å’Œ1ä¸¤ä¸ªç¬¦å·æ„æˆï¼Œå…¶è¿è¡Œæœºåˆ¶åŸºäºç”µå­å…ƒä»¶å’Œè®¸å¤šé€»è¾‘é—¨ç”µè·¯ï¼Œå³ä½¿äººç±»åˆ›é€ äº†å„ç§å„æ ·çš„é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå…¶è¯­æ³•ä»ç„¶ä¸è‡ªç„¶è¯­è¨€ç›¸å·®ç”šè¿œï¼Œäººç±»ä¾ç„¶éœ€è¦ç”¨è®¡ç®—æ€ç»´å»ä¸ºç¨‹åºç¼–å†™ä»£ç ï¼Œä¸ºå„ç§å„æ ·çš„æ•°æ®å»è®¾è®¡é«˜æ•ˆçš„å¢åˆ æ”¹æŸ¥é€»è¾‘ã€‚ â€œäººå·¥æ™ºèƒ½çš„é¢†åŸŸè¿˜å¸Œæœ›èƒ½å¤Ÿå®Œå…¨åœ¨è®¡ç®—æœºäºŒè¿›åˆ¶çš„ç¨‹åºè¯­è¨€çš„ä¸Šåˆ›é€ ä¸€ç§æ–°çš„æ™ºèƒ½ã€‚åƒç§‘å¹»ç”µå½±ã€Šé»‘å®¢å¸å›½ã€‹æˆ–ã€Šç»ˆç»“è€…ã€‹ï¼Œå°±éƒ½é¢„æµ‹ç€æ€»æœ‰ä¸€å¤©è¿™äº›äºŒè¿›åˆ¶è¯­è¨€ä¼šæŠ›ä¸‹äººæ€§ç»™å®ƒä»¬çš„æ·é”ï¼Œè€Œäººç±»æƒ³è¦åæ‰‘çš„æ—¶å€™ï¼Œå®ƒä»¬å°±ä¼šè¯•å›¾æ¶ˆç­äººç±»ã€‚â€ â€œæ–‡å­—æœ¬æ¥åº”è¯¥æ˜¯äººç±»æ„è¯†çš„ä»†äººï¼Œä½†ç°åœ¨æ­£åœ¨åä»†ä¸ºä¸»ã€‚è®¡ç®—æœºå¹¶ä¸èƒ½ç†è§£æ™ºäººå¦‚ä½•è¯´è¯ã€æ„Ÿè§‰å’Œç¼–åˆ¶æ¢¦æƒ³ï¼Œæ‰€ä»¥æˆ‘ä»¬ç°åœ¨åè€Œæ˜¯ç”¨ä¸€ç§è®¡ç®—æœºèƒ½å¤Ÿç†è§£çš„æ•°å­—æ¥æ•™æ™ºäººå¦‚ä½•è¯´è¯ã€æ„Ÿè§‰å’Œç¼–ç»‡æ¢¦æƒ³ã€‚â€ ","date":"2020-10-11","objectID":"/thumbbox1.html/:2:1","tags":["å†å²"],"title":"äººç±»ç®€å²ï¼Œä¸€äº›æœ‰è¶£çš„è§‚ç‚¹ï¼ˆå…¶ä¸€ï¼‰","uri":"/thumbbox1.html/"}]