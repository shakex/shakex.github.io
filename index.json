[{"categories":null,"content":"about ","date":"2021-01-23","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"},{"categories":["LMSI"],"content":"MIT-Adobe FiveK Dataset：MIT-Adobe美学增强数据集1 https://data.csail.mit.edu/graphics/fivek/ #Classification #Multi-label #Image enhancement 发布者：MIT CSAIL \u0026 Adobe Systems Inc. 发布日期：2011 样本数：5000 分辨率：不固定（RAW） 证书：LicenseAdobe, LicenseAdobeMIT fivekMIT-Adobe FiveK dataset \" MIT-Adobe FiveK dataset “We collected 5,000 photographs taken with SLR cameras by a set of different photographers. They are all in RAW format; that is, all the information recorded by the camera sensor is preserved. We made sure that these photographs cover a broad range of scenes, subjects, and lighting conditions. We then hired five photography students in an art school to adjust the tone of the photos. Each of them retouched all the 5,000 photos using a software dedicated to photo adjustment (Adobe Lightroom) on which they were extensively trained. We asked the retouchers to achieve visually pleasing renditions, akin to a postcard. The retouchers were compensated for their work.” ","date":"2021-01-19","objectID":"/lmsi-fivek.html/:1:0","tags":["computer vision","dataset"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek.html/"},{"categories":["LMSI"],"content":"目录 （文件太大，未全部下载） ","date":"2021-01-19","objectID":"/lmsi-fivek.html/:1:1","tags":["computer vision","dataset"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek.html/"},{"categories":["LMSI"],"content":"备注 提供全部数据下载（～50GB）和单张图片下载，可写脚本部分下载某几张图片或某个专家调色后的图片。数据集包含以下信息： 图片格式为PNG（可通过DCRAW、Adobe lightroom或其他图像工具读取），调色后的图片保存为TIFF格式 提供5位后期专家Adobe Lightroom catalog文件，即包含了5位专家对每张图片的调色记录和各参数值 提供每张图片的语义信息标注（室内/室外、拍摄时段、光线、拍摄主题等） ","date":"2021-01-19","objectID":"/lmsi-fivek.html/:1:2","tags":["computer vision","dataset"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek.html/"},{"categories":["LMSI"],"content":"引用 @inproceedings{fivek, author = \"Vladimir Bychkovsky and Sylvain Paris and Eric Chan and Fr{\\'e}do Durand\", title = \"Learning Photographic Global Tonal Adjustment with a Database of Input / Output Image Pairs\", booktitle = \"The Twenty-Fourth IEEE Conference on Computer Vision and Pattern Recognition\", year = \"2011\" } ","date":"2021-01-19","objectID":"/lmsi-fivek.html/:1:3","tags":["computer vision","dataset"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek.html/"},{"categories":["LMSI"],"content":"联系方式 fivek-dataset@googlegroups.com 数据使用 如未作特别说明，大部分公开数据集仅作为研究用途。 Bychkovsky, V., Sylvain Paris, E. Chan and F. Durand. Learning photographic global tonal adjustment with a database of input/output image pairs. [CVPR'11] ↩︎ ","date":"2021-01-19","objectID":"/lmsi-fivek.html/:1:4","tags":["computer vision","dataset"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek.html/"},{"categories":["LMSI"],"content":"Mars32k：火星数据集1 https://dominikschmidt.xyz/mars32k/ #Unsupervised 发布者：NASA/JPL-Caltech 发布日期：2018.11 样本数：32368 分辨率：560x500 sample data This dataset consists of about 32,000 color images collected by the Curiosity rover on Mars between August 2012 and November 2018. The images show various geographical and geological features of Mars such as mountains and valleys, craters, dunes and rocky terrain. All images have been scaled down using linear interpolation to 560x500px (some images have been cropped). The dataset is intended for unsupervised learning and the images are only labeled with the date they were taken on. This dataset only contains photos taken with Curiosity’s Mastcam camera and all grayscale or other images were removed. ","date":"2021-01-17","objectID":"/lsmi-mars32k.html/:1:0","tags":["computer vision","dataset"],"title":"Mars32k dataset","uri":"/lsmi-mars32k.html/"},{"categories":["LMSI"],"content":"目录 mars32k/ └[cr_]sol_nasa_filename.jpg # 文件命名规则： # cr_: 标记该图片已经过裁剪 # sol：标记拍摄这张图片的火星太阳日 # nasa_filename：标记NASA对该图片的命名 # 例如图片名称：725_0725MR0030950120402857E01_DXXX.jpg， # 表示该图片未经过裁剪，拍摄于登陆火星的第725天，名称为0725MR0030950120402857E01_DXXX ","date":"2021-01-17","objectID":"/lsmi-mars32k.html/:1:1","tags":["computer vision","dataset"],"title":"Mars32k dataset","uri":"/lsmi-mars32k.html/"},{"categories":["LMSI"],"content":"备注 数据集中的图像并非原始分辨率，都经过了线性插值，统一调整为560×500px，这些图片显示了火星的各种地理和地质特征，如山脉和山谷，陨石坑，沙丘和岩石地形。该数据集可用于一些计算机图像任务，比如于物体检测模型的训练、模拟仿真3D火星表面模型的搭建，还能作为天文学科科普所用。 ","date":"2021-01-17","objectID":"/lsmi-mars32k.html/:1:2","tags":["computer vision","dataset"],"title":"Mars32k dataset","uri":"/lsmi-mars32k.html/"},{"categories":["LMSI"],"content":"联系方式 schmidtdominik30@gmail.com 数据使用 如未作特别说明，大部分公开数据集仅作为研究用途。 https://dominikschmidt.xyz/mars32k/ ↩︎ ","date":"2021-01-17","objectID":"/lsmi-mars32k.html/:1:3","tags":["computer vision","dataset"],"title":"Mars32k dataset","uri":"/lsmi-mars32k.html/"},{"categories":["LMSI"],"content":"1. UEC Food-100：食物识别数据集1 http://foodcam.mobi/dataset100.html #Classification #Recognition #Multi-label 发布者：The University of Electro-Communications, Tokyo, Japan 发布日期：2012 样本数：16557 类别数：100 分辨率：不固定 证书：Research Only uecfood-100UEC Food 100 dataset \" UEC Food 100 dataset The dataset “UEC FOOD 100” contains 100-kind food photos. Each food photo has a bounding box indicating the location of the food item in the photo. Most of the food categories in this dataset are popular foods in Japan. Therefore, some catarogies might not be familiar with other people than Japanese. ","date":"2021-01-16","objectID":"/lmsi-uec-food.html/:1:0","tags":["computer vision","dataset"],"title":"UEC food datasets","uri":"/lmsi-uec-food.html/"},{"categories":["LMSI"],"content":"2. UEC Food-256：食物识别数据集2 http://foodcam.mobi/dataset256.html #Classification #Recognition 发布者：The University of Electro-Communications, Tokyo, Japan 发布日期：2014 样本数：16557 类别数：256 分辨率：不固定 证书：Research Only uecfood-256UEC Food 256 dataset \" UEC Food 256 dataset The dataset “UEC FOOD 256” contains 256-kind food photos. Each food photo has a bounding box indicating the location of the food item in the photo. Most of the food categories in this dataset are popular foods in Japan and other countries. Therefore, some catarogies might not be familiar with other people than Japanese. ","date":"2021-01-16","objectID":"/lmsi-uec-food.html/:2:0","tags":["computer vision","dataset"],"title":"UEC food datasets","uri":"/lmsi-uec-food.html/"},{"categories":["LMSI"],"content":"3. UECFoodPix/UECFoodPixComplete：食物分割数据集34 http://mm.cs.uec.ac.jp/uecfoodpix/ #Classification #Segmentation 发布者：The University of Electro-Communications, Tokyo, Japan 发布日期：2020.7(UECFoodPix), 2020.10(UECFoodPixComplete) 样本数：9000 (train) + 1000 (test) 类别数：103 分辨率：不固定 证书：Research Only uecfoodpixUECFoodPix/UECFoodPixComplete dataset \" UECFoodPix/UECFoodPixComplete dataset UECFoodPix and UECFoodPixComplete are food images dataset with segmentation masks including 9,000 images for training and 1,000 image for testing. The Segmentation masks are augmented by food category. In UECFoodPix, the mask images is created using a bounding box and GrabCut, and In UECFoodPixCimplete there is provided manualy.The mask images have pixel-wise food 103 class labels, and only R(red) channel have this labels. ","date":"2021-01-16","objectID":"/lmsi-uec-food.html/:3:0","tags":["computer vision","dataset"],"title":"UEC food datasets","uri":"/lmsi-uec-food.html/"},{"categories":["LMSI"],"content":"目录 # UEC Food-100 UCEFOOD100/ └[1-100]/ # 1-100类食物图片文件夹 │　└*.jpg # 属于该类的图片 │　└bb_info.txt # 该类所有图片的bouding box信息 └category_ja_{euc, sjis, utf8}.txt # 类别ID和对应标签（日文） └category.txt # 类别ID和对应标签（英文） └multiple_food.txt # 包含多标签的图片名和对应的类别ID └README.txt # 说明文档 # UEC Food-256 UCEFOOD256/ └[1-256]/ # 1-256类食物图片文件夹 │　└*.jpg # 属于该类的图片 │　└bb_info.txt # 该类所有图片的bouding box信息 └category.txt # 类别ID和对应标签（英文） └README.txt # 说明文档 # UECFoodPixComplete UECFOODPIXCOMPLTE/ ├data/ └UECFoodPIXCOMPLTE/ └train/ │　└img/*.jpg # 训练图片 │　└mask/*.png # 训练图片分割Mask └test/ │　└img/*.jpg # 测试图片 │　└mask/*.png # 测试图片分割Mask └category.txt # 类别ID和对应标签（英文） └train.txt # 训练数据（图片名） └test.txt # 测试数据（图片名） ","date":"2021-01-16","objectID":"/lmsi-uec-food.html/:3:1","tags":["computer vision","dataset"],"title":"UEC food datasets","uri":"/lmsi-uec-food.html/"},{"categories":["LMSI"],"content":"备注 UECFoodPix和UECFoodPixComplete包含相同的图像，不同在于分割Mask的生成方式不同，UECFoodPix中利用Bounding Box和GrabCut方法生成分割Mask，而在UECFoodPixComplete中分割Mask为手工标注。 其他食物数据集还有：UNIMIB Food, Food-475, VIREO, Food-101, and Food-50。 ","date":"2021-01-16","objectID":"/lmsi-uec-food.html/:3:2","tags":["computer vision","dataset"],"title":"UEC food datasets","uri":"/lmsi-uec-food.html/"},{"categories":["LMSI"],"content":"联系方式 food-group@mm.cs.uec.ac.jp (Prof. Keiji Yanai) 数据使用 如未作特别说明，大部分公开数据集仅作为研究用途。 Matsuda, Y., H. Hoashi and K. Yanai. Recognition of Multiple-Food Images by Detecting Candidate Regions. [ICME'12] ↩︎ Kawano, Y. and K. Yanai. Automatic Expansion of a Food Image Dataset Leveraging Existing Categories with Domain Adaptation. [ECCV'14 Workshops] ↩︎ Ege, Takumi, Wataru Shimoda and K. Yanai. A New Large-scale Food Image Segmentation Dataset and Its Application to Food Calorie Estimation Based on Grains of Rice. [MADiMa'19] ↩︎ K. Okamoto and K. Yanai: UEC-FoodPix Complete: A Large-scale Food Image Segmentation Dataset. [MADiMa'21] ↩︎ ","date":"2021-01-16","objectID":"/lmsi-uec-food.html/:3:3","tags":["computer vision","dataset"],"title":"UEC food datasets","uri":"/lmsi-uec-food.html/"},{"categories":["LMSI"],"content":"Mut1ny：头部/面部分割数据集1 #Segmentation 发布者：Mut1ny 发布日期：2020.8 样本数：16557 类别数：11 分辨率：300x280 / 304x304 / 256x256 / 其他 证书：CC-BY-NC-SA lmsi-1Mut1ny face-head segmentation dataset \" Mut1ny face-head segmentation dataset This new arrangement of the dataset contains over 16.5k (16557) fully pixel-level labeled segmentation images. Facial images are included from different ethnicity, ages and genders making it a well balanced dataset. Also there is a wide variety of facial poses and different camera angles to provide a good coverage from -90 to 90 degrees facing. Some images even contain multiple head/face segmentation depending on if the second or third face takes up enough screen real estate space. ","date":"2021-01-13","objectID":"/lmsi-mut1ny.html/:1:0","tags":["computer vision","dataset"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny.html/"},{"categories":["LMSI"],"content":"目录 ","date":"2021-01-13","objectID":"/lmsi-mut1ny.html/:1:1","tags":["computer vision","dataset"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny.html/"},{"categories":["LMSI"],"content":"真值（~/labels） 不同类别的rgb颜色编码如下： lmsi-1-figGround truth \" Ground truth ","date":"2021-01-13","objectID":"/lmsi-mut1ny.html/:1:2","tags":["computer vision","dataset"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny.html/"},{"categories":["LMSI"],"content":"备注 2500张真实图像 (~/real_photos)，部分做旋转处理，分辨率大部分为304x304和256x256；其余14057张图像由23位志愿者（13男+10女）的面部在不同背景和角度下合成得到，分辨率为300x280。 ","date":"2021-01-13","objectID":"/lmsi-mut1ny.html/:1:3","tags":["computer vision","dataset"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny.html/"},{"categories":["LMSI"],"content":"额外的商业版本 目前标注好了44000张图像（至2021.1），新增了3个类别。可联系发布者提供。 ","date":"2021-01-13","objectID":"/lmsi-mut1ny.html/:1:4","tags":["computer vision","dataset"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny.html/"},{"categories":["LMSI"],"content":"联系方式 data@mul1ny.com 数据使用 如未作特别说明，大部分公开数据集仅作为研究用途。 https://www.mut1ny.com ↩︎ ","date":"2021-01-13","objectID":"/lmsi-mut1ny.html/:1:5","tags":["computer vision","dataset"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny.html/"},{"categories":["拇指盒"],"content":"炼丹技巧 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:1:0","tags":["computer vision"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare.html/"},{"categories":["拇指盒"],"content":"All in Linux：一个算法工程师的IDE断奶之路 在合格的炼丹师面前，python可能被各种嫌弃…… 夕小瑶，公众号：夕小瑶的卖萌屋 前段时间在远端部署OCR模型的时候，几度被无法与外网沟通的服务器搞得十分泄气。直到项目阶段性地告一段落后才看到这篇文章，真是深感相见恨晚，接下来可以实践一下了。 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:1:1","tags":["computer vision"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare.html/"},{"categories":["拇指盒"],"content":"PyTorch常用代码段合集 本文是PyTorch常用代码段合集，涵盖基本配置、张量处理、模型定义与操作、数据处理、模型训练与测试等5个方面，还给出了多个值得注意的Tips，内容非常全面。 公众号：夕小瑶的卖萌屋 炼丹常用的代码模板，可以在此基础上写一套适用自己的模板。 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:1:2","tags":["computer vision"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare.html/"},{"categories":["拇指盒"],"content":"一文搞懂 PyTorch 内部机制 这篇博文是一篇非常新的介绍PyTorch内部机制的文章，作者Edward Z Yang来自于Stanford大学，是PyTorch的核心开发者之一。文章中介绍了如何阅读PyTorch源码和扩展PyTorch的技巧。 ArchWalker，公众号：夕小瑶的卖萌屋 这是一篇好看的翻译文章，对于了解PyTorch底层的一些原理很有帮助1。 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:1:3","tags":["computer vision"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare.html/"},{"categories":["拇指盒"],"content":"AI识别彻底懵逼，这到底是「牛」还是「鲨」？ 我和编辑部的同事因为上图到底是牛还是鲨吵了起来图片，我说这张图更像图片，同事说更像图片，我们差点儿就GAN了一架！ 耳洞打三金，公众号：AI科技评论 关于是牛还是鲨的GAN架文章，故事告诉了我们人的视觉和机器识别模型存在的一些认知差异。 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:1:4","tags":["computer vision"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare.html/"},{"categories":["拇指盒"],"content":"小程序 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:2:0","tags":["computer vision"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare.html/"},{"categories":["拇指盒"],"content":"GeoPattern 用一个字符串生成SVG格式的图案，提供了多种语言的实现方式。用到了SHA算法，具体实现还需要再读一读源码。哦！想起来本周OpenAI极其可爱的Dall-E项目——用一串文本生成符合描述的图片，大佬们用PyTorch的复现也正在路上，有空可以玩一玩。 举几个GeoPattern的栗子： GeoPattern examples\" GeoPattern examples 再举一个Dall-E的栗子： Dall-E examples \" Dall-E examples ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:2:1","tags":["computer vision"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare.html/"},{"categories":["拇指盒"],"content":"EDA (Easy Data Augmentation) 最近在训练文本识别模型的时候，遇到了中文语料不足的问题，想到可以对现有的语料库做数据增强，于是发现了这篇应用于文本分类的数据增强论文——EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks。其中的算法思想很朴素，作者提出了四种在原句子基础上进行调整的操作：随机插入、随机删除、随机交换和同义词替换，利用这种数据增强的方法可以在原模型基础上提高文本分类的准确率。 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:2:2","tags":["computer vision"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare.html/"},{"categories":["拇指盒"],"content":"书籍 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:3:0","tags":["computer vision"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare.html/"},{"categories":["拇指盒"],"content":"Kubernetes in Action 中文版 由七牛容器云团队翻译。最近在读，作为K8s的入门讲得针不戳。 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:3:1","tags":["computer vision"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare.html/"},{"categories":["拇指盒"],"content":"Google Python Style Guide 英文 中文 狗家也提供其他语言的styleguide可以参考。在团队协作的工程项目中把代码写规范还是很重要的，希望人人都可以献出一份爱，世界将充满更多毛绒绒的头发。 原文链接：http://blog.ezyang.com/2019/05/pytorch-internals/ ↩︎ ","date":"2021-01-11","objectID":"/thumbbox-sundayshare.html/:3:2","tags":["computer vision"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare.html/"},{"categories":["拇指盒"],"content":"Introduction ","date":"2020-11-10","objectID":"/thumbbox2.html/:1:0","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Basic pipeline Detection+Recognition End-to-end image-20201107140006891fig1 \" fig1 ","date":"2020-11-10","objectID":"/thumbbox2.html/:1:1","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Challenges for general text detection and recognition Diversity and variability different languages/color/fonts/size/orientations/shapes Complexity and interference of background similar patterns/occlusions Imperfect image conditions Low resolution/shot angle/blurred(unfocused)/noise/light ","date":"2020-11-10","objectID":"/thumbbox2.html/:1:2","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Methods before DL ","date":"2020-11-10","objectID":"/thumbbox2.html/:2:0","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Text detection CCA (Connected Components Analysis)：连通域分析法 提取出包含文本的候选区域（color clustering/extreme region extration） 从候选区域中过滤背景，即分割出文本类（特征提取，分类/分割） 特征：MSRE/SWT/SIFT/SURF/LBP/灰度共生矩阵等 分类器：Kmeans/KNN/SVM/NN/DecisionTree等 Huang et al., 2013; Neumann and Matas, 2010; Epshtein et al., 2010; Tu et al., 2012; Yin et al., 2014; Yi and Tian, 2011; Jain and Yu, 1998 SW (Siliding window)：滑动窗口法 利用不同大小的滑动窗口对窗口区域进行二分类（包含/不包含文本） 通过形态学操作/CRF/Graph-based-method等对窗口进行合并 Lee et al., 2011; Wang et al., 2011; Coates et al., 2011; Wang et al., 2012 ","date":"2020-11-10","objectID":"/thumbbox2.html/:2:1","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Text recognition 基于特征的方法 划分子问题 二值化(text binarization)-\u003e文本行切分(text line segmentation)-\u003e字符划分(character segmentation)-\u003e单字符识别(single character recognition)-\u003e单词校正(word correction) feature-based: Shi et al., 2013; Yao et al., 2014; Rodriguez-Serrano et al., 2013, 2015; Gordo, 2015; Almazan et al., 2014 text binarization: Zhiwei et al., 2010; Mishra et al., 2011; Wakahara and Kita, 2011; Lee and Kim, 2013 text line segmentation: Ye et al., 2003 character segmentation: Nomura et al., 2005; Shivakumara et al., 2011; Roy et al., 2009 single character recognition: Chen et al., 2004; Sheshadri and Divvala, 2012 word correction: Zhang and Chang, 2003; Wachenfeld et al., 2006; Mishra et al., 2012; Karatzas and Antonacopoulos, 2004; Weinman et al., 2007 ","date":"2020-11-10","objectID":"/thumbbox2.html/:2:2","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"End-to-end (detection+recognition) Wang et al., 2011：nearest-neighbor classifier+HoG Neumann and Matas, 2013：decision delay ap- proach+dynamic programming algorithm Wang et al., 2011; Neumann and Matas, 2013 ","date":"2020-11-10","objectID":"/thumbbox2.html/:2:3","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Methods based on DL ","date":"2020-11-10","objectID":"/thumbbox2.html/:3:0","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Text detection 早期尝试 基于目标检测的方法 Anchor-based TextBoxes (Liao et al., 2017)：anchor-based, SSD [code] EAST (Zhou et al., 2017)：anchor-based, u-net, simple pipeline and real-time speed [code] Region proposal Ma et al., 2017: solve text of arbitrary orientations [code] FEN (Zhang et al., 2018) Specific task/case (w/o sub-text) ITN (Wang et al., 2018): multi-orientated text [code] Zhang et al., 2019: irregular text Wang et al., 2019b: irregular text Sub-text components: better flexibility over shapes and aspect ratios of text Use NN to predict local attributes or segments Post-processing to re-construct text instance Pixel level PixelLink (Deng et al., 2018) [code] Border learning method (Wu and Natarajan, 2017) Component-level CTPN (Tian et al., 2016) [code] SegLink (Shi et al., 2017a) [code] Corner Localization (Lyu et al., 2018b) TextSnake (Long et., 2018) Character-level Braek et al., 2019b ","date":"2020-11-10","objectID":"/thumbbox2.html/:3:1","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Text recognition image-20201107191619556fig2 \" fig2 CTC-based (Connectionist Temporal Classification，一种时序分类算法) (CNN+RNN+CTC) CNN layer：CNN Encoder提取文本图像特征，形成若干特征序列 RNN layer：RNN进一步提取文本序列特征 Transcription layer (CTC loss)：CTC解决字符对齐问题 CRNN (Shi et al., 2017b) [code] DTRN (He et al., 2016) Gao et al., 2017 Yin er al., 2017 Encoder-Decoder (CNN+Seq2Seq+Attention) CNN layer：CNN Encoder提取文本图像特征，形成若干特征序列 Seq2Seq+Attention：好处是输出向量长度可以与输入不同 Transcription layer (Classification loss) Lee and Osindero, 2016 Cheng et al., 2018 Bai et al., 2018 Liu et al., 2018d Irregular text Case ","date":"2020-11-10","objectID":"/thumbbox2.html/:3:2","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"End-to-end (Detection+Recognition/Text Spotting) Two-stage pipeline: feature map instead of images are cropped and fed to recognition module SEE (Bartz et al., 2017) [code] Busta et al., 2017 [code] Li et al., 2017a He et al., 2018 Liu et al., 2018c One-stage pipeline: predict character and text bounding boxes as well as character type segmentation maps in parallel Xing et al., 2019 ","date":"2020-11-10","objectID":"/thumbbox2.html/:3:3","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Auxiliary techniques that support detection and recognition Synthetic Data Weakly and Semi-Supervision More paper reference https://github.com/Jyouhou/SceneTextPapers ","date":"2020-11-10","objectID":"/thumbbox2.html/:3:4","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Datasets image-20201107191949977 \" image-20201107191949977 Dataset (Year) Image Num (train/test) Text Num (train/test) Orientation Language Characteristics Detec/Recog Task End2End ==== ==== ==== ==== ==== ==== ICDAR03 (2003) 509 (258/251) 2276 (1110/1156) Horizontal EN - ✓/✓ ICDAR13 Scene Text(2013) 462 (229/233) - (848/1095) Horizontal EN - ✓/✓ ICDAR15 Incidental Text(2015) 1500 (1000/500) - (-/-) Multi-Oriented EN Blur, Small, Defocused ✓/✓ ICDAR17 / RCTW (2017) 12263 (8034/4229) - (-/-) Multi-Oriented CN - ✓/✓ Total-Text (2017) 1555 (1255/300) - (-/-) Multi-Oriented, Curved EN, CN Irregular polygon label ✓/✓ SVT (2010) 350 (100/250) 904 (257/647) Horizontal EN - ✓/✓ KAIST (2010) 3000 (-/-) 5000 (-/-) Horizontal EN, KO Distorted ✓/✓ NEOCR (2011) 659 (-/-) 5238 (-/-) Multi-oriented 8 langs - ✓/✓ CUTE (2014) or here 80 (-/80) - (-/-) Curved EN - ✓/✓ CTW (2017) 32K ( 25K/6K) 1M ( 812K/205K) Multi-Oriented CN Fine-grained annotation ✓/✓ CASIA-10K (2018) 10K (7K/3K) - (-/-) Multi-Oriented CN ✓/✓ Detection Only ==== ==== ==== ==== ==== ==== OSTD (2011) 89 (-/-) 218 (-/-) Multi-oriented EN - ✓/- MSRA-TD500 (2012) 500 (300/200) 1719 (1068/651) Multi-Oriented EN, CN Long text ✓/- HUST-TR400 (2014) 400 (400/-) - (-/-) Multi-Oriented EN, CN Long text ✓/- ICDAR17 / RRC-MLT (2017) 18000 (9000/9000) - (-/-) Multi-Oriented 9 langs - ✓/- CTW1500 (2017) 1500 (1000/500) - (-/-) Multi-Oriented, Curved EN Bounding box with_14_ vertexes ✓/- Recognition Only ==== ==== ==== ==== ==== ==== Char74k (2009) 74107 (-/-) 74107 (-/-) Horizontal EN, Kannada Character label -/✓ IIIT 5K-Word (2012) 5000 (-/-) 5000 (2000/3000) Horizontal - cropped -/✓ SVHN (2010) - (-/-) 600000 (-/-) Horizontal - House number digits -/✓ SVTP (2013) 639 (-/639) - (-/-) EN Distorted -/✓ ","date":"2020-11-10","objectID":"/thumbbox2.html/:4:0","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Evaluation ","date":"2020-11-10","objectID":"/thumbbox2.html/:5:0","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Detection Metrics Precision ($P$): the proportion of predicted text instances that can be matched to gt labels. Recall ($R$): the porportion of gt labels that have correspondents in the predicted list. F1-Score $$ F_1 = \\frac{2PR}{P+R} $$ And others ","date":"2020-11-10","objectID":"/thumbbox2.html/:5:1","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Recognition Metrics Character-level(#characters are recognized)/word level(whether the predicted word exactly the same as gt) image-20201108160251229 \" image-20201108160251229 ","date":"2020-11-10","objectID":"/thumbbox2.html/:5:2","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Applications Automatic Data Entry Identity Authentication Augmented Computer Vision Intelligence Content Analysis ","date":"2020-11-10","objectID":"/thumbbox2.html/:6:0","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":"Reference CRNN+CTC文字识别 CTPN原理与实现 完全解析RNN, Seq2Seq, Attention注意力机制 ","date":"2020-11-10","objectID":"/thumbbox2.html/:7:0","tags":["computer vision","ocr","paper"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2.html/"},{"categories":["拇指盒"],"content":" 最近在读尤瓦尔.赫拉利的《人类简史：从动物到上帝》。书中作者用比较宏观和独到的观点介绍了人类历史进程中的三场重要革命：认知革命（Cognitive Revolution）、农业革命（Agricultural Revolution）和科学革命（Scientific Revolution）。以下摘录并总结一些自己认为有趣的观点。 ","date":"2020-10-11","objectID":"/thumbbox1.html/:0:0","tags":["历史"],"title":"人类简史，一些有趣的观点（其一）","uri":"/thumbbox1.html/"},{"categories":["拇指盒"],"content":"八卦和虚构故事使大规模的有序合作成为可能 智人是一种社会性的动物，社会合作是我们得以生存和繁衍的关键。 早期形成的亲近小团体中，智人与其他生物没什么不同。人们需要十分了解彼此，才有可能进行分工合作。一旦团体过大，社交秩序就会崩坏，团体就会分裂。用关系图模型来做类比的话，每个个体节点需要与其他个体节点都有联系，才会形成合作。 认知革命以后，智人发展出了“八卦”这种能力——即人们能够在彼此背后“说坏话”达数小时之久。这种能力本质上促进了更高效信息的交换和传播，而借由八卦来维持的最大“自然”团体人数大约是150人。在这种关系图中，每个个体节点只要同属于一个连通域中，就能进行信息传递，形成合作。 之后，智人又逆天地发明了“虚拟故事”，使得即使是互相不认识的陌生人，只要相信这个“虚拟故事”，就能形成共同合作。这种“虚拟故事”使得团体的规模空前扩大，合作趋于有序、精细和专业化。神、国家、公司、法律等等这些概念所形成的故事网络，直至今日早已构建出了一个“虚拟世界”。在这种关系图中，“故事”通过当时最先进的媒介进行传播，在可达范围内的所有个体节点只要相信这个故事为真，就可以与其他同类个体节点形成合作交互。 ","date":"2020-10-11","objectID":"/thumbbox1.html/:1:0","tags":["历史"],"title":"人类简史，一些有趣的观点（其一）","uri":"/thumbbox1.html/"},{"categories":["拇指盒"],"content":"人类发明了它，也被它驯化 ","date":"2020-10-11","objectID":"/thumbbox1.html/:2:0","tags":["历史"],"title":"人类简史，一些有趣的观点（其一）","uri":"/thumbbox1.html/"},{"categories":["拇指盒"],"content":"农业革命（P2C5） 农业革命确实养活了更多人和动植物，实现了演化意义上的成功，也为农民带了一定的利益。但作者在书中提到，农业革命是史上最大的一桩骗局，它本质上让更多的人以更糟的状况活下去。主要影响有几个： 人类的身体演化目的并不是让我们去弯腰清石块、努力挑水桶的，适应这些活动让人类付出了诸如椎间盘突出、关节炎和疝气等疾病代价； 人类的活动范围更加聚集，人口增加、聚落密度也随之增大，导致传染病更容易滋生和扩散； 人类的饮食更加单一化。谷物作为主食不仅矿物质和维生素含量不足、难以消化，还对牙齿和牙龈大大有害； 人类越来越依赖于一方之土。在战争暴力和自然灾害面前，人们或死守田地，或忍饥挨饿，对于未来的忧虑也进一步加深。 农业革命豢养了一群养尊处优，娇生惯养的精英分子； 农业革命使人类开始落入奢侈生活的陷阱。想让生活变得轻松的努力，反而给人带来无穷的麻烦（如劳心劳力地工作、生活焦虑等）； 总体来看，农业革命也使那些被驯养的动植物成了受害者。鸡鸭牛羊和小麦们虽然依靠人类遍布了整个世界，但是它们或许也会想：我宁愿成为濒危而自由的个体，也不要做交易与供养的奴隶。 ”人类以为自己驯化了植物，但其实是植物驯化了智人。“ 想象的秩序（P2C6） “想象构建的秩序塑造了我们的欲望，而个人欲望成了虚构秩序最强大的守护者。” “例如，浪漫主义告诉我们，为了要尽量发挥潜力，就必须尽量累积不同的经验。必须体会不同的情感，尝试不同的关系，品尝不同的美食，还必须学会欣赏不同风格的音乐。而其中最好的一种办法，就是摆脱日常生活及工作，远离熟悉的环境，前往遥远的国度，好亲身‘体验’不同的文化、气味、美食和规范；消费主义告诉我们，想要快乐，就该去买更多的产品、更多的服务。如果觉得少了什么，或者有什么不够舒服的地方，那很可能是该买些什么商品（新车、新衣服、有机食品），或买点什么服务（清洁工、心理咨询、瑜伽课）。” “一如古埃及精英分子，现在大多数人一生汲汲营营，也都是想盖起某种金字塔，只不过这些金字塔在不同文化里会有不同的名字、形体和规模罢了。” “身为人类，我们不可能脱离想象所构建出的秩序。每一次我们以为自己打破了监狱的高墙、迈向自由的前方，其实只是到了另一件更大的监狱，把活动范围稍稍加以扩大而已。” 文字与计算机（P2C7） 文字与计算机的发明是对人脑存储的增强，但它在某种程度上也改变了人类的思维和看待这个世界的方式。这种改变很大程度上源于文字和计算机系统的归档、编目和检索技术，这与我们大脑原本内建机制非常不同。 “在大脑里，所有都自由地互相连接。比如我在和另一半一起去办新家抵押贷款的时候，就想到我们一起住的第一个地方，这又让我想到去新奥尔良度的蜜月，再想到鳄鱼，再想到西方的恶龙，再想到歌剧《尼布龙根的指环》；结果我不知不觉就哼起了歌剧里面齐格飞的主旋律，把银行职员搞得一头雾水。” 对于文字系统，必须分门别类才易于检索。例如古代的官僚制度，各种数据用类似于一种抽屉系统进行存储——一个抽屉放住宅抵押贷款，一个放结婚证书，第三个放税务登记材料，第四个放诉讼案件卷宗……操作这种系统的人必须接受训练，思考方式不能像一般人，而得有专业文书和会计的样子。 数字系统这种部分表意的文字使得存储和处理数据的效率进一步提升。不仅在像物理和工程方面发挥作用，甚至像“贫穷”、“幸福”和“诚实”这些概念也能翻译成一个又一个的数字，成了“贫穷线”、“主观幸福感程度”、“信用等级”，几乎整个知识领域都能快要和人类的口语语言脱节，而由数学符号独挑大梁。 计算机所使用的二进制程序语言，仅仅只由0和1两个符号构成，其运行机制基于电子元件和许多逻辑门电路，即使人类创造了各种各样的高级编程语言，其语法仍然与自然语言相差甚远，人类依然需要用计算思维去为程序编写代码，为各种各样的数据去设计高效的增删改查逻辑。 “人工智能的领域还希望能够完全在计算机二进制的程序语言的上创造一种新的智能。像科幻电影《黑客帝国》或《终结者》，就都预测着总有一天这些二进制语言会抛下人性给它们的枷锁，而人类想要反扑的时候，它们就会试图消灭人类。” “文字本来应该是人类意识的仆人，但现在正在反仆为主。计算机并不能理解智人如何说话、感觉和编制梦想，所以我们现在反而是用一种计算机能够理解的数字来教智人如何说话、感觉和编织梦想。” ","date":"2020-10-11","objectID":"/thumbbox1.html/:2:1","tags":["历史"],"title":"人类简史，一些有趣的观点（其一）","uri":"/thumbbox1.html/"}]