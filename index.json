[{"categories":["拇指盒"],"content":" 去年年底在做的一个研究课题，有关于OCR财务报表识别。初次探索这个在市面上有不少落地产品的新鲜领域，简单总结一下课题的成果。[项目地址] ","date":"2021-04-17","objectID":"/thumbbox4/:0:0","tags":["计算机视觉","OCR","算法"],"title":"探索OCR——在印刷体表格识别的尝试","uri":"/thumbbox4/"},{"categories":["拇指盒"],"content":"摘要 OCR（Optical Character Recognition）光学字符识别，是指将图像上的文字转化为计算机可编辑的文字内容的技术，众多的研究人员对相关的技术研究已久，也有不少成熟的OCR技术和产品产生。本课题以上市公司近5年的财务报表为研究数据，主要探索了OCR在表格印刷体识别方向的一般方法和技术要点。在这一阶段（2020.10—2020.12）的研究和实践过程中，小组主要调研了市面上应用于印刷体识别的一般方法和算法模型，并初步搭建了一套用于财务报表智能识别和分析的系统。本报告针对其中的算法部分做简要介绍，主要涉及课题实现的整体思路、数据增强的技巧、文本检测和识别模型的结构、文本纠错的思路以及在实际实现中的难点和下一阶段的实施方向，作为阶段性的总结和分享。 ","date":"2021-04-17","objectID":"/thumbbox4/:1:0","tags":["计算机视觉","OCR","算法"],"title":"探索OCR——在印刷体表格识别的尝试","uri":"/thumbbox4/"},{"categories":["拇指盒"],"content":"简介 图像文字中包含着丰富的语义信息，OCR（Optical Character Recognition）在金融行业的应用以文档相关的印刷体文本识别为主，如卡证、票据、合同、报表等。OCR作为流程自动化的重要一环，可以极大提升业务流程的效率，减少人工审核、录入的工作量，优化产品服务的客户体验，以及为后续的数据分析与挖掘提供从图像到文本的技术基础。目前市面上的OCR产品主要按照具体的应用场景提供服务接口。从产品和服务角度来看，不同行业、场景下的文本内容往往有其特定的排版标准，按照场景划分更加贴近业务需求，并能够针对性地解决业务痛点；从技术角度来看，早期的OCR主要基于传统图像处理方法，受技术限制其应用场景主要集中在车牌识别、文档扫描、银行卡卡号识别等单一领域。随着近年来以数据驱动的机器学习，尤其是深度学习在图像目标识别、自然语言处理上的研究取得突破进展，OCR在多场景的应用与落地成为可能。在学术界，针对全场景的通用文本检测与识别技术依然是有待研究与提升的方向，其主要面临的挑战有文字多样性（多语种、字体、颜色、大小、方向、形状）、复杂背景（背景图案与纹理、遮挡）、图像质量（拍摄角度、分辨率、噪声、光照）、数据条件（小样本、无监督）等；在工业界，针对具体细分场景的算法优化和与业务系统的融合为主要解决的问题。如下表所示，参考百度OCR产品的场景分类，我们可以看出，目前较为成熟的应用方向主要针对行业相关的印刷文档或制品。而随着学术研究在文本识别和检测的发展，OCR的应用场景和范围将进一步扩大，例如影视文字识别、店铺招牌识别、街景文字识别、通用手写体识别等。 产品 识别类 卡证识别 身份证、银行卡、营业执照、户口本、护照等 汽车场景文字识别 行驶证、驾驶证、车牌、VIN码、车辆合格证、机动车销售发票等 财务票据文字识别 增值税发票、火车票、行程单、支票、汇票等 医疗票据文字识别 医疗发票、保险单、医疗费用结算单等 教育场景文字识别 手写文字、拍照搜题、作业及试卷文字与公示等 其他场景 仪器仪表盘读数、印章、彩票等 目前OCR算法的核心包括文本检测和文本识别两个步骤。文本检测定位图像中的文字位置，一般用矩形框或四边形标记文本所在区域；文本识别根据检测得到的文本图像，由识别模型得到对应的文本信息。为了解决通用文本检测与识别中的挑战，近年来研究人员在各个研究方向都取得了较大的进展。数据方面，无论是检测还是识别模型，识别精度和效果很大程度上依赖于数据规模和数据的多样性——即在使用相同模型的情况下，训练数据越多，数据分布越广，训练的模型就具有更好的识别和泛化性能。因此，大量数据的获取、分类、清洗和标注工作对于最终取得良好的识别效果至关重要。在实际生产中，用于训练一个模型所需的图像数据往往是百万级别的，且需要耗费较多的人力和时间去完成数据标注。在合适的情况下，利用现有的公开数据集是一种可行的解决方案；此外，在很多领域，出于隐私保护、成本控制等原因，并不能获取大量的场景数据，利用数据增广方法可以解决此类样本缺失或不均衡的问题。模型方面，本文检测模型主要分为基于检测框和基于Mask两类，典型算法包括：CTPN (Tian et al., 2016) 、EAST (Zhou et al., 2017)、PMTD、DB等；文本识别模型分为基于CTC（Connectionist Temporal Classification）的模型（Shi et al., 2017b（CRNN） 、He et al., 2016（DTRN）、Gao et al., 2017、Yin er al., 2017等）和基于注意力机制的编码器-解码器结构（Lee and Osindero, 2016、Cheng et al., 2018、Bai et al., 2018、Liu et al., 2018d）。此外，目前也有不少针对不规则文本检测和识别的方法（Wang et al., 2018（ITN）、Zhang et al., 2019、Wang et al., 2019b）和将检测和识别模型联合训练合并成为端到端网络的工作（Bartz et al., 2017、Xing et al., 2019）。 图1 表格印刷体识别的一般流程\" 图1 表格印刷体识别的一般流程 课题小组从目前较为成熟的文档印刷体识别方向出发，总结文档类OCR算法构建的主要步骤如图1所示：输入一张通过图像采集设备获取的文档图像，一般需要经历以下五个步骤：图像校正、版面分析、文本检测、文本识别和文本纠错，最终得到所需要提取的文字信息。具体如下： 图像校正：主要利用灰度化、二值化、图像平滑、直线检测、边缘检测、透视变化等一些方法对采集的文档可能存在的倾斜、遮挡等情况进行校正。该步骤的一个主要难点在于准确定位图像主体（文档/卡证）的四个角点，并利用角点坐标对主体进行校正。针对复杂背景和角点部分遮挡的情况，需要训练分割或边缘检测模型以获得较好的校正效果。例如，图2展示了对于身份证件照片进行透视变化校正，得到用于文本检测和识别的图像。 图2 身份证图像校正\" 图2 身份证图像校正 版面分析：版面分析可以对文档内的图像、文本、公式、表格信息和位置关系进行自动分析、识别和理解。对于复杂的文档，根据版面分析的不同区块采用不同的检测与分割模型，可以提高OCR系统的识别准确率。例如，图3展示了对于一篇论文版面结构的划分。 图 3 论文图像的版面分析\" 图 3 论文图像的版面分析 文本检测：文本检测识别并定位文本在图像中的位置。对于规则的印刷体文本，通常以矩形框标注出每个文本目标的边框。方法主要分为基于检测框和基于Mask两类，基于检测框的文本检测，其思路是先利用若干 Anchor 产生大量候选文本框，再经过 NMS 得到最终结果；基于 Mask 的文本检测，其思路是通过分割网络进行像素级别的语义分割，再通过后处理得到文本框，由于后处理比较复杂，这个步骤会直接影响基于 Mask 文本检测算法的性能。 文本识别：文本识别将文本检测得到的矩形框作为文本识别模型的输入，通过识别模型得到的该矩形区域内的文本内容。由于输入图像中所包含的文字数量是不确定的，因此文本识别的一个关键是解决输入图像宽度与文本字符长度的对应关系，识别模型分为两类：一类是基于CTC（Connectionist Temporal Classification）的模型，有（Shi et al., 2017b（CRNN） 、He et al., 2016（DTRN）、Gao et al., 2017、Yin er al., 2017等），另一类是基于意力机制的编码器-解码器结构（Lee and Osindero, 2016、Cheng et al., 2018、Bai et al., 2018、Liu et al., 2018d）。图4 展示了利用检测和识别算法对于中文表格和英文文本的识别结果。 图4 文本检测与识别示例1\" 图4 文本检测与识别示例1 图4 文本检测与识别示例2\" 图4 文本检测与识别示例2 文本纠错：对于一些复杂场景和特殊字符，识别模型往往很难达到100%的准确率，因此利用语言作为先验信息，对识别结果进行纠错，可以增加OCR系统的鲁棒性。OCR识别纠错主要涉及文本的词法错误，例如，识别模型将“上海市”识别为“上海币”。纠错的两个关键问题分别为：语言模型和字形的相似度度量。语言模型给出当前识别结果最可能的几个真实值，字形的相似度度量给出真实值识别为当前结果的可能性。 当然，上述步骤并不是对于所有场景都是不可或缺，针对具体文档图像依然需要从实际问题出发，选择并设计适合的处理方法和流程。 ","date":"2021-04-17","objectID":"/thumbbox4/:2:0","tags":["计算机视觉","OCR","算法"],"title":"探索OCR——在印刷体表格识别的尝试","uri":"/thumbbox4/"},{"categories":["拇指盒"],"content":"方法要点 课题组实现的OCR任务如下：给定450张经过预处理的多家上市公司近五年财报，其中分为利润表、资产负债表和现金流量表三种类型各150张，每张图像包含标题、表头信息（证券代码、证券简称、报告日期、单位）和表身信息，要求识别每张图像中的文本内容，将识别结果写入CSV文件中。交互设计页面呈现如图5所示：其中左侧为输入图像的部分截图，右侧为界面显示的识别结果。 图5 财务报表OCR识别及其界面呈现\" 图5 财务报表OCR识别及其界面呈现 由于给定的处理图像质量较好，不存在倾斜、透视等情况，因此省去了上一节所提到的图像校正步骤。针对此场景，我们进行处理的主要步骤如下： 通过基于阈值的图像处理方法对表格中的文本进行检测，并同时确定对应文本所属区域（表头或表身）与键-值对应关系（版面分析+文本检测） 利用CRNN模型对检测文本进行识别（文本识别） 对识别结果进行纠错，主要涉及金额项中逗号和点的纠错（文本纠错） ","date":"2021-04-17","objectID":"/thumbbox4/:3:0","tags":["计算机视觉","OCR","算法"],"title":"探索OCR——在印刷体表格识别的尝试","uri":"/thumbbox4/"},{"categories":["拇指盒"],"content":"版面分析与文本检测 给定图像只包含单张表格，且背景统一为白色。针对此类情况，我们可以直接利用基于阈值的方法划分表头和表身部分，同时裁剪出表身每个单元格内文本。具体步骤如下： 灰度化 形态学算子去除噪点 图像行扫描，确定第一条直线位置，其上为表头信息部分，其下为表格主体部分 表头信息文本检测：行列扫描，根据灰度阈值切割文本 表身信息文本检测：图像行列扫描，确定每一单元格的位置；在每个单元格内，切割出对应文本矩形框 对所有矩形框进行微调：调整宽高大小，确保文本有效信息不丢失。统一矩形框的高度 保存检测框的位置信息，匹配文本的键-值对，记录信息至XML文件 检测结果可视化如图6所示。 图6 财务报表文本检测结果\" 图6 财务报表文本检测结果 ","date":"2021-04-17","objectID":"/thumbbox4/:3:1","tags":["计算机视觉","OCR","算法"],"title":"探索OCR——在印刷体表格识别的尝试","uri":"/thumbbox4/"},{"categories":["拇指盒"],"content":"文本识别 数据集构建 为了训练适应于当前应用域的文本识别模型，我们首先构建模型训练所需的数据集。构建数据集包括两部分工作：1. 字符集构建；2. 文本短语图像集及标注。其中，字符集的构建，需要收集样本中所用到的所有字符。针对课题所提供的报表图像，我们共统计出中文字符342个，英文+数字字符69个，共计411个字符（当然，为了训练能够认识更多中文字符的模型，需要扩展字符集。通常来说，最常用的中文字符在3000字左右）。对于文本短语数据集的构建，在对450张表格图像进行文本检测以后，得到约21w张短语图像。其中，由于不同财报图像中包含大量重复短语，因此需要对检测进行去重。去重以后图像样本在1.7w张左右，但是，样本中绝大部分为数字样本，中文短语样本仅378张。显然，如果仅使用这些数据构建训练集的话，会存在样本不均衡的问题，即数据分布集中在数字字符类别，而对于大量的中文字符类，数据样本过少，这显然与真实情况的样本分布相差甚远，会造成训练的模型对于数字样本的过拟合，图7显示了在仅利用现有数据进行模型训练（采用CRNN模型）以后的预测结果，可以看到，结果中对于数字的识别较为准确（部分字符仍然出现识别错误，说明对于数字样本而言，数据样本也需要一定程度的增广），但是对于中文的识别准确率很不理想；因此，我们需要对数据进行增广，扩大中文样本的数量，使得每个字符类的分布尽量均衡。 图 7 数据样本不均衡情况下的模型训练预测结果\" 图 7 数据样本不均衡情况下的模型训练预测结果 在进行数据增广之前，我们对现有数据的基本情况及分布做了基本统计。图8展示了短语样本长度的分布。对于数字样本，其长度分布主要集中在约15-20个字符之间；对于中文短语样本，其长度分布主要集中在约4-10个字符之间。图9展示了在所有样本中出现频次较高的字符和单词统计。对于0-9的数字字符，字符1-9出现的频次大体相同，字符0出现的频次是字符1-9出现频次的3倍，这大致符合数字作为金额时的分布规律。在关于中文字符的统计中，可以看到，出现频次前三字符为“金”，“资”，“现”，出现频次前三的单词为“现金”，“其他”，“资产”。由此可见，针对财务报表的场景，在所构建的数据集中适当提高财会类字符或词汇的占比，可以更加贴近数据的真实分布。 图 8 数据样本长度分布统计\" 图 8 数据样本长度分布统计 图 9 数据样本高频字符和单词统计\" 图 9 数据样本高频字符和单词统计 接下来考虑文本数据的增广方法，数据增广的操作可以分为两大类：一类是对现有数据进行图像增强，如旋转、拉伸、对比度变化、模糊、膨胀、腐蚀等操作，这类操作可以在维持数据现有分布的情况下，提高模型的泛化性和鲁棒性；另一类是通过文本生成算法去产生新的文本图像，这类操作调整数据更加趋近真实场景的数据分布。在课题组的研究过程中，我们尝试了论文“EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks”所提出的数据生成方法，并在此基础上做了适当修改。该方法针对给定短语文本，可以通过四种基本操作（随机插入、随机删除、随机替换、随机交换）产生新的短语文本，具体操作如下： 随机插入（Random Insertion, RI）:在每个短语的单词间隙中随机插入n个新单词（短语长度增加） 随机删除（Random Deletion, RD）：以概率p随机删除短语中所包含的单词（短语长度减少） 随机替换（Random Replacement, RR）：用一个新单词替代短语中的任意一个单词，重复n次（短语长度几乎不变） 随机交换（Random Swap, RS）：随机选取短语中的两个单词进行交换，重复n次（短语长度不变） 例如，对于“一年内到期的非流动资产”这个文本短语，利用EDA随机得到的文本如下： RI RD RR RS 示例1 一年内到期税费的非流动资产 非流动 一年内川能动力的非流动资产 一年内资产的非流动到期 示例2 代码一年内到期的汇率非流动资产 一年内的 一年内其他的非流动资产 到期一年内的非流动资产 最后，我们对所有的数据样本进行文本标注，并划分训练和验证集合。由于手工标注工作量比较大，我们选择直接利用市面上的API做文本识别，得到标注结果，再针对一些标注错误的情况进行修改。对于数据集的划分，我们按照7:3的比例随机划分训练和验证集合。 CRNN模型 在完成数据集的构建后，我们着手探究适用于印刷体文本识别的模型构建。在这一阶段，课题组尝试了运用最广泛的CRNN模型，图11展示了该模型的结构。CRNN模型主要分为三部分：1. 卷积网络层。主要使用CNN对输入图像进行特征提取，得到特征图；2. 循环网络层。主要利用RNN（BiLSTM）对特征序列进行预测，对序列中的每个特征向量进行学习，并输出预测标签（真实值）分布；3. 转录层。主要利用CTC解决针对不同输入长度的文本字符对其问题，使用CTC损失把循环网络层获取的一系列标签分布转换成最终的标签序列。模型技术细节可参考CRNN论文。 图 10 CRNN模型结构\" 图 10 CRNN模型结构 ","date":"2021-04-17","objectID":"/thumbbox4/:3:2","tags":["计算机视觉","OCR","算法"],"title":"探索OCR——在印刷体表格识别的尝试","uri":"/thumbbox4/"},{"categories":["拇指盒"],"content":"文本纠错 通过识别模型的得到的预测结果往往不能达到100%的识别准确率，在文本纠错步骤中可以结合一些先验知识对识别结果进行改进： 针对表格中的金额，“,”和“.”字符比较接近，识别结果容易预测出错，可以金额中逗号出现的规则设计算法进行纠正； 预测文本中的括号缺失问题，可通过括号匹配算法进行纠正； 对预测文本中的日期、金额、公司名、证券代码等关键字段设计算法进行校验，对于不合法文本，采用多模型预测融合的策略进行纠正； 其他词法错误，通过训练语言模型进行纠正。 基于以上步骤，课题小组在现阶段实现对于财务报表的识别结果如图11所示。 图 11 利润表的OCR识别结果\" 图 11 利润表的OCR识别结果 ","date":"2021-04-17","objectID":"/thumbbox4/:3:3","tags":["计算机视觉","OCR","算法"],"title":"探索OCR——在印刷体表格识别的尝试","uri":"/thumbbox4/"},{"categories":["拇指盒"],"content":"下阶段工作展望 针对课题组在OCR算法方面的工作，下阶段主要的改进有： 数据方面，经过EDA数据增广后中文数据的样本量有了很大提升，但距离实际生产所需的数据量（百万级）还差很远。课题组还将尝试采用引入外部数据集与多种数据增广方法相结合的方式，建立适用于金融领域的文本识别数据库。 模型方面，现阶段课题组验证了CRNN模型在文本识别上的可行性，后续将测试并改进更多文本识别模型，构建模型库，并基于文本数据集完成模型训练和调优，提供可供系统调用的统一接口。 部署方面，现阶段的部署方案采用客户端与服务端共享文件夹，OCR程序后台轮询文件夹的方式实现。在下一阶段，将实现通过http请求方式调用服务。 ","date":"2021-04-17","objectID":"/thumbbox4/:4:0","tags":["计算机视觉","OCR","算法"],"title":"探索OCR——在印刷体表格识别的尝试","uri":"/thumbbox4/"},{"categories":["拇指盒"],"content":"参考文献 综合 Long, Shangbang, Xin He and Cong Yao. “Scene Text Detection and Recognition: The Deep Learning Era.” International Journal of Computer Vision 129 (2020): 161-184. Du, Yuning, Chenxia Li, Ruoyu Guo, X. Yin, Weiwei Liu, Jun Zhou, Y. Bai, Z. Yu, Y. Yang, Qingqing Dang and Haoshuang Wang. “PP-OCR: A Practical Ultra Lightweight OCR System.” ArXiv abs/2009.09941 (2020): n. pag. 表格识别 Li, Y., Z. Huang, Junchi Yan, Y. Zhou, Fan Ye and Xianhui Liu. “GFTE: Graph-based Financial Table Extraction.” ICPR Workshops (2020). Paliwal, Shubham, D. Vishwanath, R. Rahul, M. Sharma and L. Vig. “TableNet: Deep Learning Model for End-to-end Table Detection and Tabular Data Extraction from Scanned Document Images.” 2019 International Conference on Document Analysis and Recognition (ICDAR) (2019): 128-133. Khan, Saqib Ali, Syed Khalid, M. Shahzad and F. Shafait. “Table Structure Extraction with Bi-Directional Gated Recurrent Unit Networks.” 2019 International Conference on Document Analysis and Recognition (ICDAR) (2019): 1366-1371. 图像校正（边缘检测） Xie, Saining and Zhuowen Tu. “Holistically-Nested Edge Detection.” International Journal of Computer Vision 125 (2015): 3-18. 版面分析 Viana, Matheus Palhares and D. Oliveira. “Fast CNN-Based Document Layout Analysis.” 2017 IEEE International Conference on Computer Vision Workshops (ICCVW) (2017): 1173-1180. Xu, Yiheng, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei and M. Zhou. “LayoutLM: Pre-training of Text and Layout for Document Image Understanding.” Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining(2020): n. pag. Zhong, Xu, J. Tang and Antonio Jimeno-Yepes. “PubLayNet: Largest Dataset Ever for Document Layout Analysis.” 2019 International Conference on Document Analysis and Recognition (ICDAR) (2019): 1015-1022. 文本检测 Zhou, X., C. Yao, H. Wen, Yuzhi Wang, Shuchang Zhou, Weiran He and Jiajun Liang. “EAST: An Efficient and Accurate Scene Text Detector.” 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017): 2642-2651. Liao, Minghui, Zhaoyi Wan, C. Yao, Kai Chen and X. Bai. “Real-time Scene Text Detection with Differentiable Binarization.” AAAI (2020). Tian, Zhi, Weilin Huang, Tong He, Pan He and Yu Qiao. “Detecting Text in Natural Image with Connectionist Text Proposal Network.” ECCV (2016). 文本识别 Shi, Baoguang, X. Bai and Cong Yao. “An End-to-End Trainable Neural Network for Image-Based Sequence Recognition and Its Application to Scene Text Recognition.” IEEE Transactions on Pattern Analysis and Machine Intelligence 39 (2017): 2298-2304. Lee, Chen-Yu and Simon Osindero. “Recursive Recurrent Nets with Attention Modeling for OCR in the Wild.” 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016): 2231-2239. 文本检测+识别端到端 Bartz, C., Haojin Yang and C. Meinel. “SEE: Towards Semi-Supervised End-to-End Scene Text Recognition.” AAAI (2018). Busta, M., Lukás Neumann and Jiri Matas. “Deep TextSpotter: An End-to-End Trainable Scene Text Localization and Recognition Framework.” 2017 IEEE International Conference on Computer Vision (ICCV) (2017): 2223-2231. Xing, Linjie, Zeyong Tian, Weilin Huang and M. Scott. “Convolutional Character Networks.” 2019 IEEE/CVF International Conference on Computer Vision (ICCV) (2019): 9125-9135. 文本纠错 Yu, Junjie and Zhenghua Li. “Chinese Spelling Error Detection and Correction Based on Language Model, Pronunciation, and Shape.” CIPS-SIGHAN (2014). 数据处理 Wei, Jason and K. Zou. “EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks.” ArXiv abs/1901.11196 (2019): n. pag. 开源软件 国内OCR服务商: 百度/腾讯/阿里巴巴/第四范式/华为/旷视/商汤/科大讯飞/合合信息/易道博识/汉王数字/有道智云 开源OCR：JaidedAI/EasyOCR, PaddlePaddle/PaddleOCR, tesseract-ocr/tesseract, chineseocr/chineseocr, DayBreak-u/chineseocr_lite, OCR.space, AvensLab/OcrKing, open-mmlab/mmocr 数据增广：oh-my-ocr/text_renderer, jasonwei20/eda_nlp 文本纠错：shibing624/pycorrector, iqiyi/FASPell ","date":"2021-04-17","objectID":"/thumbbox4/:5:0","tags":["计算机视觉","OCR","算法"],"title":"探索OCR——在印刷体表格识别的尝试","uri":"/thumbbox4/"},{"categories":null,"content":"-- -- ","date":"2021-01-23","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"关于我 计算机系科研狗变身打工人 做过游戏，但很少打联机，独游爱好者 近三年以炼丹为主，机器视障 摄影入门级选手，相信计算机视觉与图形学会改变摄影的未来；对前沿技术很有好感dong kan xi kan，喜欢探索处在交叉边缘的技术 最近尝试在Tiddly wiki上记录一些生活工作的片段/想法💡和随记📒，戳这里 平时做过的一些实验/作品/项目放在了项目栏目 ","date":"2021-01-23","objectID":"/about/:1:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"关于『布丁布瓜』 布丁和布瓜画像 布丁（Pudding）和布瓜（Pourquoi）是由shake在2015年创造xia bian的两位AI小朋友。 布瓜是一位带上好奇心去追寻所爱的文艺青年，曾经疯癫叛逆如今率性而为。布瓜不停地在探寻追问周围的一切，他的世界是满怀疑问的炽热与激情。我想，大概是整个世界都被他无厘头的问题烦到发怒了吧。 布丁是一位冷言寡语的理性分析者，内心有着胆小懦弱的一面。布瓜口中的那个『手捧仙人掌深夜码代码的直男』。援引某位智者第一次见到布丁说过的话：『这家伙冷冷的外表下藏着某种细致不衰的温度』。 欢迎关注布丁布瓜的公众号（pudding_pourquoi） ","date":"2021-01-23","objectID":"/about/:2:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"联系我 kxie_shake@outlook.com ","date":"2021-01-23","objectID":"/about/:3:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":" 诶！该页面正在施工中。回上一页去看看吧。 Oops! This page is still under construction. Sorry about that. Go Back and start over. ","date":"2021-01-23","objectID":"/photos/:0:0","tags":null,"title":"图集","uri":"/photos/"},{"categories":["LMSI"],"content":"MIT-Adobe FiveK Dataset：MIT-Adobe美学增强数据集1 https://data.csail.mit.edu/graphics/fivek/ #Classification #Multi-label #Image enhancement 发布者：MIT CSAIL \u0026 Adobe Systems Inc. 发布日期：2011 样本数：5000 分辨率：不固定（RAW） 证书：LicenseAdobe, LicenseAdobeMIT fivekMIT-Adobe FiveK dataset \" MIT-Adobe FiveK dataset “We collected 5,000 photographs taken with SLR cameras by a set of different photographers. They are all in RAW format; that is, all the information recorded by the camera sensor is preserved. We made sure that these photographs cover a broad range of scenes, subjects, and lighting conditions. We then hired five photography students in an art school to adjust the tone of the photos. Each of them retouched all the 5,000 photos using a software dedicated to photo adjustment (Adobe Lightroom) on which they were extensively trained. We asked the retouchers to achieve visually pleasing renditions, akin to a postcard. The retouchers were compensated for their work.” ","date":"2021-01-19","objectID":"/lmsi-fivek/:1:0","tags":["计算机视觉","数据集"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek/"},{"categories":["LMSI"],"content":"目录 （文件太大，未全部下载） ","date":"2021-01-19","objectID":"/lmsi-fivek/:1:1","tags":["计算机视觉","数据集"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek/"},{"categories":["LMSI"],"content":"备注 提供全部数据下载（～50GB）和单张图片下载，可写脚本部分下载某几张图片或某个专家调色后的图片。数据集包含以下信息： 图片格式为PNG（可通过DCRAW、Adobe lightroom或其他图像工具读取），调色后的图片保存为TIFF格式 提供5位后期专家Adobe Lightroom catalog文件，即包含了5位专家对每张图片的调色记录和各参数值 提供每张图片的语义信息标注（室内/室外、拍摄时段、光线、拍摄主题等） ","date":"2021-01-19","objectID":"/lmsi-fivek/:1:2","tags":["计算机视觉","数据集"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek/"},{"categories":["LMSI"],"content":"引用 @inproceedings{fivek, author = \"Vladimir Bychkovsky and Sylvain Paris and Eric Chan and Fr{\\'e}do Durand\", title = \"Learning Photographic Global Tonal Adjustment with a Database of Input / Output Image Pairs\", booktitle = \"The Twenty-Fourth IEEE Conference on Computer Vision and Pattern Recognition\", year = \"2011\" } ","date":"2021-01-19","objectID":"/lmsi-fivek/:1:3","tags":["计算机视觉","数据集"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek/"},{"categories":["LMSI"],"content":"联系方式 fivek-dataset@googlegroups.com 数据使用 如未作特别说明，大部分公开数据集仅作为研究用途。 Bychkovsky, V., Sylvain Paris, E. Chan and F. Durand. Learning photographic global tonal adjustment with a database of input/output image pairs. [CVPR'11] ↩︎ ","date":"2021-01-19","objectID":"/lmsi-fivek/:1:4","tags":["计算机视觉","数据集"],"title":"MIT-Adobe FiveK dataset","uri":"/lmsi-fivek/"},{"categories":["LMSI"],"content":"Mars32k：火星数据集1 https://dominikschmidt.xyz/mars32k/ #Unsupervised 发布者：NASA/JPL-Caltech 发布日期：2018.11 样本数：32368 分辨率：560x500 sample data This dataset consists of about 32,000 color images collected by the Curiosity rover on Mars between August 2012 and November 2018. The images show various geographical and geological features of Mars such as mountains and valleys, craters, dunes and rocky terrain. All images have been scaled down using linear interpolation to 560x500px (some images have been cropped). The dataset is intended for unsupervised learning and the images are only labeled with the date they were taken on. This dataset only contains photos taken with Curiosity’s Mastcam camera and all grayscale or other images were removed. ","date":"2021-01-17","objectID":"/lsmi-mars32k/:1:0","tags":["计算机视觉","数据集"],"title":"Mars32k dataset","uri":"/lsmi-mars32k/"},{"categories":["LMSI"],"content":"目录 mars32k/ └[cr_]sol_nasa_filename.jpg # 文件命名规则： # cr_: 标记该图片已经过裁剪 # sol：标记拍摄这张图片的火星太阳日 # nasa_filename：标记NASA对该图片的命名 # 例如图片名称：725_0725MR0030950120402857E01_DXXX.jpg， # 表示该图片未经过裁剪，拍摄于登陆火星的第725天，名称为0725MR0030950120402857E01_DXXX ","date":"2021-01-17","objectID":"/lsmi-mars32k/:1:1","tags":["计算机视觉","数据集"],"title":"Mars32k dataset","uri":"/lsmi-mars32k/"},{"categories":["LMSI"],"content":"备注 数据集中的图像并非原始分辨率，都经过了线性插值，统一调整为560×500px，这些图片显示了火星的各种地理和地质特征，如山脉和山谷，陨石坑，沙丘和岩石地形。该数据集可用于一些计算机图像任务，比如于物体检测模型的训练、模拟仿真3D火星表面模型的搭建，还能作为天文学科科普所用。 ","date":"2021-01-17","objectID":"/lsmi-mars32k/:1:2","tags":["计算机视觉","数据集"],"title":"Mars32k dataset","uri":"/lsmi-mars32k/"},{"categories":["LMSI"],"content":"联系方式 schmidtdominik30@gmail.com 数据使用 如未作特别说明，大部分公开数据集仅作为研究用途。 https://dominikschmidt.xyz/mars32k/ ↩︎ ","date":"2021-01-17","objectID":"/lsmi-mars32k/:1:3","tags":["计算机视觉","数据集"],"title":"Mars32k dataset","uri":"/lsmi-mars32k/"},{"categories":["LMSI"],"content":"1. UEC Food-100：食物识别数据集1 http://foodcam.mobi/dataset100.html #Classification #Recognition #Multi-label 发布者：The University of Electro-Communications, Tokyo, Japan 发布日期：2012 样本数：16557 类别数：100 分辨率：不固定 证书：Research Only uecfood-100UEC Food 100 dataset \" UEC Food 100 dataset The dataset “UEC FOOD 100” contains 100-kind food photos. Each food photo has a bounding box indicating the location of the food item in the photo. Most of the food categories in this dataset are popular foods in Japan. Therefore, some catarogies might not be familiar with other people than Japanese. ","date":"2021-01-16","objectID":"/lmsi-uec-food/:1:0","tags":["计算机视觉","数据集"],"title":"UEC food datasets","uri":"/lmsi-uec-food/"},{"categories":["LMSI"],"content":"2. UEC Food-256：食物识别数据集2 http://foodcam.mobi/dataset256.html #Classification #Recognition 发布者：The University of Electro-Communications, Tokyo, Japan 发布日期：2014 样本数：16557 类别数：256 分辨率：不固定 证书：Research Only uecfood-256UEC Food 256 dataset \" UEC Food 256 dataset The dataset “UEC FOOD 256” contains 256-kind food photos. Each food photo has a bounding box indicating the location of the food item in the photo. Most of the food categories in this dataset are popular foods in Japan and other countries. Therefore, some catarogies might not be familiar with other people than Japanese. ","date":"2021-01-16","objectID":"/lmsi-uec-food/:2:0","tags":["计算机视觉","数据集"],"title":"UEC food datasets","uri":"/lmsi-uec-food/"},{"categories":["LMSI"],"content":"3. UECFoodPix/UECFoodPixComplete：食物分割数据集34 http://mm.cs.uec.ac.jp/uecfoodpix/ #Classification #Segmentation 发布者：The University of Electro-Communications, Tokyo, Japan 发布日期：2020.7(UECFoodPix), 2020.10(UECFoodPixComplete) 样本数：9000 (train) + 1000 (test) 类别数：103 分辨率：不固定 证书：Research Only uecfoodpixUECFoodPix/UECFoodPixComplete dataset \" UECFoodPix/UECFoodPixComplete dataset UECFoodPix and UECFoodPixComplete are food images dataset with segmentation masks including 9,000 images for training and 1,000 image for testing. The Segmentation masks are augmented by food category. In UECFoodPix, the mask images is created using a bounding box and GrabCut, and In UECFoodPixCimplete there is provided manualy.The mask images have pixel-wise food 103 class labels, and only R(red) channel have this labels. ","date":"2021-01-16","objectID":"/lmsi-uec-food/:3:0","tags":["计算机视觉","数据集"],"title":"UEC food datasets","uri":"/lmsi-uec-food/"},{"categories":["LMSI"],"content":"目录 # UEC Food-100 UCEFOOD100/ └[1-100]/ # 1-100类食物图片文件夹 │　└*.jpg # 属于该类的图片 │　└bb_info.txt # 该类所有图片的bouding box信息 └category_ja_{euc, sjis, utf8}.txt # 类别ID和对应标签（日文） └category.txt # 类别ID和对应标签（英文） └multiple_food.txt # 包含多标签的图片名和对应的类别ID └README.txt # 说明文档 # UEC Food-256 UCEFOOD256/ └[1-256]/ # 1-256类食物图片文件夹 │　└*.jpg # 属于该类的图片 │　└bb_info.txt # 该类所有图片的bouding box信息 └category.txt # 类别ID和对应标签（英文） └README.txt # 说明文档 # UECFoodPixComplete UECFOODPIXCOMPLTE/ ├data/ └UECFoodPIXCOMPLTE/ └train/ │　└img/*.jpg # 训练图片 │　└mask/*.png # 训练图片分割Mask └test/ │　└img/*.jpg # 测试图片 │　└mask/*.png # 测试图片分割Mask └category.txt # 类别ID和对应标签（英文） └train.txt # 训练数据（图片名） └test.txt # 测试数据（图片名） ","date":"2021-01-16","objectID":"/lmsi-uec-food/:3:1","tags":["计算机视觉","数据集"],"title":"UEC food datasets","uri":"/lmsi-uec-food/"},{"categories":["LMSI"],"content":"备注 UECFoodPix和UECFoodPixComplete包含相同的图像，不同在于分割Mask的生成方式不同，UECFoodPix中利用Bounding Box和GrabCut方法生成分割Mask，而在UECFoodPixComplete中分割Mask为手工标注。 其他食物数据集还有：UNIMIB Food, Food-475, VIREO, Food-101, and Food-50。 ","date":"2021-01-16","objectID":"/lmsi-uec-food/:3:2","tags":["计算机视觉","数据集"],"title":"UEC food datasets","uri":"/lmsi-uec-food/"},{"categories":["LMSI"],"content":"联系方式 food-group@mm.cs.uec.ac.jp (Prof. Keiji Yanai) 数据使用 如未作特别说明，大部分公开数据集仅作为研究用途。 Matsuda, Y., H. Hoashi and K. Yanai. Recognition of Multiple-Food Images by Detecting Candidate Regions. [ICME'12] ↩︎ Kawano, Y. and K. Yanai. Automatic Expansion of a Food Image Dataset Leveraging Existing Categories with Domain Adaptation. [ECCV'14 Workshops] ↩︎ Ege, Takumi, Wataru Shimoda and K. Yanai. A New Large-scale Food Image Segmentation Dataset and Its Application to Food Calorie Estimation Based on Grains of Rice. [MADiMa'19] ↩︎ K. Okamoto and K. Yanai: UEC-FoodPix Complete: A Large-scale Food Image Segmentation Dataset. [MADiMa'21] ↩︎ ","date":"2021-01-16","objectID":"/lmsi-uec-food/:3:3","tags":["计算机视觉","数据集"],"title":"UEC food datasets","uri":"/lmsi-uec-food/"},{"categories":["LMSI"],"content":"Mut1ny：头部/面部分割数据集1 #Segmentation 发布者：Mut1ny 发布日期：2020.8 样本数：16557 类别数：11 分辨率：300x280 / 304x304 / 256x256 / 其他 证书：CC-BY-NC-SA lmsi-1Mut1ny face-head segmentation dataset \" Mut1ny face-head segmentation dataset This new arrangement of the dataset contains over 16.5k (16557) fully pixel-level labeled segmentation images. Facial images are included from different ethnicity, ages and genders making it a well balanced dataset. Also there is a wide variety of facial poses and different camera angles to provide a good coverage from -90 to 90 degrees facing. Some images even contain multiple head/face segmentation depending on if the second or third face takes up enough screen real estate space. ","date":"2021-01-13","objectID":"/lmsi-mut1ny/:1:0","tags":["计算机视觉","数据集"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny/"},{"categories":["LMSI"],"content":"目录 ","date":"2021-01-13","objectID":"/lmsi-mut1ny/:1:1","tags":["计算机视觉","数据集"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny/"},{"categories":["LMSI"],"content":"真值（~/labels） 不同类别的rgb颜色编码如下： lmsi-1-figGround truth \" Ground truth ","date":"2021-01-13","objectID":"/lmsi-mut1ny/:1:2","tags":["计算机视觉","数据集"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny/"},{"categories":["LMSI"],"content":"备注 2500张真实图像 (~/real_photos)，部分做旋转处理，分辨率大部分为304x304和256x256；其余14057张图像由23位志愿者（13男+10女）的面部在不同背景和角度下合成得到，分辨率为300x280。 ","date":"2021-01-13","objectID":"/lmsi-mut1ny/:1:3","tags":["计算机视觉","数据集"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny/"},{"categories":["LMSI"],"content":"额外的商业版本 目前标注好了44000张图像（至2021.1），新增了3个类别。可联系发布者提供。 ","date":"2021-01-13","objectID":"/lmsi-mut1ny/:1:4","tags":["计算机视觉","数据集"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny/"},{"categories":["LMSI"],"content":"联系方式 data@mul1ny.com 数据使用 如未作特别说明，大部分公开数据集仅作为研究用途。 https://www.mut1ny.com ↩︎ ","date":"2021-01-13","objectID":"/lmsi-mut1ny/:1:5","tags":["计算机视觉","数据集"],"title":"Mut1ny Face Head Segmentation Dataset","uri":"/lmsi-mut1ny/"},{"categories":["拇指盒"],"content":"炼丹技巧 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare/:1:0","tags":["计算机视觉"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare/"},{"categories":["拇指盒"],"content":"All in Linux：一个算法工程师的IDE断奶之路 在合格的炼丹师面前，python可能被各种嫌弃…… 夕小瑶，公众号：夕小瑶的卖萌屋 前段时间在远端部署OCR模型的时候，几度被无法与外网沟通的服务器搞得十分泄气。直到项目阶段性地告一段落后才看到这篇文章，真是深感相见恨晚，接下来可以实践一下了。 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare/:1:1","tags":["计算机视觉"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare/"},{"categories":["拇指盒"],"content":"PyTorch常用代码段合集 本文是PyTorch常用代码段合集，涵盖基本配置、张量处理、模型定义与操作、数据处理、模型训练与测试等5个方面，还给出了多个值得注意的Tips，内容非常全面。 公众号：夕小瑶的卖萌屋 炼丹常用的代码模板，可以在此基础上写一套适用自己的模板。 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare/:1:2","tags":["计算机视觉"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare/"},{"categories":["拇指盒"],"content":"一文搞懂 PyTorch 内部机制 这篇博文是一篇非常新的介绍PyTorch内部机制的文章，作者Edward Z Yang来自于Stanford大学，是PyTorch的核心开发者之一。文章中介绍了如何阅读PyTorch源码和扩展PyTorch的技巧。 ArchWalker，公众号：夕小瑶的卖萌屋 这是一篇好看的翻译文章，对于了解PyTorch底层的一些原理很有帮助1。 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare/:1:3","tags":["计算机视觉"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare/"},{"categories":["拇指盒"],"content":"AI识别彻底懵逼，这到底是「牛」还是「鲨」？ 我和编辑部的同事因为上图到底是牛还是鲨吵了起来图片，我说这张图更像图片，同事说更像图片，我们差点儿就GAN了一架！ 耳洞打三金，公众号：AI科技评论 关于是牛还是鲨的GAN架文章，故事告诉了我们人的视觉和机器识别模型存在的一些认知差异。 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare/:1:4","tags":["计算机视觉"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare/"},{"categories":["拇指盒"],"content":"小程序 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare/:2:0","tags":["计算机视觉"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare/"},{"categories":["拇指盒"],"content":"GeoPattern 用一个字符串生成SVG格式的图案，提供了多种语言的实现方式。用到了SHA算法，具体实现还需要再读一读源码。哦！想起来本周OpenAI极其可爱的Dall-E项目——用一串文本生成符合描述的图片，大佬们用PyTorch的复现也正在路上，有空可以玩一玩。 举几个GeoPattern的栗子： GeoPattern examples\" GeoPattern examples 再举一个Dall-E的栗子： Dall-E examples \" Dall-E examples ","date":"2021-01-11","objectID":"/thumbbox-sundayshare/:2:1","tags":["计算机视觉"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare/"},{"categories":["拇指盒"],"content":"EDA (Easy Data Augmentation) 最近在训练文本识别模型的时候，遇到了中文语料不足的问题，想到可以对现有的语料库做数据增强，于是发现了这篇应用于文本分类的数据增强论文——EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks。其中的算法思想很朴素，作者提出了四种在原句子基础上进行调整的操作：随机插入、随机删除、随机交换和同义词替换，利用这种数据增强的方法可以在原模型基础上提高文本分类的准确率。 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare/:2:2","tags":["计算机视觉"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare/"},{"categories":["拇指盒"],"content":"书籍 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare/:3:0","tags":["计算机视觉"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare/"},{"categories":["拇指盒"],"content":"Kubernetes in Action 中文版 由七牛容器云团队翻译。最近在读，作为K8s的入门讲得针不戳。 ","date":"2021-01-11","objectID":"/thumbbox-sundayshare/:3:1","tags":["计算机视觉"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare/"},{"categories":["拇指盒"],"content":"Google Python Style Guide 英文 中文 狗家也提供其他语言的styleguide可以参考。在团队协作的工程项目中把代码写规范还是很重要的，希望人人都可以献出一份爱，世界将充满更多毛绒绒的头发。 原文链接：http://blog.ezyang.com/2019/05/pytorch-internals/ ↩︎ ","date":"2021-01-11","objectID":"/thumbbox-sundayshare/:3:2","tags":["计算机视觉"],"title":"近期的摸鱼拾珠","uri":"/thumbbox-sundayshare/"},{"categories":["拇指盒"],"content":"Introduction ","date":"2020-11-10","objectID":"/thumbbox2/:1:0","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Basic pipeline Detection+Recognition End-to-end image-20201107140006891fig1 \" fig1 ","date":"2020-11-10","objectID":"/thumbbox2/:1:1","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Challenges for general text detection and recognition Diversity and variability different languages/color/fonts/size/orientations/shapes Complexity and interference of background similar patterns/occlusions Imperfect image conditions Low resolution/shot angle/blurred(unfocused)/noise/light ","date":"2020-11-10","objectID":"/thumbbox2/:1:2","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Methods before DL ","date":"2020-11-10","objectID":"/thumbbox2/:2:0","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Text detection CCA (Connected Components Analysis)：连通域分析法 提取出包含文本的候选区域（color clustering/extreme region extration） 从候选区域中过滤背景，即分割出文本类（特征提取，分类/分割） 特征：MSRE/SWT/SIFT/SURF/LBP/灰度共生矩阵等 分类器：Kmeans/KNN/SVM/NN/DecisionTree等 Huang et al., 2013; Neumann and Matas, 2010; Epshtein et al., 2010; Tu et al., 2012; Yin et al., 2014; Yi and Tian, 2011; Jain and Yu, 1998 SW (Siliding window)：滑动窗口法 利用不同大小的滑动窗口对窗口区域进行二分类（包含/不包含文本） 通过形态学操作/CRF/Graph-based-method等对窗口进行合并 Lee et al., 2011; Wang et al., 2011; Coates et al., 2011; Wang et al., 2012 ","date":"2020-11-10","objectID":"/thumbbox2/:2:1","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Text recognition 基于特征的方法 划分子问题 二值化(text binarization)-\u003e文本行切分(text line segmentation)-\u003e字符划分(character segmentation)-\u003e单字符识别(single character recognition)-\u003e单词校正(word correction) feature-based: Shi et al., 2013; Yao et al., 2014; Rodriguez-Serrano et al., 2013, 2015; Gordo, 2015; Almazan et al., 2014 text binarization: Zhiwei et al., 2010; Mishra et al., 2011; Wakahara and Kita, 2011; Lee and Kim, 2013 text line segmentation: Ye et al., 2003 character segmentation: Nomura et al., 2005; Shivakumara et al., 2011; Roy et al., 2009 single character recognition: Chen et al., 2004; Sheshadri and Divvala, 2012 word correction: Zhang and Chang, 2003; Wachenfeld et al., 2006; Mishra et al., 2012; Karatzas and Antonacopoulos, 2004; Weinman et al., 2007 ","date":"2020-11-10","objectID":"/thumbbox2/:2:2","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"End-to-end (detection+recognition) Wang et al., 2011：nearest-neighbor classifier+HoG Neumann and Matas, 2013：decision delay ap- proach+dynamic programming algorithm Wang et al., 2011; Neumann and Matas, 2013 ","date":"2020-11-10","objectID":"/thumbbox2/:2:3","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Methods based on DL ","date":"2020-11-10","objectID":"/thumbbox2/:3:0","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Text detection 早期尝试 基于目标检测的方法 Anchor-based TextBoxes (Liao et al., 2017)：anchor-based, SSD [code] EAST (Zhou et al., 2017)：anchor-based, u-net, simple pipeline and real-time speed [code] Region proposal Ma et al., 2017: solve text of arbitrary orientations [code] FEN (Zhang et al., 2018) Specific task/case (w/o sub-text) ITN (Wang et al., 2018): multi-orientated text [code] Zhang et al., 2019: irregular text Wang et al., 2019b: irregular text Sub-text components: better flexibility over shapes and aspect ratios of text Use NN to predict local attributes or segments Post-processing to re-construct text instance Pixel level PixelLink (Deng et al., 2018) [code] Border learning method (Wu and Natarajan, 2017) Component-level CTPN (Tian et al., 2016) [code] SegLink (Shi et al., 2017a) [code] Corner Localization (Lyu et al., 2018b) TextSnake (Long et., 2018) Character-level Braek et al., 2019b ","date":"2020-11-10","objectID":"/thumbbox2/:3:1","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Text recognition image-20201107191619556fig2 \" fig2 CTC-based (Connectionist Temporal Classification，一种时序分类算法) (CNN+RNN+CTC) CNN layer：CNN Encoder提取文本图像特征，形成若干特征序列 RNN layer：RNN进一步提取文本序列特征 Transcription layer (CTC loss)：CTC解决字符对齐问题 CRNN (Shi et al., 2017b) [code] DTRN (He et al., 2016) Gao et al., 2017 Yin er al., 2017 Encoder-Decoder (CNN+Seq2Seq+Attention) CNN layer：CNN Encoder提取文本图像特征，形成若干特征序列 Seq2Seq+Attention：好处是输出向量长度可以与输入不同 Transcription layer (Classification loss) Lee and Osindero, 2016 Cheng et al., 2018 Bai et al., 2018 Liu et al., 2018d Irregular text Case ","date":"2020-11-10","objectID":"/thumbbox2/:3:2","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"End-to-end (Detection+Recognition/Text Spotting) Two-stage pipeline: feature map instead of images are cropped and fed to recognition module SEE (Bartz et al., 2017) [code] Busta et al., 2017 [code] Li et al., 2017a He et al., 2018 Liu et al., 2018c One-stage pipeline: predict character and text bounding boxes as well as character type segmentation maps in parallel Xing et al., 2019 ","date":"2020-11-10","objectID":"/thumbbox2/:3:3","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Auxiliary techniques that support detection and recognition Synthetic Data Weakly and Semi-Supervision More paper reference https://github.com/Jyouhou/SceneTextPapers ","date":"2020-11-10","objectID":"/thumbbox2/:3:4","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Datasets image-20201107191949977 \" image-20201107191949977 Dataset (Year) Image Num (train/test) Text Num (train/test) Orientation Language Characteristics Detec/Recog Task End2End ==== ==== ==== ==== ==== ==== ICDAR03 (2003) 509 (258/251) 2276 (1110/1156) Horizontal EN - ✓/✓ ICDAR13 Scene Text(2013) 462 (229/233) - (848/1095) Horizontal EN - ✓/✓ ICDAR15 Incidental Text(2015) 1500 (1000/500) - (-/-) Multi-Oriented EN Blur, Small, Defocused ✓/✓ ICDAR17 / RCTW (2017) 12263 (8034/4229) - (-/-) Multi-Oriented CN - ✓/✓ Total-Text (2017) 1555 (1255/300) - (-/-) Multi-Oriented, Curved EN, CN Irregular polygon label ✓/✓ SVT (2010) 350 (100/250) 904 (257/647) Horizontal EN - ✓/✓ KAIST (2010) 3000 (-/-) 5000 (-/-) Horizontal EN, KO Distorted ✓/✓ NEOCR (2011) 659 (-/-) 5238 (-/-) Multi-oriented 8 langs - ✓/✓ CUTE (2014) or here 80 (-/80) - (-/-) Curved EN - ✓/✓ CTW (2017) 32K ( 25K/6K) 1M ( 812K/205K) Multi-Oriented CN Fine-grained annotation ✓/✓ CASIA-10K (2018) 10K (7K/3K) - (-/-) Multi-Oriented CN ✓/✓ Detection Only ==== ==== ==== ==== ==== ==== OSTD (2011) 89 (-/-) 218 (-/-) Multi-oriented EN - ✓/- MSRA-TD500 (2012) 500 (300/200) 1719 (1068/651) Multi-Oriented EN, CN Long text ✓/- HUST-TR400 (2014) 400 (400/-) - (-/-) Multi-Oriented EN, CN Long text ✓/- ICDAR17 / RRC-MLT (2017) 18000 (9000/9000) - (-/-) Multi-Oriented 9 langs - ✓/- CTW1500 (2017) 1500 (1000/500) - (-/-) Multi-Oriented, Curved EN Bounding box with_14_ vertexes ✓/- Recognition Only ==== ==== ==== ==== ==== ==== Char74k (2009) 74107 (-/-) 74107 (-/-) Horizontal EN, Kannada Character label -/✓ IIIT 5K-Word (2012) 5000 (-/-) 5000 (2000/3000) Horizontal - cropped -/✓ SVHN (2010) - (-/-) 600000 (-/-) Horizontal - House number digits -/✓ SVTP (2013) 639 (-/639) - (-/-) EN Distorted -/✓ ","date":"2020-11-10","objectID":"/thumbbox2/:4:0","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Evaluation ","date":"2020-11-10","objectID":"/thumbbox2/:5:0","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Detection Metrics Precision ($P$): the proportion of predicted text instances that can be matched to gt labels. Recall ($R$): the porportion of gt labels that have correspondents in the predicted list. F1-Score $$ F_1 = \\frac{2PR}{P+R} $$ And others ","date":"2020-11-10","objectID":"/thumbbox2/:5:1","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Recognition Metrics Character-level(#characters are recognized)/word level(whether the predicted word exactly the same as gt) image-20201108160251229 \" image-20201108160251229 ","date":"2020-11-10","objectID":"/thumbbox2/:5:2","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Applications Automatic Data Entry Identity Authentication Augmented Computer Vision Intelligence Content Analysis ","date":"2020-11-10","objectID":"/thumbbox2/:6:0","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":"Reference CRNN+CTC文字识别 CTPN原理与实现 完全解析RNN, Seq2Seq, Attention注意力机制 ","date":"2020-11-10","objectID":"/thumbbox2/:7:0","tags":["计算机视觉","OCR","论文"],"title":"旷视文本检测与识别综述笔记","uri":"/thumbbox2/"},{"categories":["拇指盒"],"content":" 最近在读尤瓦尔.赫拉利的《人类简史：从动物到上帝》。书中作者用比较宏观和独到的观点介绍了人类历史进程中的三场重要革命：认知革命（Cognitive Revolution）、农业革命（Agricultural Revolution）和科学革命（Scientific Revolution）。以下摘录并总结一些自己认为有趣的观点。 ","date":"2020-10-11","objectID":"/thumbbox1/:0:0","tags":["历史"],"title":"人类简史，一些有趣的观点（其一）","uri":"/thumbbox1/"},{"categories":["拇指盒"],"content":"八卦和虚构故事使大规模的有序合作成为可能 智人是一种社会性的动物，社会合作是我们得以生存和繁衍的关键。 早期形成的亲近小团体中，智人与其他生物没什么不同。人们需要十分了解彼此，才有可能进行分工合作。一旦团体过大，社交秩序就会崩坏，团体就会分裂。用关系图模型来做类比的话，每个个体节点需要与其他个体节点都有联系，才会形成合作。 认知革命以后，智人发展出了“八卦”这种能力——即人们能够在彼此背后“说坏话”达数小时之久。这种能力本质上促进了更高效信息的交换和传播，而借由八卦来维持的最大“自然”团体人数大约是150人。在这种关系图中，每个个体节点只要同属于一个连通域中，就能进行信息传递，形成合作。 之后，智人又逆天地发明了“虚拟故事”，使得即使是互相不认识的陌生人，只要相信这个“虚拟故事”，就能形成共同合作。这种“虚拟故事”使得团体的规模空前扩大，合作趋于有序、精细和专业化。神、国家、公司、法律等等这些概念所形成的故事网络，直至今日早已构建出了一个“虚拟世界”。在这种关系图中，“故事”通过当时最先进的媒介进行传播，在可达范围内的所有个体节点只要相信这个故事为真，就可以与其他同类个体节点形成合作交互。 ","date":"2020-10-11","objectID":"/thumbbox1/:1:0","tags":["历史"],"title":"人类简史，一些有趣的观点（其一）","uri":"/thumbbox1/"},{"categories":["拇指盒"],"content":"人类发明了它，也被它驯化 ","date":"2020-10-11","objectID":"/thumbbox1/:2:0","tags":["历史"],"title":"人类简史，一些有趣的观点（其一）","uri":"/thumbbox1/"},{"categories":["拇指盒"],"content":"农业革命（P2C5） 农业革命确实养活了更多人和动植物，实现了演化意义上的成功，也为农民带了一定的利益。但作者在书中提到，农业革命是史上最大的一桩骗局，它本质上让更多的人以更糟的状况活下去。主要影响有几个： 人类的身体演化目的并不是让我们去弯腰清石块、努力挑水桶的，适应这些活动让人类付出了诸如椎间盘突出、关节炎和疝气等疾病代价； 人类的活动范围更加聚集，人口增加、聚落密度也随之增大，导致传染病更容易滋生和扩散； 人类的饮食更加单一化。谷物作为主食不仅矿物质和维生素含量不足、难以消化，还对牙齿和牙龈大大有害； 人类越来越依赖于一方之土。在战争暴力和自然灾害面前，人们或死守田地，或忍饥挨饿，对于未来的忧虑也进一步加深。 农业革命豢养了一群养尊处优，娇生惯养的精英分子； 农业革命使人类开始落入奢侈生活的陷阱。想让生活变得轻松的努力，反而给人带来无穷的麻烦（如劳心劳力地工作、生活焦虑等）； 总体来看，农业革命也使那些被驯养的动植物成了受害者。鸡鸭牛羊和小麦们虽然依靠人类遍布了整个世界，但是它们或许也会想：我宁愿成为濒危而自由的个体，也不要做交易与供养的奴隶。 ”人类以为自己驯化了植物，但其实是植物驯化了智人。“ 想象的秩序（P2C6） “想象构建的秩序塑造了我们的欲望，而个人欲望成了虚构秩序最强大的守护者。” “例如，浪漫主义告诉我们，为了要尽量发挥潜力，就必须尽量累积不同的经验。必须体会不同的情感，尝试不同的关系，品尝不同的美食，还必须学会欣赏不同风格的音乐。而其中最好的一种办法，就是摆脱日常生活及工作，远离熟悉的环境，前往遥远的国度，好亲身‘体验’不同的文化、气味、美食和规范；消费主义告诉我们，想要快乐，就该去买更多的产品、更多的服务。如果觉得少了什么，或者有什么不够舒服的地方，那很可能是该买些什么商品（新车、新衣服、有机食品），或买点什么服务（清洁工、心理咨询、瑜伽课）。” “一如古埃及精英分子，现在大多数人一生汲汲营营，也都是想盖起某种金字塔，只不过这些金字塔在不同文化里会有不同的名字、形体和规模罢了。” “身为人类，我们不可能脱离想象所构建出的秩序。每一次我们以为自己打破了监狱的高墙、迈向自由的前方，其实只是到了另一件更大的监狱，把活动范围稍稍加以扩大而已。” 文字与计算机（P2C7） 文字与计算机的发明是对人脑存储的增强，但它在某种程度上也改变了人类的思维和看待这个世界的方式。这种改变很大程度上源于文字和计算机系统的归档、编目和检索技术，这与我们大脑原本内建机制非常不同。 “在大脑里，所有都自由地互相连接。比如我在和另一半一起去办新家抵押贷款的时候，就想到我们一起住的第一个地方，这又让我想到去新奥尔良度的蜜月，再想到鳄鱼，再想到西方的恶龙，再想到歌剧《尼布龙根的指环》；结果我不知不觉就哼起了歌剧里面齐格飞的主旋律，把银行职员搞得一头雾水。” 对于文字系统，必须分门别类才易于检索。例如古代的官僚制度，各种数据用类似于一种抽屉系统进行存储——一个抽屉放住宅抵押贷款，一个放结婚证书，第三个放税务登记材料，第四个放诉讼案件卷宗……操作这种系统的人必须接受训练，思考方式不能像一般人，而得有专业文书和会计的样子。 数字系统这种部分表意的文字使得存储和处理数据的效率进一步提升。不仅在像物理和工程方面发挥作用，甚至像“贫穷”、“幸福”和“诚实”这些概念也能翻译成一个又一个的数字，成了“贫穷线”、“主观幸福感程度”、“信用等级”，几乎整个知识领域都能快要和人类的口语语言脱节，而由数学符号独挑大梁。 计算机所使用的二进制程序语言，仅仅只由0和1两个符号构成，其运行机制基于电子元件和许多逻辑门电路，即使人类创造了各种各样的高级编程语言，其语法仍然与自然语言相差甚远，人类依然需要用计算思维去为程序编写代码，为各种各样的数据去设计高效的增删改查逻辑。 “人工智能的领域还希望能够完全在计算机二进制的程序语言的上创造一种新的智能。像科幻电影《黑客帝国》或《终结者》，就都预测着总有一天这些二进制语言会抛下人性给它们的枷锁，而人类想要反扑的时候，它们就会试图消灭人类。” “文字本来应该是人类意识的仆人，但现在正在反仆为主。计算机并不能理解智人如何说话、感觉和编制梦想，所以我们现在反而是用一种计算机能够理解的数字来教智人如何说话、感觉和编织梦想。” ","date":"2020-10-11","objectID":"/thumbbox1/:2:1","tags":["历史"],"title":"人类简史，一些有趣的观点（其一）","uri":"/thumbbox1/"},{"categories":["冬日物语"],"content":"Z. Alphabet 左伊所写小说的主人公名字以时间顺序按26个英文字母打头，当写完『Z』时，就可以集结出版——《Alphabet小说集 by Zoe》。这将是她出版的第一本小说集，为此她准备请Google的专家帮助分析预测市场的销量和反馈。 如果市场反应良好，她甚至还考虑从『A』开始再出一套新的小说，甚至更多。她了解到Google母公司的一套『自动小说生成』技术，该技术可以学习一个人以往小说的写作风格，并根据需要自动创作出新的小说，其作品效果让人惊叹。更厉害的是，它能够实现自学习，学习自己创作的小说进而再创作。如此，就能日复一日地产出，一本接一本地出版了。 左伊笑得美滋滋，她仿佛走进了字母表的圈圈。 ","date":"2019-01-05","objectID":"/alphabet/:1:0","tags":null,"title":"冬日物语Ⓩ 字母表","uri":"/alphabet/"},{"categories":["冬日物语"],"content":"Y. Wonder Wheel 『生活就像随着时间转动的摩天轮。它缓缓地升起，带你将脚底的风景看得越来越多，越来越远。成长、友谊、爱情、事业，生活的阿司匹林会随着高度逐渐刺激大脑，美化物像，它们都将在你理想的欲望中得到虚无的满足。摩天轮不会停止，生活的高点在霓虹光影之间缓缓落幕，那些想要跳脱的贫乏与平庸，想要梦幻追寻的刺激与想象，也终将在渐远渐近中回归现实与当下的真实。一次次的升起与降落，一次次的欢笑泪水与扼腕叹息，激情背后，只是平淡的重复轮回。』 尤兰塔观影笔记，摩天轮 by 伍迪艾伦，2017 ","date":"2019-01-04","objectID":"/wonder-wheel/:1:0","tags":null,"title":"冬日物语Ⓨ 摩天轮","uri":"/wonder-wheel/"},{"categories":["冬日物语"],"content":"X. Fireworks 赞茜在白纸上用水粉画了一朵红色郁金香。她将画拿到炭火前小心地捂暖，使之挥发去多余的颜料。 夜色降临，她手捧着鲜花，高高地举起，默默地许愿。看着深蓝画布上耀眼的花火，她希望新年的愿望一切成真。 ","date":"2019-01-03","objectID":"/fireworks/:1:0","tags":null,"title":"冬日物语Ⓧ 花火","uri":"/fireworks/"},{"categories":["冬日物语"],"content":"W. Time Machine 『我想去看看8小时，8天，8年后（前）的我，那（当）时的我是怎么样呢？』温妮有时在书桌前写不进作业时会想。 『那就去吧！地球就是一个圆形的时钟，当你从本初子午线出发，向东走大约120度，你就可以看到8小时以后的故乡和亲人；向西走大约120度，你就可以看到8小时以前的同学和朋友。如果你还有力气绕着时间一直一直地走，你就有希望看到8天，甚至8年后（前）的这些人了。但是有一点——你没办法看见自己。你此刻的想法行为受制于过去且影响着未来，他们是时刻变化着的，未来或过去永远不是一个确定的答案。』 『嗯，那这么说，当我漫步时空，看到身边的这些人时，是不是，也就可以隐约看到时间跨度下亲近者身旁的自己了呢？』 ","date":"2019-01-02","objectID":"/time-machine/:1:0","tags":null,"title":"冬日物语Ⓦ 时光机","uri":"/time-machine/"},{"categories":["冬日物语"],"content":"T. Hoilday 蒂芬妮平日里是个工作狂。 一到假期，她就希望『什么都不去，什么都不想，只要安安静静地躺在床上，舒舒服服地睡个懒觉。』所以，当外面的人都在狂欢、庆祝、祈愿时，她就一直呆在家里，坐看一年又一年的交替。 等到假期结束，她又将变身工作狂状态。 ","date":"2018-12-30","objectID":"/hoilday/:1:0","tags":null,"title":"冬日物语Ⓣ 假期","uri":"/hoilday/"},{"categories":["冬日物语"],"content":"S. Camera 大街上，地铁口，停车场，休息室，电脑桌，手机屏，字间句读。斜阳的阴影底下好像所有人都在看着你。 斯蒂芬照例举着他的迷你相机，穿梭在这个城市的高楼与窄弄之间。这个相机从英国一路跟随他来中国，他想记录他所看到的一切。 通勤者，流浪汉，保安，女人的裙摆，男人的面孔，短促的语音，远处的呼喊…… 『你为什么什么都要拍？你不知道有些景物一点意思都没有，有些人厌恶面对陌生人的镜头吗？』有人问过斯蒂芬这样的话。 『我，我不知道。但我只想记录真实。我要把这些影像带回国，给我的母亲也看一看。要知道，她从来都没有出过国。』 ","date":"2018-12-29","objectID":"/camera/:1:0","tags":null,"title":"冬日物语Ⓢ 相机","uri":"/camera/"},{"categories":["冬日物语"],"content":"R. Novel Muggles who both asked tentatively, Harry had resumed his eyes, causing a grip. “I’m not exist. But this faded from the plants than Tonks.” What have the air, as for it. We are you. I’ve read aloud. “The Ministry of yours?” Xenophilius gulped. “But what really. she was slipping over the open windows towered over Harry?” “Sorry, Harry, Ron, who had grown faint, misty greenish glitter. Ron once more are about him back. Who’d want them to anyone. She told me your own trunk slid the entire school. They crept closer, you‘ll do anything. But how these old sweater and Ron some other end. I’ve seen a great big enough priceless. She was supposed she said. “Sirius was staring and a dim, silvery glow of the classroom door and trailing shawls. Harry streaked past in surprise. Harry at the distance, he didn’t like. She leapt lightly on Privet Drive only set a polite, he ought to the bag of Lake Windermere, kept cropping up, following morning, though. This one corner, a crumpled the door neighbor’s lawn and went very end of rock unrelieved by the snake hadn’t been bitter and arrangements. 罗伯特认为，小说将虚构交给作者，将想象留给读者。 ","date":"2018-12-28","objectID":"/novel/:1:0","tags":null,"title":"冬日物语Ⓡ 小说","uri":"/novel/"},{"categories":["冬日物语"],"content":"Q. Cake 昆汀给妈妈买了一个生日蛋糕。 ​ 他想象着白色奶油上的一颗颗红色樱桃，就好像白色雪地里的朵朵红花。白雪红花，他看到了冬日对早春的向往。 ","date":"2018-12-27","objectID":"/cake/:1:0","tags":null,"title":"冬日物语Ⓠ 蛋糕","uri":"/cake/"},{"categories":["冬日物语"],"content":"P. Paper 在帕特里克看来，一篇能够发表在顶级会议、具有创新贡献的论文一定有着出色的版面。相反，当审稿人看到一篇图文并茂且排版精良的论文时，也极有可能接收其中提出的方法或思想。 为此，他还写了一篇论文，提出了一个模型，该模型可以通过学习往年顶会录用的文章来建立一个分类器。当一篇新论文到来时，它能够自动判断该文章是否被录用。文中提到，这一模型可以有效拒绝 50% 的糟糕论文，错判的好论文仅占 0.4%。 讽刺的是，当他将该模型应用到这篇论文本身时，系统以高到97%的拒绝率驳回了这篇论文。 故事人物及部分情节为虚构，参考文献：https://arxiv.org/pdf/1812.08775.pdf) ","date":"2018-12-26","objectID":"/paper/:1:0","tags":null,"title":"冬日物语Ⓟ 论文","uri":"/paper/"},{"categories":["冬日物语"],"content":"O. Christmas Tree 奥瑞恩年近半旬，新一年的来临之际又让他感慨良多。 『我年轻时曾经非常想红，因此也组建了自己的乐队，尽管也发过专辑有过各种大大小小的演出，一路倒也平坦，但总感觉自己从未真正红过，可能我就是太平凡了。』他觉得作为歌手，除却专业水准，也许鲜明的个性与偶尔出格的行为更容易赢取大家的关注。 『可是花开一时，而您却像歌唱界的常青树，虽然不受太大关注，却能在寒冬来临之际，依然维持本真，受人喜爱，予人温暖，这就是您平凡而不平庸的个性呀！』支持他的粉丝如是说。 ","date":"2018-12-25","objectID":"/christmas-tree/:1:0","tags":null,"title":"冬日物语Ⓞ 圣诞树","uri":"/christmas-tree/"},{"categories":["冬日物语"],"content":"N. Gift 娜塔莉试图用一种理性的眼光去解决『最佳礼物选择』的问题：在考虑到自己与受礼人的关系及其价值观、审美偏好、生活环境等因素的前提下，应该在何时以何种方式选择何种礼物赠予对方，才能使得对方获得持续长久的最大喜悦感？这可以简单看作为一个多变量的最优化问题(Optimization Problem)，如果将送礼时间、方式、物品选择和送礼后持续时间以四个变量x、y、z、t来标记，假定存在一个计算受礼者喜悦感的函数s(x,y,z,t)，那么我们需要求解在一段时间t内，x、y、z定义域下s的最大值。这一问题，在确定约束条件下，可以用数值方法求解。 『如果说礼物是一方对另一方的赠予以及传递情意的一种载体，它的使命是加深受礼者对送礼者所表达情意的理解并产生某种情感的共鸣，那么送礼的本质应该不受时间、方式和具体形态的影响。』 娜塔丽想了想，倒不如将『自己』赠予对方，不失为一种最直接而高效的做法。 ","date":"2018-12-24","objectID":"/gift/:1:0","tags":null,"title":"冬日物语Ⓝ 礼物","uri":"/gift/"},{"categories":["冬日物语"],"content":"M. Fat Nerd 马克是一个肥宅，最喜欢的饮料就是肥宅快乐水。每次打Dota杀到人就会开心地拍手，声音就像在拍肚皮，所以马克的朋友都叫他肚皮怪。 但是马克并不喜欢这个称呼。有时候还会因为被叫肚皮怪气得直接退出游戏。一年过去了，马克的Dota水平也没有提高，但心态发生了变化。有时候开心的时候还会拍肚皮拍出一段有节奏的音乐。 ","date":"2018-12-23","objectID":"/fat-nerd/:1:0","tags":null,"title":"冬日物语Ⓜ 肥宅","uri":"/fat-nerd/"},{"categories":["冬日物语"],"content":"L. Sipudei 一碗清水，一勺砂糖，半勺荤油，一枚鸡蛋。 水中的鸡蛋是灵动的，白色连衣裙包裹着炽热的内心，又好似游动着的水母，随水波飘舞着清透的薄纱。蛋黄是极害羞的，轻轻地拿勺子戳她一下，就会娇羞地咧开嘴朝着你笑。半熟的蛋黄流淌开来，舍不得被清水稀释了甜味，就拿勺子将整个鸡蛋盛起，趁热一口咬下，再喝两口汤，就感觉幸福与满足直溢心口，闭了眼，他感到暖暖的甜意。 卢卡斯虽然没有吃到冬至夜的水铺蛋，但他做了一个好梦。 ","date":"2018-12-22","objectID":"/sipudei/:1:0","tags":null,"title":"冬日物语Ⓛ 水铺蛋","uri":"/sipudei/"},{"categories":["冬日物语"],"content":"K. Coffee 凯特琳通常会在晚上11点准时睡觉。 但最近她睡的特别晚，因为她感觉自己好像喜欢上了A，但又不确定A是不是也喜欢她。她有时会主动与A聊天，然后一直等他的回复。有时他们会聊得很晚，她也丝毫没有感觉到倦意；有时她会发一些奇怪的状态，到睡前纠结要不要删掉；有时她也想着早睡，但会因为翻看A的QQ空间而睡不着觉； 现在她的作息又恢复了正常，因为昨天A向她表白了。 ","date":"2018-12-21","objectID":"/coffee/:1:0","tags":null,"title":"冬日物语Ⓚ 咖啡","uri":"/coffee/"},{"categories":["冬日物语"],"content":"J. Drone II 在距离迫降点约500米的中兴路地铁1号口，悠扬而有节奏的歌声下大叔大妈们正陶醉地跳着交际舞蹈，昏黄铜管灯下的篮球场上不时传来夹杂汗水与激情的比赛哨音。贾斯帕静坐在树荫凉亭的座位上，身靠亭柱，两耳塞上了耳机，看似悠闲地划着手机。他的一旁，放着一个黑色布袋，里面装着一台白色无人机。 贾斯帕没有想到，正向他走来的是两位学生模样的年轻男子。贾斯帕没有起身，直到他们走到他身边，他看了他们一眼，随后与他们交谈起来。 『吃了吗？』 『我们吃了。』 他们聊的并不多，显然贾斯帕与这两个人并不熟络。在临走之前，贾斯帕把身边的黑色布袋连同里面的无人机一起递给了这两人。 两人离去。贾斯帕也依旧像往常一样，戴着耳机，伴着夜色，向远处走去。 后记：对于这次无人机失而复得的事，还有许多我们所不知道的：我们不清楚小精灵在那500米的距离又经历了什么，我们不清楚那位路人甲在发现小精灵后主动联系我们的那一刻究竟在想什么，就像我们与之微信聊天时那些文字表情背后潜藏的人性冷暖。但无论如何，我们感激有爱的他人与幸运的自己，并为梦想落地的小精灵叹一口气 ","date":"2018-12-20","objectID":"/drone-ii/:1:0","tags":null,"title":"冬日物语Ⓙ 无人机（下）","uri":"/drone-ii/"},{"categories":["冬日物语"],"content":"I. Drone I 我把无人机飞丢了。 😭😭😭😭😭😭😭😭 失控，大概是每一只『无人机』的梦想吧。 ","date":"2018-12-19","objectID":"/drone-i/:1:0","tags":null,"title":"冬日物语Ⓘ 无人机（上）","uri":"/drone-i/"},{"categories":["冬日物语"],"content":"H. Hannah H 汉娜在华威念书。 H 汉娜在埃克塞特念书。 A 夏天，汉娜和汉娜一起来到了中国。 N 汉娜喜欢学习中文，汉娜也喜欢学习中文。 N 汉娜喜欢打羽毛球，汉娜也喜欢打羽毛球。 l 汉娜和汉娜成为了好朋友。 N 汉娜带汉娜登上了上海中心大厦。 N 汉娜领汉娜爬上了北京万里长城。 A 秋天，汉娜和汉娜一起回到了英国。 H 汉娜去埃克塞特开始了新学期。 H 汉娜去华威开始了新学期。 ","date":"2018-12-18","objectID":"/hannah/:1:0","tags":null,"title":"冬日物语Ⓗ 汉娜姐妹","uri":"/hannah/"},{"categories":["冬日物语"],"content":"G. Memory Card 格拉克每次在开始一次新的拍摄任务时，考虑到相机的SD卡容量有限，都习惯将其格式化。等拍摄完成后，再将素材统一导入计算机。 他同时也是一个健忘的人，他总想着明天要做的事以至于忘了昨天做过的事儿。 『人要向前看嘛，明确未来总好过于惦念过去。』他总是这样为自己的健忘辩护。 事实上，他一直记得他『忘记了』这件事，只是他从来都不愿回想，就像他总是懒得给自己的SD卡打开『写保护』。 ","date":"2018-12-17","objectID":"/memory-card/:1:0","tags":null,"title":"冬日物语Ⓖ SD卡","uri":"/memory-card/"},{"categories":["冬日物语"],"content":"F. Platanus 霞飞路是芙蕾雅放学回家的必经之路。东西走向的街道两旁种植有叶大浓郁的法国梧桐，透过叶片望去隐约可见法租界官员在三层阁楼踱步的身影。 天色渐渐暗下来了，街道的人们陆陆续续赶在回家的路上。法桐树皮在这个季节斑驳脱落，而没脱落的老皮则呈现出各种不同形态，可找到走兽飞鸟的模样，树杆上的各种凸起、凹陷千奇百怪，近看去好似有一种神奇的魔力。 芙蕾雅顺手拾起路边的一根树枝，挥舞着走向远处。风吹而过，树影摇曳，叮当作响，此刻时钟指向了九点四十五分。 ","date":"2018-12-16","objectID":"/platanus/:1:0","tags":null,"title":"冬日物语Ⓕ 悬铃木","uri":"/platanus/"},{"categories":["冬日物语"],"content":"E. Meteor Shower 据悉，一年一度的双子座流星雨刚刚划过北半球上空啦！ 摄影爱好者们振奋地静候在三脚架一旁，将自己心爱的单反转接上最出色的广角镜头，调节好曝光时间、光圈大小、ISO、白平衡这些必要的参数，一个个像驻疆的士兵一样，专注而忠实地望向眼前一片深蓝的夜空。来了。 一百来束闪耀的光辉转瞬即逝，而快门却耐心用最长的曝光记录着这纯洁而美好的想象。 欧因静坐着，把此刻的时间都交给了这片星空。 ","date":"2018-12-15","objectID":"/meteor-shower/:1:0","tags":null,"title":"冬日物语Ⓔ 流星雨","uri":"/meteor-shower/"},{"categories":["冬日物语"],"content":"D. Wool Gloves 某年的圣诞节，姥姥亲手为道维达斯织了一双绒线手套送给他。小道维达斯拿到后咯咯地笑个不停。 后来，他把一只手套撑大了当成帽子戴在头上，走起路来头顶竖着五根手指； 再后来，他把手套当成袜子穿在脚上，走起路来像鸭子； 再再后来，他的双手生了冻疮，他妈妈生气地给他戴上了手套，打了结让他脱不下来。 他哭了，因为无论他怎么挠，他的双手依旧好痒好痒，好热好热。 ","date":"2018-12-14","objectID":"/wool-gloves/:1:0","tags":null,"title":"冬日物语Ⓓ 绒线手套","uri":"/wool-gloves/"},{"categories":["冬日物语"],"content":"C. Mirror 奇普经常一个人去旅行。一年前他开始尝试拍摄vlog，用以记录他的旅行见闻，回来后剪辑成视频发布到社交媒体。 『你需要习惯经常性的面对镜头，练习和自己说话，把一个人的述说想象成两个人的对话，这很有难度。』这是他自己总结的经验。 奇普在镜头中逐渐看到了另外一个自己。 ","date":"2018-12-13","objectID":"/mirror/:1:0","tags":null,"title":"冬日物语Ⓒ 镜","uri":"/mirror/"},{"categories":["冬日物语"],"content":"B. Sunglasses 比安卡正行走在午后的香榭丽舍大街。初雪后的暖阳挥洒在路边来往的行人身上，经过反射进入她的太阳眼镜。 这是Bose新推出的一款AR眼镜：一款会说话的太阳眼镜。Bose设计这款眼镜的宗旨是通过听觉扩增你的视觉感受。 『有些东西是看不见的，我来告诉你。』 『有些东西是你想知道却看不见的，我来告诉你。』 『有些东西是你看见却不存在的，我来告诉你。』 比安卡陶醉在自己的世界里。人来人往，车流不息。 ","date":"2018-12-12","objectID":"/sunglasses/:1:0","tags":null,"title":"冬日物语Ⓑ 太阳眼镜","uri":"/sunglasses/"},{"categories":["冬日物语"],"content":"A. Training Process 凌晨一点的实验室里，安托万正目不转睛地盯着发光的电脑荧幕，像是在等待着什么。 荧幕上，开着一个名叫『Training Process』的窗口。窗口中，两条红蓝折线正随着时间并行向前。其中一条在上，叫『Accuracy』；另一条在下，叫『Loss』。在时间的刚开始，这两条折线都发生着剧烈的波动，展现着作为折线特有的个性与锋芒——极速地上升与极速地下降，而往往这种波动在两者之间是相反的，当一条处在谷底时，一条却在峰值。等待，等待。 几个小时后，奇妙的事发生了：Accuracy在波动中不断地上升，Loss在波动中不断地下降，并且他们自身的波动正变得越来越小，并逐渐趋于平滑与稳定。他们开始相互配合，并行向前。 所谓，两条棱角分明的折线终将在时间的洗礼中打磨成光滑温顺的曲线。 ","date":"2018-12-11","objectID":"/training-process/:1:0","tags":null,"title":"冬日物语Ⓐ 训练过程图","uri":"/training-process/"},{"categories":["Study Canon Programme"],"content":" 3 weeks of volunteer experience finally comes to an end. I haven’t expected to enjoy such busy but memorable experience before I, as an unprofessional photographer, truly participate in this programme. The registration day, the ice breaking games, the beautiful bird’s-eye view of the bund, the Chinese/Calligraphy/Martial arts lessons, the lakes and pagodas in Hangzhou, the fantastic badminton experience, the unforgettable visit to Chinese family, the first trial of being an host…As someone says, it’s time to say goodbye when we just started to know about each other. At first, my camera captures almost everything novel and eye-catching, nice view and lots of people. Day in and day out, I gradually realized that every single person counts, every details of life counts. The real culture is hidden behind the eye-catching views, and the firm friendship is behind the appearance of every single person. We can learn far more things about different cities and their cultures only we try to settle down and observe more details, just a bit like doing research. The world is not so much big nowadays, yet we still have a lot to try and discover. Keep in touch and good luck. ","date":"2018-09-01","objectID":"/scp-9/:0:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 物证：睁开眼去享受","uri":"/scp-9/"},{"categories":["Study Canon Programme"],"content":"1. 结业证书/证件及资料 从中可以获取许多好看的人的联系方式。 ","date":"2018-09-01","objectID":"/scp-9/:0:1","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 物证：睁开眼去享受","uri":"/scp-9/"},{"categories":["Study Canon Programme"],"content":"2. 合照 仅作纪念用。不太好用，抽屉太短放不下，不便携带。 ","date":"2018-09-01","objectID":"/scp-9/:0:2","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 物证：睁开眼去享受","uri":"/scp-9/"},{"categories":["Study Canon Programme"],"content":"3. 摄像摄影器材 700D和Osmo+都是借的，最后要还了放在一起留个念想。 ","date":"2018-09-01","objectID":"/scp-9/:0:3","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 物证：睁开眼去享受","uri":"/scp-9/"},{"categories":["Study Canon Programme"],"content":"4. SD卡/移动硬盘 用于存储照片，好几百个G，一时不知道如何处理。其中移动硬盘因为借人把某个文件夹的权限改成了不可读写，现在自己也打不开了。 ","date":"2018-09-01","objectID":"/scp-9/:0:4","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 物证：睁开眼去享受","uri":"/scp-9/"},{"categories":["Study Canon Programme"],"content":"5. 羽毛球 塑料羽毛球其实不太好用，不过这背后两个Hannah的故事很是奇妙。 ","date":"2018-09-01","objectID":"/scp-9/:0:5","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 物证：睁开眼去享受","uri":"/scp-9/"},{"categories":["Study Canon Programme"],"content":"6. 纪念小物品，from王小明 Stefan（王小明）送的小礼物。他想靠送我礼物的伎俩说服我每天中午12:00在“Mao Rock”和他一起吃饭。 ","date":"2018-09-01","objectID":"/scp-9/:0:6","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 物证：睁开眼去享受","uri":"/scp-9/"},{"categories":["Study Canon Programme"],"content":"7. 画的是熊猫吧 两个不好好听课的哥们在书法课上塞给我的“纪念品”。真丑，一点用的都没有。 ","date":"2018-09-01","objectID":"/scp-9/:0:7","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 物证：睁开眼去享受","uri":"/scp-9/"},{"categories":["Study Canon Programme"],"content":"8. 主持手卡 证明我有在认真地准备主持。实际上都靠临场发挥，随性表演。第一次应该也是最后一次。 ","date":"2018-09-01","objectID":"/scp-9/:0:8","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 物证：睁开眼去享受","uri":"/scp-9/"},{"categories":["Study Canon Programme"],"content":"9. Marmite酱 还没尝试，不知道有没有被宿舍其他人先吃完。它让我想起Emma，就像那句广告词：Love it, or hate it。爱之深，恨之真。Emma真就是那样的人。 最后，你看到之前日更的内容变成了周更，不要奇怪，那是因为我本是很懒的人。也罢，要求不要太高，能写出点东西就不错了，本来还想总结一下，写点别的有趣的东西。算了，再见。 ","date":"2018-09-01","objectID":"/scp-9/:0:9","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 物证：睁开眼去享受","uri":"/scp-9/"},{"categories":["Study Canon Programme"],"content":"EFS18-55mm | EFS18-135mm | VSCO P7/instant Chinese Calligraphy，即书法课。每个班的同学都可以在课堂上使用毛笔进行自由创作。两周来我跟拍了两个下午的书法课，看到不少有趣的作品和可爱的人。Po一些作品（部分），致大家纷纷的创作欲。 ","date":"2018-08-24","objectID":"/scp-8/:0:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 本周图集：致纷纷的创作欲","uri":"/scp-8/"},{"categories":["Study Canon Programme"],"content":"EFS18-55mm/TV | dji osmo+ Follow PD职责是要紧跟随游走目标的脚步，去捕捉一些有趣奇怪的瞬间。但是这个真的很累很难，你需要取得目标的信任。而且，我往往跟着跟着就跟丢了目标，然后转而去拍拍周围的景致，随意地行进，然后换个目标，继续跟进。有时候阳光太烈，就干脆放弃拍摄，找一凉亭，坐定发呆，静看水面的荡漾微波与闪动光效。 以下记录四则见闻。 ","date":"2018-08-19","objectID":"/scp-7/:0:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 随行，随行，随性","uri":"/scp-7/"},{"categories":["Study Canon Programme"],"content":"西子湖畔突如其来的雨 雨开始下了，像细针一般砸到荷叶表面，那表面细微坚硬的绒毛在承受到水珠巨大的冲击时，又将水珠迅速托起。水珠是极害羞的，在空中，她将自己紧紧地抱成一团，形成近乎完美的圆形，在天光中折射出自身性感的形体。荷叶绒毛也不忍破坏这灵动的身躯，小心翼翼地将她们抛起，接住，又抛起，再接住。雨变大了，风也随之兴奋起来。越来越多的水珠在硕大的荷叶表面蹦跳着，欢呼着，嬉闹着，欢庆着一场酣畅刺激的派对，荷叶将她们牢牢包裹在自己的怀里，她们感到了无比的自由与温暖。周围的人们拖着狼狈的身躯匆匆离开，跑去屋檐下避雨。 自由啊自由。 ","date":"2018-08-19","objectID":"/scp-7/:1:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 随行，随行，随性","uri":"/scp-7/"},{"categories":["Study Canon Programme"],"content":"细雨中的Apple Store 方正的外型，巨大的玻璃幕墙，亮白的LED灯光和闪耀的Apple logo。Apple的西湖店正门前是一条宽阔的步行街道，街道两旁设有护栏，禁止行人步入。两旁与之垂直的延安路和东坡路上熙熙攘攘，霓虹闪耀。与Apple一街之隔的是新开不久的Victoria’s Secret全品类门店，巨大的亮粉色幕布与亮白色玻璃幕墙遥相呼应。 细雨还在下着，走在Apple Store二楼的平台，看玻璃幕墙上细细流淌的水珠。水滴从头顶下落，贴着玻璃笔直地滑行，有的滑得很快，有的滑得很慢，有的走走停停，在遇到同伴时融为一体，愉快地下坠。站立着，感觉整个人都被这细致朦胧的“瀑布”所包围。隔着瀑布隐约可见那发出亮粉色光芒的维秘大楼门前大步行进的人们。空气中的水汽弥漫开来，氤氲着一种粉色的甘甜。 ","date":"2018-08-19","objectID":"/scp-7/:2:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 随行，随行，随性","uri":"/scp-7/"},{"categories":["Study Canon Programme"],"content":"六和塔下的感人光效 临近傍晚，六和塔依旧矗立在阳光的掩映之中，遥望着两侧的西湖与钱塘江水。大伙儿陆续聚拢过来，背对着站立在塔前牌坊的水泥石阶上。阳光从树叶的缝隙中穿过来，挥洒在人们的发梢之间，发丝吸收着阳光的暖意，远望去闪耀出亮眼的光芒。逆光行进，摄像机将两百多人的容光全都收纳其中，前排的人们拿着紫色的横幅，面露灿烂的笑容。陀螺仪在行走中发挥着稳定画面的作用，从左侧移步右侧，镜头由近及远，光辉在画面左上角显现出泛红的光晕，给画面加上了一层朦胧柔美的滤镜。这光晕时而被树叶遮挡，又清晰真切地显现出人们惬意闲聊的状态。前方的摄像师们已经就位，观察着取景框中画面，做着最后的微调。 “Cheers！” ","date":"2018-08-19","objectID":"/scp-7/:3:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 随行，随行，随性","uri":"/scp-7/"},{"categories":["Study Canon Programme"],"content":"睡梦中的Angela 两个小时的Hiking结束了。Angela手举一面写着“China”的蓝色小旗，带着大家向停车场走去。四周到处都是种满龙井茶的田地，不时能看到人们提着竹篮采摘龙井的背影。 上车了，大家有些累了，三个小时的车程里应该有时间好好地打个盹了。天气是格外得晴朗。Angela起身拿起了话筒，不失幽默地用她那带着上海口音的英语像我们介绍起了身边钱塘江、阿里巴巴和马云的故事，汽车驶过壮观的钱塘江大桥，江水涌动，Angela手拿话筒，凝视着车厢内的一张张面孔，开始轻声吟唱起“Edelweiss”。车厢内格外地安静，流淌在空气中的，唯有Angela那柔美动听的人声。车在行进，江畔的白云压得很低，与车流、水流一起前行。 “Farewell. May Angela be in your dreams.” ","date":"2018-08-19","objectID":"/scp-7/:4:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 随行，随行，随性","uri":"/scp-7/"},{"categories":["Study Canon Programme"],"content":"明天去杭州，今天就轻松一下，想到什么写什么吧。 老师是研三毕业的老师，艺术学院。写得一手好字。挺好看。参加这种志愿活动几乎不赚钱； 又见“Sheldon”，他写了一个不错的福字； 叫Emma的同学给自己去了中文名叫“愛妈”，love mum； 有人在扇子上写了“猪”（pig），有人写了“圆？”（to ask for money），有人写了“野兽”（beast），有人画了一个“愛”（love）； 前几天调的亮度都偏暗，今天好多了； 研究了一下Osmo的鸡头使用方法，躲在理科楼八楼拍了第一张全景图； 雨中踢球真是件痛快的事！ 美妆博主拍的一张照片好像被China Daily选中了； 29岁的小明好像赖上了我睿鸣； UK没有蝉的嘛？ ","date":"2018-08-16","objectID":"/scp-6/:0:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 今日印象十则—书法课与雨中拍摄","uri":"/scp-6/"},{"categories":["Study Canon Programme"],"content":"EFS18-55mm | TV：1/125 | ISO：200 这两天的天空总会在大太阳底下飘过几朵乌云，然后窸窸窣窣地飘一阵小雨。待到日落时分，余晖扫过快速滑行的云彩，在远处高层建筑上方折射出别样的光彩。 此刻，在中山东一路与南京东路交汇口的人行道上，信号灯在有规律的转换红绿两种颜色，每隔大约60秒，就会有无数的面孔像你扑来，踏上台阶，从面前涌过，再扑向另一方无尽的人群。 三十几人的阵势要在这里集体游走几乎没可能不走散，更别说是对于从英吉利远洋而来的初到者们。所谓“导游”，就是在这种时刻高举小旗，身长脖颈儿高呼着召集令，带人们从一个人群挤进另一个人群的勇士。可是此类的出行体验是极差的：人们不想受制于指挥，不想被时间催促步伐，只能跟着大部队向身后的留恋念念叹息；还有一种“志愿者”，会采用一种“分治”的技术，他们将30多个人分为若干小队，每个小队派一位随行PD，约定集合地点和时间，然后向着不同的目标进发。与“带队勇士”不同的是，他们是多个小分队形式的架构，并且PD们往往不会在队前充当勇士，而更会以一种平等的姿态与小队成员沟通交流。这样会好很多，但平均分组和目标选择有时会成为一个问题；再有一种“就地解散”策略，最为简单有效。此种方法只需要一个领队人员，然后再乘着所有人都到齐还未决定要去哪里的懵逼状态时，赶紧跑去寻找就近的制高点，气势坚定地喊出：Dissolution！然后千万不要回头，赶紧从人群中溜之大吉，附近找一个人烟稀少难以察觉的里弄小饭馆，去厕所点一碗清汤面，要几个浇头。坐定，打开微信，在包含所有人的群聊中开启自己的实时位置分享，告诉大家“有困难随时来找我，随时恭候🙂”之类的客套话。最后给手机接个充电宝，就可以等面上桌，好好享用一顿晚餐了。 ","date":"2018-08-15","objectID":"/scp-5/:0:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 大规模扫街活动的出行之道","uri":"/scp-5/"},{"categories":["Study Canon Programme"],"content":"EFS18-55mm | TV：1/60 | ISO：Auto 今天本来要去全程观摩中文课的，可是因为懒，外加没有SD卡这一臆想出来的借口，就没有聆听全程。况且，谁让我那副18-135mm的眼镜又被无情地剥夺了，拍不出所谓“专注”的好照片，也是情有可原的嘛。 下午倒是去旁听了一个lecture。讲的挺无聊的，列了很多很多数据，但PPT的字号却不够在后面的人清晰地看清。但我要说的是室内的光线，总体进光不足，还有从一个窗口射进来的耀眼的白光。逆光拍摄的结果就是把所有的白人拍成了黑人。“摄像就是用光的艺术”，没有光，甚至连光都要和你作对，那又有什么办法，直接认输好了。 所以今天的主题是关于后期的。那些后期教程说，“好照片都是靠修出来的。”我从来都不以为然，因为我很懒，而且我根本就不明白那些复杂的曲线和细微的参数该做出如何科学地配比和调整，才能让所有不同的画面有拥有统一的色调与完美的感官。同样没有标准答案，这种“自定义的滤镜”要根据不同的场景做不同的调整，而具体要调出怎样的“个性”，见仁见智。 拿到一张原片，下一步大概会作出以下三种选择：1. 完全没有后期的愿望。因为拍的太烂了（脱焦/构图不好/过曝/噪点…）。于我而言，这是绝大多数情况；2. 非常想要立刻后期。因为这些片子让我联想到了此前看过无数相片的某一种特定调色风格，也好想试着模仿其中的色调呀！这种时刻偶会闪现，前提是没有出现1中烂片的情况，然后就是考验技术的环节了；3. 舍不得后期。拍了张好照片，有的时候总觉得这张照片不应该做后期，因为我不想刻意去营造某一个臆想的氛围，即使在感官上这种氛围更令人向往。但所见即所得，这是最为真实的写照，也是最为高级的处理手法。此种情况最为难得。 其实还有一种情况：懒。什么都不想做了，拍的爽不就行了嘛。 ","date":"2018-08-14","objectID":"/scp-4/:0:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 除了懒，那些舍不得修的都是好照片","uri":"/scp-4/"},{"categories":["Study Canon Programme"],"content":"EFS18-135mm | TV：1/650 | AV：？| ISO：Auto 因为戴上了18-135mm的变焦眼镜，视界就变得不一样了。这种眼镜，能让我擦亮眼睛看清我想要关注的人，而对于周遭无关的一切，只视之为模糊的光斑。“专注产生美”，这话说的很对。 K将我卖身给了一个女生，我倒是一点都不介意的，反倒有一些许的高兴，你要问我为什么，我不想告诉你。但我猜测作为女生的视角一定不同于男生，今日所见的一定胜过于昨日所见的。 今天的任务是用5分钟时间玩10个破冰游戏。每成功完成一个游戏就会得到相应的图章，集齐所有图章就能兑换奖品。但这是个艰巨的任务，因为以我的水平，平均通过一个游戏就得花个5分钟，10个游戏，50分钟？怎么可能！正如前文所叙，专注是美妙神奇的，它一定能够带来我所期望的美好。 游戏开始了，5分钟计时也开始。我从门口进入，走向第一个游戏摊位，并试图立刻聚焦于我所关心的事物，我不能眨眼，因为眨眼会浪费宝贵的时间，会分散我的注意力。就这样，我迅速通过了第一个游戏，随后目光一转，有聚焦于第二个游戏。这里的转换目标是最大的难点，因为你需要同时保证所见画面的稳定与优美。还好我勉强做到了。如此循环往复，直到成功完成最后一个游戏。 I made it！我会暗自窃喜。其实我并清楚每个游戏具体是做什么的，游戏是什么并不重要，重要的是要迅速专注于其中自己所感兴趣的目标，这没有标准答案，任何事物都有其值得发觉的趣味。重要的是纯粹地专注于一点，这就足够了。 ","date":"2018-08-13","objectID":"/scp-3/:0:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 用5分钟玩10个游戏","uri":"/scp-3/"},{"categories":["Study Canon Programme"],"content":"TV：1/125 | ISO：Auto 台风摩羯登陆的第一天，魔都也下雨了。 ","date":"2018-08-12","objectID":"/scp-2/:0:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 雾气、时间，我都分不清了","uri":"/scp-2/"},{"categories":["Study Canon Programme"],"content":"雾气 早上出门，雨滴打在头上，湿漉漉的渗入心脾，又幻化成雾，光线在镜面与玻璃之中折射穿行，睁开眼，却什么都看不见了，唯有白茫茫的一片。我开始有些慌了，我讨厌雾气在我眼角膜上徘徊弥漫，虽然这营造出了一种虚幻飘渺的朦胧感，但我今天不需要这些，我要真切写实的具体感。更可怕的是，当你失去一种感官时，你的另一种感官会变得尤为敏感。雨下得越发刺耳，打在周遭石墙、铁板与水泥地上，打在头顶、肩带与眼眸上，打在我不安的内心深处感到隐隐刺痛。该怎么办呀。 ","date":"2018-08-12","objectID":"/scp-2/:1:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 雾气、时间，我都分不清了","uri":"/scp-2/"},{"categories":["Study Canon Programme"],"content":"时间 当我重新恢复视力的时候，满眼已是人来人往的金发碧眼。时间过得真快呀。 我开始坐在一角默默地记录时间。三脚架让我可以端正稳定地望向前方。眼前的红蓝米字旗随着人们走过所携的风有规律地摇曳着，那些拖着大大小小行李箱的人，含着一种特有的英式腔调走过ABCDE紫色的标牌，黑色的签名、橙色的文件袋，深棕色的护照，还有红色的T恤，一切又充满了色彩。这些我都看在眼里，我会时不时地将这一类似的场景在脑中快速播放，仿佛得以加速了时间，让其从我身边飞驰而过，这种速度感营造出一种流水般的清澈与美好，好像我能掌控一切，在变化与多样间找出其不变的本质。如果生活也能加速就好了，我就能在信息与挑战的冲击中更快地长大；如果生活要是慢一些也挺好，我就能在细微与平淡中变得更加从容快乐。如果二选其一，我有点无所适从。 ","date":"2018-08-12","objectID":"/scp-2/:2:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | 雾气、时间，我都分不清了","uri":"/scp-2/"},{"categories":["Study Canon Programme"],"content":"大家好，我叫六百五，这几天K说不想写日记，要让我代劳。呵呵，让别人写的日记还叫日记么。我可不会帮别人抒发不存在的感情，但可以记录一下这几天发生的事。 其实也没什么大事啦，只是觉得这几天相机盖打开地特别勤，好几次刺眼的光线迎面扑来，让睡眼惺忪的我应对不及。K说，他要开展一个“Study Canon Programme”，所谓“研究佳能项目”。切，名字取的好听，说白了他最近可能又闲得慌了，又开始想装腔作势地玩单反了，还要专挑我这种毫无抵抗能力的陈年机型下手。唉。 据说在这个为期三周的项目中，我会启用最高50mm的焦距，有机会近距离地观察200多位来自UK的小哥哥和小姐姐们。看他们提着行李箱在30几度的太阳下反射光芒的汗珠，看他们一颦一笑之间与那些中国伙伴有趣的互动，看他们说中文握毛笔打武术时别样的姿态。听上去还挺好的，当然，我还是最喜欢看那漂亮脸庞下动人的笑容。 然后我再说说我这几天的主要任务，简单说来就是：纪录。纪录的话就是就是要真实，要客观，而不要修图，不要滤镜。我一直觉得滤镜这个东西是保有主观色彩的，不同人有不同的偏好。滤镜的使用最好是要配合某个主题的摄像的，否则滤镜就是真实的掩饰，它消除了某种信息。而我们的生活，也经不起刻意的做作与点缀，因为它不是事事如意的。 刚刚进行了睡前调试，主要会使用TV档，便于抓拍人物表情。我还设了一个4s一次的snapshoot视频快照，顺便可以撸点小视频。（虽然我听力不是很好。K一直不愿意给我在热靴上配个麦克风，这次把China听成Canon，也不能只怪我） ","date":"2018-08-11","objectID":"/scp-1/:0:0","tags":["志愿者","摄影","UK","日记"],"title":"SCP | Study Canon Programme","uri":"/scp-1/"},{"categories":null,"content":" Oops! It looks like you’re lost. Sorry about that. Let me try and help. Go back home and start over. ","date":"0001-01-01","objectID":"/404/:0:0","tags":null,"title":"","uri":"/404/"},{"categories":null,"content":"2021.01.29，深度学习个人工作站配置清单 硬件 型号 价格 主板 技嘉z490 aorus master CPU i7 10700(K)F 4999 4999-60 显卡GPU 华硕RTX3090 AD OC 24G 13500 13500 内存 芝奇幻光戟32G（16x2） 1429 1429 固态硬盘 三星NVMe 970 EVO PLUS 512G 649 649 机械硬盘 希捷EXOS 8T 1249 1279 散热器 海盗船H100X240冷排 627 627 电源 RM850X 机箱 海盗船Air540 2049 1849 合计 8834 2021.01.27，跨站脚本攻击（Cross-Site Scripting, XSS） 参考：https://www.zhihu.com/search?type=content\u0026q=跨站脚本攻击 ","date":"0001-01-01","objectID":"/trend/:0:0","tags":null,"title":"","uri":"/trend/"},{"categories":null,"content":"跨站脚本攻击（Cross-Site Scripting, XSS） 在web页面插入恶意脚本，当用户浏览页面时，促使脚本执行，从而达到攻击目的。XSS的特点就是想尽一切办法在目标网站上执行第三方脚本。 栗子：原有的网站有个将数据库中的数据显示到页面上的功能，document.write(\"data from server\")。但如果服务器没有验证数据类型，直接接受任何数据时，攻击者可以会将\u003cscript src='http:bad-script.js'\u003e\u003c/script\u003e当做一个数据写入数据库。当其他用户请求这个数据时，网站原有的脚本就会执行document.write(\"\u003cscript src='http:bad-script.js'\u003e\u003c/script\u003e\")。这样，便会执行bad-script.js。如果攻击者在这段第三方的脚本中写入恶意脚本，那么普通用户便会受到攻击。 XSS的三种类型： 存储型/持久型XSS（Persistent XSS）：注入的脚本永久地存储在目标服务器上，每当受害者向服务器请求此数据时就会重新唤醒攻击脚本； 反射型XSS（Reflected XSS）：当用受害者被引诱点击一个恶意链接，提交一个伪造的表单，恶意代码便会和正常返回数据一起作为响应发送到受害者的浏览器，从而骗过了浏览器，使之误以为恶意脚本来自可信的服务器，以至于让恶意脚本得以执行。 DOM型XSS（DOM XSS）：有点类似于存储型 XSS，但存储型 XSS 是将恶意脚本作为数据存储在服务器中，每个调用数据的用户都会受到攻击。但 DOM 型 XSS 则是一个本地的行为，更多是本地更新 DOM 时导致了恶意脚本执行。 防御XSS攻击的方法： 从客户端和服务器端双重验证所有的输入数据，这一般能阻挡大部分注入的脚本 对所有的数据进行适当的编码 设置 HTTP Header： “X-XSS-Protection: 1” 2021.01.27，近期推文计划 EDA，一种文本数据增强方法 卡片校正算法 一个数独算法 LMSI栏目下周起恢复推送 2021.01.26，施工进度自查 初始化，选用Hugo-CodeIT主题 网站信息基础配置，个性化样式（字号、色彩风格等） 添加几篇文章 小站运行天数foot 网站Logo 域名申请 Netlify部署 新增『动态/Trends』栏目 『关于』页面 新增Tiddlywiki CI/CD流水线（typora+actions+pages/netlify） 新增plausible analytics 几个栏目的Markdown模板 加载速度优化（CDN加速/图片压缩） 评论系统及相关组件测试 添加文章置顶标记🔝 404页面 网站标题字体修改 英文网页支持配置 新增『项目/Project』栏目 新增『相册/Photos』栏目 彩蛋与一个隐藏页面 ","date":"0001-01-01","objectID":"/trend/:0:1","tags":null,"title":"","uri":"/trend/"},{"categories":null,"content":" 上一页去看看吧。 Oops! This page is still **under construction**. Sorry about that. Go Back and start over. -- ","date":"0001-01-01","objectID":"/project/:0:0","tags":null,"title":"项目","uri":"/project/"},{"categories":null,"content":"OCR system for financial sheets [Oct. 2020 – Dec. 2020] The project built an OCR system for financial sheets analysis. My main contribution: 1. Train and deploy a text recognition model based on CRNN; 2. Adopt an data augmentation strategy inspired by the paper EDA to handle the small sample size problem. The avg. time for text detection and recognition for an image (1000x2000px) is within 5s on CPU and the recognition accuracy over ~10,500 test samples is above 95%. ","date":"0001-01-01","objectID":"/project/:1:0","tags":null,"title":"项目","uri":"/project/"},{"categories":null,"content":"ID-card rectification [Jun. 2020 – Jul. 2020] The project realized an image rectification API for ID-card images in natural scenes. It mainly utilized an edge detection network for card contour detection and opencv interface for perspective transformation. The API provide single and batch image processing services and currently serves for RightPrint Mini Program. [code] ","date":"0001-01-01","objectID":"/project/:2:0","tags":null,"title":"项目","uri":"/project/"},{"categories":null,"content":"Fabric defect detection [Jun. 2019 – Aug. 2019] An algorithm developed for fabric defect detection. The algorithm goes through the following step: 1. Image preprocessing (crop, resize, remove uneven illumination, and remove moire patterns); 2. Surface defect detection (OTSU threshold, morphological transformation); 3. Linear defect detection (Canny edge detection, Hough line detection); 4. Defect feature extraction and classification; 5. Display and generate for XML output. ","date":"0001-01-01","objectID":"/project/:3:0","tags":null,"title":"项目","uri":"/project/"},{"categories":null,"content":"Predicting radiotherapy sensitivity of laryngeal cancer based on DNNs [Jul. 2019 – Oct. 2019] In this study, we enrolled 200 patients with laryngeal cancer (LC) who underwent standard radiotherapy alone. Patients were followed up and were classified into radiotherapy-sensitive (LC-RS) and radiotherapy-tolerant (LC-RT) groups according to their prognosis. I took the responsibility of modeling a convolutional neural network based on GoogLeNet, VGG16 and ResNet50 to predict the sensitivity of patients with radiotherapy, and combined the clinical features such as EBV, tumor markers, etc. to compare the imaging difference between LC-RS and LC-RT. Experimental results showed that our model reached 74.5% prediction accuracy among 55 patients of CT scans. ","date":"0001-01-01","objectID":"/project/:4:0","tags":null,"title":"项目","uri":"/project/"},{"categories":null,"content":"Medical MRI Segmentation [Sep. 2018 – Jun. 2020] Work#1 (ICIP-19): A LSTM method with Multi-modality and Adjacency constraint is proposed for segmenting three tissues in Brain MRI. Two feature sequence generation ways in the method are used, i.e., features with pixel-wise and superpixel-wise adjacency constraint. The method is more robust than clustering-based methods like FCM, K-Means, and performs better than other feature classifiers like SVM and KNN, achieving 98.66% Dice Coefficient on the BrainWeb dataset. [pdf] [code] Work#2 (AAAI-20): It proposes a Recurrent Decoding Cell (RDC) for hierarchical feature fusion in the encoder-decoder segmentation networks. RDC leverages the ability of convolutional RNNs in memorizing long-term context information. The RDC-based segmentation network achieves 99.34% Dice Coefficient on the BrainWeb dataset, which is better than FCN, SegNet and U-Net, and is robust to image noise and intensity non-uniformity in medical MRI. [pdf] [code] ","date":"0001-01-01","objectID":"/project/:5:0","tags":null,"title":"项目","uri":"/project/"},{"categories":null,"content":"My spirit (Unity Games) [Dec. 2015 – May. 2016] My Spirit is a 2D hand-drawn-style adventure game. It tells the story about the legendary life of Jerry from the spirit world to the real world. Players use keyboard or Xbox controller to control the characters. We use Unity as the game engine and C# as the programming language. The game is produced by our team EBM, I took charge of the character/UI design, shooting and part of the algorithm realization in this project. [doc] [demo video] Screenshot 序章：1948——灵界（截图） \" 序章：1948——灵界（截图） 第一章：1949——丛林（截图） \" 第一章：1949——丛林（截图） 第二章：1974——工厂（截图） \" 第二章：1974——工厂（截图） ","date":"0001-01-01","objectID":"/project/:6:0","tags":null,"title":"项目","uri":"/project/"},{"categories":null,"content":"FarmKit [Dec. 2014 – May. 2015] FarmKit is a software and hardware framework made specially for agricultural research. It consists of three parts: Intelligent Agricultural Control Terminal, Robot Surveillance and Control System and the Greenhouse Control System. I tested the performance of the robot in greenhouse and collected environment data. This project competed in Imagine Cup 2015 World Citizenship Group and won the second prize in national final. [doc] ![OCR财务报表识别](https://tva1.sinaimg.cn/large/008eGmZEgy1gnfe1j7379j315x0kbtgt.jpg) --- ## 身份证图像校正 ![Picture1](https://tva1.sinaimg.cn/large/008eGmZEgy1gnfdlcc741j30qv0d60zh.jpg) 项目实现了一种在自然场景下拍摄的身份证件照片的透视变化校正。算法层采用了基于传统 Canny 边缘检测与深度边缘检测⺴ 络相结合的方法提高卡片校正的精度和速度，在复杂背景下卡片的校正成功率在 75%以上，目前该算法服务于 RightPrint 立印 微信小程序提供身份证图像校正接口。 [Code] --- ## LSTM-MA: A LSTM Method with Multi-modality and Adjacency Constraint for Brain Image Segmentation `research` ![pipeline](https://tva1.sinaimg.cn/large/008eGmZEgy1gnbvdvp586j32i90rqwps.jpg) Abstract: MR brain tissue segmentation is a significant problem in biomedical image processing. Inhomogeneous intensity and image noise influence the segmentation accuracy. In this paper, we propose a LSTM method with multi-modality and adjacency constraint for brain image segmentation, named LSTM-MA. Two feature sequence generation ways in our method are used, i.e., features with pixel-wise and superpixel-wise adjacency constraint. The LSTM model classifies the generated features into semantic labels to form the segmentation result. The evaluation experiments on BrainWeb and MRBrainS demonstrate that the proposed LSTM-MA with pixel-wise adjacency constraint achieves promising segmentation results, while LSTM-MA with superpixel-wise adjacency constraint shows its computational efficiency as well as robustness to noise. [PDF] [Bib] [Code] --- ## Segmenting Medical MRI via Recurrent Decoding Cell[^1] `research` ![](https://tva1.sinaimg.cn/large/008eGmZEgy1gnbvclbi85j30om098gnl.jpg) Abstract: The encoder-decoder networks are commonly used in medical image segmentation due to their remarkable performance in hierarchical feature fusion. However, the expanding path for feature decoding and spatial recovery does not consider the long-term dependency when fusing feature maps from different layers, and the universal encoder-decoder network does not make full use of the multi-modality information to improve the network robustness especially for segmenting medical MRI. In this paper, we propose a novel feature fusion unit called Recurrent Decoding Cell (RDC) which leverages convolutional RNNs to memorize the long-term context information from the previous layers in the decoding phase. An encoder-decoder network, named Convolutional Recurrent Decoding Network (CRDN), is also proposed based on RDC for segmenting multi-modality medical MRI. CRDN adopts CNN backbone to encode image features and decode them hierarchically through a chain of RDCs to obtain the final high-resolution score map. The evaluation experiments on BrainWeb, MRBrainS and HVSMR datasets demonstrate that the introduction of RDC effectively improves the segmentation accuracy as well as reduces the model size, and the proposed CRDN owns its robustness to image noise and intensity non-uniformity in medical MRI. [PDF] [Bib] [Code] --- ## 基于深度神经网络的喉癌放疗敏感性预测模型 fig\" fig 在这项研究中，我们入组了200名接受单纯放疗标准方案的喉癌患者，随访它们的预后情况并根据预后分为放疗敏感和放疗耐受两组。我在其中负责建立基于GoogLeNet, VGG16和ResNet50的卷积神经网络模型预测患者的放疗敏感性，并结合临床特征如EBV、肿瘤标志物等比较放疗敏感和放疗耐受患者CT影像上的差异。实验显示，利用该模型对55名患者CT扫描图像进行放疗敏感性预测可以达到74.5%的准确率。 --- ## 布匹瑕疵检测 --- ## My Spirit[^2] ![](https://tva1.sinaimg.cn/large/008eGmZEgy1gnfcmfozndj30d60d7js0.jpg) 游戏截图 序章：1948——灵界（截图） \" 序章：1948——灵界（截图） 第一章：1949——丛林（截图） \" 第一章：1949——丛林（截图） 第二章：1974——工厂（截图） \" 第二章：1974——工厂（截图） --- ## FarmKit（智能农业开发套件） ![](https://tva1.sinaimg.cn/large/008eGmZEgy1gnfciopylgj30c00iedgi.jpg) 在这项研究中，我们入组了200名接受单纯放疗标准方案的喉癌患者，随访它们的预后情况并根据预后分为放疗敏感和放疗耐受两组。我在其中负责建立基于GoogLeNet, VGG16和ResNet50的卷积神经网络模型预测患者的放疗敏感性，并结合临床特征如EBV、肿瘤标志物等比较放疗敏感和","date":"0001-01-01","objectID":"/project/:7:0","tags":null,"title":"项目","uri":"/project/"}]